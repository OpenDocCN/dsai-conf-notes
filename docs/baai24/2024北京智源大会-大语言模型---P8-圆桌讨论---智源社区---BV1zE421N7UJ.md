# 2024北京智源大会-大语言模型 - P8：圆桌讨论 - 智源社区 - BV1zE421N7UJ

首先我想問各位嘉賓，因為各位都是做大模型的，那麼大模型的能力呢，我們也看到它呈現出非常明顯的代際差，比如說我們看到GPT-3，GPT-3。5，GPT-4，以及我們非常期待的未來的GPT-5。

大家都猜測說每一代的能力，也現在已經看到的，包括猜測都發現它們相差是很大的，那麼想問各位老師，你們覺得是什麼關鍵的要素，可以產生這樣的提升，要不有請趙老師先說，請嘉賓先說，好的好的，那曾老師先說吧。

非常感謝，其實我今天在我的PPT裡，也放了一張和Scanning Law有點相關的圖，然後那個圖其實大家仔細看的話，我覺得它的大模型發展的奧秘，基本上都藏在其中，為什麼模型代際之間會有巨大的效果差異。

其實它也是來源於Scanning Law，我們去看那個圖，它有兩個軸，一個是橫軸一個縱軸，兩個軸都是取了對數之後，它的表現是呈一條依次曲線，然後這樣一個，就是因為它滿足這樣的關係。

所以當我們對我們的訓練算法，對模型的各種理解加深之後，我們能夠把那個曲線，就向內平移一下，往下平移一下，這樣它帶來的提升也是指數級的提升，所以這樣的一種性質帶來了，就不同代際之間模型架構能夠有。

那模型效果能夠有一個非常明顯的變化，同時就是包括我們做Mini CPM，為什麼能夠佔成自身幾倍的模型，而不是比自身多多少幣參數的模型，其實也是因為這個原理。

所以曾老師覺得是Scanning Law的這個優勢，然後它什麼也不用做，就可以有這樣的代際差，那不知道其他老師有沒有不同的意見，東老師也是真正參與訓練模型大模型。

Scanning Law也在你的那個talk裡多次被提到，你覺得除了這個還有什麼關鍵的要素嗎，我覺得Scanning Law首先肯定是非常fundamental的一個factor，或者甚至是最重要的。

有可能是大概率是最重要的一個factor，然後除此之外的話，其實今天很多那個報告也提到，其實無論是GPT還是我們自己的模型，咱們國內其他團隊的模型。

其實大家也可以看到從2023到今年2024這一年多的時間，其實大家都推出了好幾代，其實大家如果看各自的模型，其實應該是國揚提到好像是說就包括拉瑪自己也是，對吧，其實就看各自一個模型family之內的話。

看同樣的size的話，同樣的compute的情況下，其實模型的效果也有很大的提升，其實很大程度上可能那個主要的變量還是那個數據質量，或者數據的多樣性，或者數據的配比方面的一些探索，然後，除此之外的話。

我猜可能還有其他元素，可能我們賀老師或者其他老師可以再補充，其他老師有補充嗎，對，東老師提到也非常重要，數據，對，我要不我簡要補充一下，其實我以前也簡單短暫的在工業界工作過，我個人覺得還有一個因素。

其實是其實整個大模型，因為這幾個模型都是畢業模型，我們先不考慮開源的模型，畢業模型其實背後它其實是個系統工程，我理解就是說，其實它背後到底是從我們用戶快熱進去到返回輸出，整個過程我們是不知道的。

它背後到底是一個模型在工作，還是甚至有多個模型在工作，我們也不知道，我覺得它是個系統工程，就是說它很可能為了考慮一些安全因素，甚至它也可能會收集一些用戶的數據等等，它會有各種各樣的機制。

包括有一些敏感的信息進去以後，它肯定是有一些策略去做一些處理的，然後我們看到有一些非常好的結果，到底是一個模型出來的，還是多個模型一起來做一些處理的等等，我覺得這是個背後是個很複雜的系統工程。

所以說這也是我們現在不知道一些像openai等等，甚至很多模型效果這麼好的，可能是一個因素之一，對，那不知道曾老師和東老師後面是一個模型，還是幾個模型，我們是開源的，開源是明白透明的。

我們是很多是開源的，這個非常明確，比如說我們的6B模型，從一代二代到三代，其實基本上從架構從參數量，如果fix compute的話，其實也能看出來，然後背後的system。

其實也是語言part也是一個模型，對，非常感謝，那賀老師有沒有什麼補充的，這塊我是真不懂，因為真的沒有接觸過，但是我覺得可能數據量和數據質量，肯定是兩個最關鍵的因素之一，對，然後我覺得數據質量方面。

可能除了於訓練的數據質量以外，可能同樣比較重要的也是，file tuning時的數據質量，比如說如果做一些RLHF，那顯然一些非常高質量的訓練數據，肯定會對你模型最終的效果，有著一個非常重要的影響。

沒錯，那如果是提到數據的話，大家有一個擔心，就是大模型現在已經，吃下了這麼多的數據，又速度這麼快，那如果現在產生數據的速度，沒有超過大模型訓練的吃數據的速度，會不會有一天這種數據，會成為一個發展的瓶頸。

不知道各位怎麼想，好的，曾老師，能不能換個順序，可以，行，要不這個我先來回答，張老師你先，剛剛可能我也接孫老師的問題，可能兩個問題，第一個就是怎麼去看待這個模型進展，我覺得這個其實很有趣的一個事情。

就是大家可以去考慮，就是比如說人類的保健的這個學科，就是比如說人吃什麼東西會成長，或者是人成長需要什麼衛生素，這個其實要到古代那個時間，大家可能完全是搞不清楚，我覺得可能大模型訓練。

在數據這個方面和這個可能有一個類比，就是現在大家可能準備好多數據，然後去訓練，但是就是在早期，人們可能完全搞不清楚，什麼樣的數據會出什麼樣的能力，但我覺得大概到現在這個情況，可能很多大學長。

包括可能在座的很多老師，已經大概會知道，比如說什麼樣的數據，可能會出什麼樣的能力，就像你吃了什麼樣的東西，然後你可能比如說缺心或者缺鈣，可以很快去補上，對我覺得這是非常有趣的一個事情。

然後我自己覺得可能現在，像3+5像4甚至5，就數據量和scaling很重要，但是對於這個的深刻理解，可能也是非常非常重要的，對就比如說有一些能力就很難去提升，比如說像推理能力。

還有一些比如說算術的計算能力，那麼這些靠什麼數據，吃這個什麼樣的數據去把它給補充上來，我覺得這是很關鍵的一個問題，然後我覺得這個東西都得隨著時間嘗試，然後去包括一些科學探索，才能慢慢摸清楚。

然後第二個可能問題也比較有趣一點，就是說現有的數據是不是夠支撐，現在去做這樣的一個事情，首先我覺得可能很多這種超級，我稱之為超級公司，因為它有卡太多了，資源也很多，我覺得他們可能考慮的數據。

能比我們想像的可能還是多很多的，所以我覺得他們至少現在像，就是GBT5這個級別，我自己推測可能數據還沒有成為，它現在的一個瓶頸，因為他們可能有多種的，比如說私有數據，比如說多媒體數據轉文本數據。

然後可能還有很多源去獲得數據，但如果再往後走，我覺得很有可能數據會成為一個很大的，一個局限一個限制點，然後這是一個方面，另外一個方面就是，現在可能現有的數據未必是最好的，一個大模型的一個實物。

然後可能現在已經有很多，還工作開始做了，包括我們自己開始做了，就是這種合成數據，現在合成數據有的時候，對於特定能力的激發是非常非常明顯的，對 可能是我個人的一些觀念，太好了，所以實物不光有天然的。

還有人工的 人造的實物，那賀老師這方面有什麼，我覺得數據來看的話，現在其實一個趨勢就是用一些人造的數據來做，而且實際上從我們人的學習過程中來看，是人造數據也是非常重要的，因為我們可以看。

我們所有的考試題，某種意義上的數量都是人造的，因為知識本身是一個非常範的東西，那我們OK在學校的時候，會把知識抽象成很多門課，然後在每門課上，又把知識抽象成很多個知識點，而你所謂的考試的卷子。

實際上就是這些知識點的某種有機的，這種整合起來，所以如果採用這種，和人類學習差不多的這樣的辦法去生成數據，有可能能夠突破這種數據的界限，同時模型學到一些更具有繁華的這樣的一個過程，好的，東老師有補充嗎。

我想一下這個問題，我感覺我的回答會比較亂，我感覺幾個維度，第一個我想一下怎麼形容，就是說我們其實現在如果只討論語言模型的話，我們現在用到的數據實際上，某種意義上就是互聯網或者計算機，過去三四十年。

通過電子化的方式，把我們的人類很多語言，記錄下來了，在互聯網上記錄下來的，甚至包括把我們過去三十年互聯網之前的，千年的無論是古籍啊各種歷史啊，這個積累啊其實電子化了。

對吧我們現在用的其實語言數據大部分是這塊，但是從，我有點不記得是哪個統計，好像是大約有個統計是說，互聯網上現存的電子化的數據，其實只佔我們人類產生，當下產生語言或者產生文本。

所謂的text的大約1%到5%之間，我不太確定具體那個數字，對吧也就是說實際上如果從這個角度，我們理論上可用的數據還有無限多，理論上也沒有叫無限多吧，至少還有20倍到100倍的一個空間。

當然這個東西怎麼將它電子化，怎麼讓這個模型或者是算力consume，可能是一個比較難的問題，然後從另一個視角的話，就是剛才也提到了合成數據，其實比如說我們在做那個。

把這個模型context lens由128k，推到1 million的時候，1 million token的時候，其實也面臨了關於數據，當下非常實在的數據缺失的，或者是缺少的一個問題。

就是說比如說在預訓練階段，我們想把這個context lens，即使我們算力上計算上，可以推到支持1 million，在這個前提下，它其實我們目前，至少我們team能夠，access到的預訓練數據。

積累的預訓練數據，其實超過1 million，這種token的數據，其實只佔從條數的角度，instance角度可能也只有1萬條，所以某種程度上，我們也不得不利用已有的數據，利用已有的模型。

做很多合成數據的嘗試，來提供給這個模型做預訓練，其實我就以這個超常文本為例，其實我們某種程度上，也在做這個合成數據，然後還回到剛才那個第一個點，其實就是說，我們一直也在，部分我們團隊部分同學。

還有我自己其實一直在想，一個問題，就是你看，就是說我們這個大模型，到底是要學推理，還是要存知識，還是boss，就是說如果僅僅是推理的話，我感覺某種意義上是說，數據我們可能並不需要，無限的數據幫我們。

提升模型的推理能力，對吧，當然這只是個假設，我大概率我的一個猜測，如果是存知識，那自然是你有新的數據來，新的知識來，他嘗試把它存下來，但如果單純的，讓模型提升它的推理能力，是不是我們一定是需要。

無限的數據來提升，它的推理能力，其實我們也沒有想明白，或者沒有驗證明白的一點，就是說比如說我們自己的模型，三代四代一代二代到三代四代，在同樣的compute，同樣的model參數下。

用越來越高質量的數據，模型的，就是以這個benchmark衡量出來，這個推理能力是越來越強了，就是這個過程當中，其實到底我們這個數據，這個質量優化的極限在哪裡，對吧，是不是真的需要海量數據。

其實是一個開放的問題，對，也是我們團隊也一直在想，驗證和回答的一個問題，是非常深刻的見解，那那個張老師，對，我接著董老師剛才的觀點，其實表達兩個觀點，就是合成數據，我覺得其實對於現在的大模型。

是非常重要的，我最近該再跟學生討論一個問題，就是我們現在正在做合成數據，到底是在對這個世界，或者這個信息空間在做差值，還是說有可能去做外推，也就是說這個世界其實有很多數據，有可能是一個人造的。

還有一些可能是真實的，那如果這個空間可以通過合成數據填滿，那會發生一個什麼樣的事情，還是說我們可能突破這個現有的空間，去做一些全新的東西，這個其實現在我也不知道答案是什麼，但我覺得比較有趣的就是說。

那這個到底這些空間要不要被填滿，其實剛才董老師其實就提到了，這個跟這個相關的一個觀點，所以我覺得挺好奇這個事情，就是說是不是對於所有的情況，我們都需要這麼多的數據去用，當然還有另外一個觀點。

其實現在有很多合成數據，我們看到互聯網上有很多這樣的數據，其實它帶來了一個問題，就是帶來了一個數據治理的問題，因為我們看到現在有很多這種QA的，這種社區問答上面，有很多機器生成的答案。

我們有很多合成數據被公開，但它的質量其實不一定都特別好，那隨著時間推移這些數據量，達到非常巨大的時候，如果沒有一個有效的治理方案，這些數據可能會影響我們未來模型的訓練。

甚至我們都不知道這些數據是真的還是假的，甚至我們都不知道這些數據到底是，是哪個模型產生出來的都有可能，那這些數據將來如果一旦進入到，我們虛模型的Pipeline裡邊，進入到我們這種Rack系統裡邊。

那會帶來一個比較嚴重的影響，我感覺 對，曾老師對這方面，對 我其實剛剛是沒想好，其實數據這個說起來，對大模型訓練還挺重要的，特別是數據量，所以我一直覺得也許我們，就是數據其實現在確實。

容易收集的數據會變得越來越少，因為大家已經積累，那些數據肯定是比較容易收集的，然後我覺得我們可能會到達某一個臨界點，那個臨界點會在什麼時候呢，就是當我們的模型它能夠和現實世界交互的時候。

它能自己就去創造出一些新的數據，我覺得這樣的話，可能才能為我們帶來新的數據增量，以及源源不斷的新數據，能夠讓模型根據自己和世界的交互來，不斷地實現自我的進化，我覺得這個可能才是一個比較好的長期解決方案。

是的 是的，聽了你們的非常有啟發，我感覺到就是說，一是說真的我的組裡也是，就是自從有了大模型之後，我那個標數據的費用就下降了很多，同學們都是首選先生數據，而且有的效果還是非常驚人的好。

甚至是現實中不太可能，因為隱私的關係，收集不到的數據他們也能造出來，對，那麼接下來我想問諸位一個問題就是，因為今天咱們是這個大語言模型，為咱們的標題，語言肯定是非常重要的一個模態。

但是它也只是世界的一部分，那你們認為以語言為核心的大模型，會是描述世界知識的最終模型嗎，要不請趙老師先，我先抱著隱喻，我先說一下個人的這個觀念，首先就是現在可能語言模型，可能已經可以拓展到多模態了。

然後現在可能有兩種方法，然後第一種方法相當於是，在語言模型上加上一些對齊的，已經訊號的這種Visual Encoder，然後這種是比較廉價的一個方式，核心還是借助於這個底層模型的能力。

這個我們認為可能還是非常輕便的一個方式，但我覺得這種方式本質上還是語言模型為驅動的，整個backbone全是語言模型去驅動的，那麼第二個方式就是這個，現在可能也有人叫語言生的多模態模型。

就是他會把所有模態的數據全部統一去token化，然後去衝進一個聯合的模型，可能真的可能就是這樣的一個模型，然後其實這裡我也有一些疑問，我覺得我也可以抱著和大家一起去探討，就是說比如說建模這種。

比如基礎性的這種多模態的任務，那麼你這種原生的模型是不是有一些，多模態上面的一些核心的優勢，那麼比如說，那麼我再往高說，比如說比較複雜的一些多模態的任務，它是不是這種優勢會更大。

現在可能就是大家可能還是，能夠去做出原生的多模態模型，但是對這兩個問題現在我覺得探討，還是都在bunchmark上面，就是大家還是沒有去把這個底層的，這個原生多模態的模型的優勢，能夠說清楚。

然後另外的一個，我覺得可能比較關鍵的一個問題，就是現在這種建模多模態的方式，就有可能不是特別適合有限模態，比如說像圖像啊聲音啊，儘管現在GPT-4O可能是，它可能據傳聞可能是這種。

原生的或者是怎麼樣去蠢的，但是我自己是感覺這個有可能，對於有限模態並不是很友好，但是有什麼更好的方式，我現在還是很難能想到，對，鍾老師，對然後我其實非常喜歡那種，原生的多模態，但是好像現在看起來。

第一是訓練成本也比較高，第二是好像效果也沒有說，就真的非常的突出，所以其實現在從我們的路徑上來說，我們還是先有語言模型，再有其他模態，當然這個的話我覺得從未來來看，也許也得看技術的發展。

我個人是覺得純靠語言，一種模態的信息應該是有限的，特別是比如，如果我們沒法真正的去，能夠通過視覺去看的話，我們就很難去想像一些三維的，實際空間中的那種知識，掌握那種知識，掌握那種推理的能力。

所以我覺得這個，也許未來更多模態是有必要的，但是以什麼為核心，可能後邊就不會有核心這個概念了，因為如果真是原生的多模態，真是端到端的，它可能會，我覺得可能未來真的會往這個方向走。

所以曾老師比較支持原生派，那張老師呢，我其實挺認同，剛才趙老師跟曾老師的觀點，就是這種原生的多模態模型，因為我們想像一下這個人，你從出生開始的時候，你是先睜眼看世界的，那個時候你還不會說話。

你甚至也估計也聽不太懂，這個父母那時候在說啥，慢慢的你壓下去，你學會了說話，其實我記得好像是，Nature還是Science有篇文章，是那個就是在那個小孩子頭上，戴了一個那個ProGoPro。

然後他們就相當於在模仿那個，那個其實就是一個多模態的原模型，有點像啊，那個打個比方，然後進入了大量的這種視頻的這個信息，然後去學習，但我們現在的確這個多模態的這個架構，還是包括學習心理效率。

還是跟人比還是差距很大的，但是我有個觀點，就是如果從更長遠的角度講，如果說你是說世界模型，還是用現有這個架構的話，其實資源消耗實在太龐大了，我覺得感覺還是要，很多共同的一些學者來去共同探討。

怎麼樣去未來去優化這套學習的模式，好的那東老師呢，對我還沒有一個明確的這個答案，因為就是說你看如果我們是，現在是所謂的artificial這種，human intelligence的話。

就讓模型或者讓這個算法，有這個能力的話，或者嘗試去模仿，或者是甚至遠生這種能力的話，那剛才張老師也提到這個小孩這個問題，那從某種意義上，小孩雖然不會說話，但是他可以知道他應該幹什麼。

對吧應該吃飯應該幹什麼，即使他不會說話，好像是說明語言也沒有那麼重要，但是從另一個視角，好像如果沒有語言的話，可能這個小孩或者是說，這個生物的limitation也比較，明確會放在一個困難的地方。

對吧所以我，因為既然我們是個panel，是的是的一定要有點衝突，對我就嘗試說一個，可能我們真的還是需要，或者主要靠語言來建立這個世界模型，而且是不是推理這個部分，是語言模型非常獨特的能力。

您覺得推理是不是需要在語言上去做，而不能在其他模態上去做，對這是好問題，就是我感覺好像也，我個人的感覺好像是也都可以，對吧因為你看，從咱們進化到咱們今天這個人的這個種屬來看，那個類人猿的進化角度來看。

其實語言產生，好像語言學家的定論大約是，語言只是產生於十萬年前左右，也就是說在上千萬年的這個進化到今天人這個過程當中，其實大部分時間是沒有語言的，那其實就是我們的祖先為了生存下去。

對世界的觀察對世界的理解，在整個世界當中生存交互，其實好像他也有世界模型，是但是從技術的角度，就像剛才是趙老師還是郭陽講的，就是說可能建模語言目前相對更容易，或者換句角度來講建模動態。

目前我們還沒有找到一個更好的方式，當然tokenize可能也是目前我們有的一個思路，但其實要是跟動物比的話，我們的語言確實是我們的一個優勢，是吧豐富到如此豐富的語言的時候，他可能會強一點。

就是推理或者抽象的推理，長期的，還有我可以反問一個問題嗎，其實我一直也沒有想明白，我不是不同意我只是沒想明白，我們為什麼一定需要建模世界模型，或者需要世界模型，就我們創造出來這個模型。

或者是算法一定目標是為了這個這個這個，人類智能嗎或者是，賀老師可以，我來說吧因為這個跟那個我想說的差不多，就是我是覺得知識本身是一個很虛的東西，我比如說吧我們看到這個，從樹上蘋果落下來。

那他這個本身我們看到的東西也是一個知識，那動物他不會說話他也能看到這個知識，那對於我們人來說我們有語言，我們有這個能說這個OK萬有演習定律，我這個蘋果為什麼受這個受到重力的影響。

才能夠掉下來我們有這個文字版的，所以你說前面那個東西是知識嗎，他肯定也是知識，那他對應的實際上就是世界模型，那後面這個東西呢他就在自然語言裡面，他也是知識，但我個人還是認為自然語言模型是必不可少的。

因為我覺得自然語言是知識的一個非常乾淨的一份數據，我們剛才講大模型很多的之前老師都說這個，數據質量很重要，有一個比較好的數據質量我們可以學一個非常小的model，它可以達到很好的效果。

但我覺得在知識面前語言實際上就是知識最高質量的一個數據，但是我們也知道最高質量的數據有可能它是不夠的，因為實際上存在著很多我們不知道的，沒有辦法用語言形容的，甚至都沒有寫到我們書裡面的知識。

那所以在這個時候為了去解決所有的常委的東西，我們可能還是需要世界模型，但是這些所有的東西可能都是要從語言模型，這份最乾淨的數據出發去展開的，但是語言模型怎麼和多模態建立一個比較好的聯繫。

那之前幾位老師不知道我也不知道，不知道有沒有回答東老師的問題，其他老師還對於為什麼要構建這個世界模型有補充嗎，好的好像是SORA出現的時候，大家突然非常熱議對物理世界的一個建模。

那現在我可能先稍微填一下，把這個問題留給我們的觀眾，這個機會還有15分鐘，那有沒有觀眾特別想問各位嘉賓的問題，大家可以舉手，好的，各位老師好，很榮幸有這樣一個學習的機會。

就是我想問一個關於數據質量的問題，就是剛剛很多老師都講這個數據質量很重要，就我想問一下，怎麼去判斷這個數據質量好還是不好，然後如果你知道這個數據質量不好，你怎麼去提升它的質量呢。

就是我想問這樣一個具體的問題，有沒有特定想問的老師，沒有，因為我覺得在座的都是這方面的專家，好的，那我們請要不曾老師有實際要問的，好的非常感謝，非常感謝對我的肯定，是這樣的就是什麼是好的數據。

其實如果從一個最直接定義來說，就是這個數據拿給模型訓練之後，它在評測級上表現上漲的數據，那肯定是好的，但是等訓完了再判斷它是不是好數據，這肯定是就已經太晚了嘛，其實我們更想要的是能夠通過數據。

一些其他特徵能夠和它訓練之後，在最終表現上的一個變化能夠掛鉤，而這件事的話其實就非常複雜，包括預訓練什麼是好數據，什麼是SFT的好數據，其實都是不太容易去定義的，然後在我們的實踐裡邊。

其實我們嘗試了很多規則，做了很多實驗，然後具體其實也沒有一個，什麼特別容易概括的一個觀點，就是說什麼樣數據一定就好，就有時候它有點反直覺，要不我們請趙老師也補充一下，趙老師我知道他訓練預覽的時候。

為數據編程花了很多心思，對這個問題感覺就像支付，好像好多上面都被問很多次了，我覺得它比較困難的一個問題，其實還是我最早說的那一個問題，就是說大模型的能力其實很有趣，它就跟剛才。

它跟你的數據就像小孩的食物一樣，但是說什麼食物它吃進去，可能以後等到訓完，可能是一兩個月後會有些什麼成長，這個事情現在還是很難有科學的東西，去給它搞清楚，但這個事情一旦搞清楚之後。

以後這個模型對數據的需求量，就有可能會銳減，但是現在可能還沒有到那個階段，但是現在可能比較公認，可能比較常用的方式就是，啟發式規則洗一下，然後去清量級的分類器再去洗一下，然後如果洗得再細一些。

可能很多人會用GDP4去再洗一下，但這些可能就是這個Pipeline，可能你如果看那個Falcon或者是百川，有一個論文那個圖就會越來越少，所以你原來的數據。

比你從CC裡面Common Ground裡面，你拿到的數據可能是，比如說是幾十T的，你最後一洗完可能就很少，所以現在另外的一個，很常見的一個途徑，可能很多公司都已經用了，就是改寫數據。

比如說這些數據原來質量很差，但它的內容其實還是有一些意義的，那麼這個時候可以上一些，可能功能比較強的模型，比如說像GDP4給它去重寫，那就很有可能原始的內容就留下了，但是這個形式也會變得很好。

然後另外的途徑就是說，你可以蠢一些，比如說蠢一些LAMA3，你去微調一下，讓它去重寫，因為GDP4畢竟代價還是很高的，然後這大概是，可能比較，我說的是規則性的，因為我沒在公司待過，這個是自己大概。

可能公開的一些消息去摸索到的吧，然後另外可能非常重要的就是說，這個數據，以什麼形式去呈現給模型，也是非常非常重要的，就同一批數據，如果最後它以一個什麼樣的格式，去讓這個模型去看，讓它去學。

可能也是很重要的，所以說也很常見就是說，有很多人可能會集體把這個，據訊的數據去加上一些格式標籤，或者是去進行一些特殊的格式的重排，可能也類似改寫吧，這可能大概是我知道的，謝謝張老師。

那我們現在剛才講了很多數據的問題，其實大模型這個機理，我們很多時候，我們在嘗試的時候，也還是不是很理解了解，就像剛才說數據的，也需要很多啟發式，缺乏一些理論性的工作，那我們在座的也有非常資深的。

做理論研究，做這個解釋性的，我們想問你們說，如何從工程實踐中，更好的總結出來這個規律探索本質，來推動大模型的這個發展，我們可能先請那個賀老師，就此來，因為您的主要做了一些，很重要的理論工作。

我覺得做理論，或者是做一些比較，反應的東西，在現在其實還挺難的，我覺得主要這種東西，主要可以分為兩類，第一類是一些，這種回顧性的，比如說我現在已經知道，這個東西work了，然後只不過是說。

我想知道它為什麼work，我希望知道它背後的機理是什麼，比如說OK，神經網絡它表現很好，那為什麼，比如說大圓模型，要用思維鏈為什麼，為什麼用這種in context learning，它會變好。

那這種相當於是說，我知道問題了，我甚至說，我幾乎已經知道答案了，我只是說，想讓你用一些數學，告訴我這個答案真的是對的，那這種東西的話，其實相對來說，就是就像我們考試，給你一個考題，你去做一樣。

但是這種東西可能，更缺乏一些實際上的一些，就是往，怎麼推動這個東西往前走，但如果真的是有這種，前瞻性非常強的這種理論工作，那基本上就是一個，影響力非常大的東西，比如說我能夠，記得起來的這種工作。

就是比如說GAN和瓦薩斯蘭GAN，之間你可以覺得，瓦薩斯蘭GAN是一個，很理論的東西，但是它解決了GAN裡面的一個，很多的問題，然後也引發了就是，對這種如何去度量量體，實標準之間的差別。

包括最近的像這種DPU，如果大家做大模型的同學，可能也知道OK，我原來都是用這種PPO很慢，但是我去想辦法，用這種比較快的，比較stable的辦法去做，然後這種東西只要你做出來，基本上都是一個。

就是非常非常重要的東西，但是這種東西做起來也很難，因為它解決的實際上就是，所有人都想解決的，最難受的問題，比如GAN訓練很慢，OKPPO訓練很不穩定，那我就是想辦法去解決，可能會受到的。

這個賽道可能會很捲，因為就是大家都會關心這個，然後我覺得這個是很困難的，是的我們理論工作非常的上游，一旦是做了很重要的，就可能會影響很多下游，那其他老師還有補充嗎，張老師您有什麼。

我打一個這個不一定恰當的比方，就是現在大模型的這種機理，或者理論研究，有點像以前物理那個，開普勒的那種開普勒時代，其實有點像，就是說我們會有一些數據，有一些現象，然後總結出一些經驗性的規律。

但是這個紐頓定律在哪，現在好像還，我不知道有沒有啊，現在這個，這個是個問題，包括現在很多的這種，我們發現的，比較有非常work的一些方法，是發現了這個原理，包括transformer也是。

先有了這個transformer以後，才會有人去解釋，包括理解它背後為什麼是這樣子，為什麼會有FFN，為什麼會有單線，這並不是因為基於一個理論，去造出了transformer。

而是反過來有了這個東西以後，反而去解釋這個事情，所以這個也說明了，其實背後的這個核心，最根本的fundamental的理論，我們現在還沒有，對 這個是我想補充的一點，但可能科學的發現。

也非常需要直覺是吧，可能數學家也是有一個先有直覺，再有一個理論的支撐，還有其他老師想要補充的嗎，對 其實，對 然後其實我一直也挺關注，就是這方面有沒有什麼新的理論出來，因為訓練大模型。

它畢竟也是一個成本非常高的事，如果能有理論指導，其實能讓我們更好地深入理解，大模型到底是怎麼工作的，但確實也能看出來，現在在大模型方面，其實是實驗快於理論，就是實驗已經做得非常快，已經得到一大堆結論了。

然後但是很難有對應的理論，甚至有很多，我了解到有很多，都是做出實驗之後，發現效果很好，在想為什麼很好，就這樣，對 所以其實我倒是特別想要，能有一些這樣的理論，但反正現在的話，我們還是在以一種。

實驗科學的方法去搞大模型，就是做各種實驗，然後去總結其中，理解其中的一些規律吧，剛才賀老師的工作，就給我印象特別深刻，就有時候一些理論分析完了，就可以防止我們，就幫助我們節省一些浪費的時間，是吧。

我們就不用在那個地方，再花時間去做實驗了，好的，那我們再把一個問題，留給現場觀眾，前排的那個朋友，旁邊有，對 這邊，各位老師好，想請教一個關於，AI文本生成的這種檢測的，就是一個問題。

就是說現在其實充斥很多，這種AI生成文本，它有些是對的，有些是深度偽造的，甚至有些是有害的，那麼其實區分這個，AI生成和人類的文本，它其實是一個，現在研究的一個方向，然後呢。

但是現在有一個什麼樣的問題呢，就比如說2023年，OpenAI它自己原來有一個，訓練的工具，是基於GDP2的，但是由於效果不好，它後面自己把這個項目關停了，然後就是說現在，就到目前為止，在生成和檢測。

似乎就是說，生成還是處在上風，就是檢測還沒有辦法，特別精準的把生成的這種，是AI檢測出來，那麼就是說，想請教您兩個問題，就是一是，現在有沒有什麼就是說，比較值得去做，或者值得去研究的這種，檢測的方向。

因為傳統的話，是基於這種統計概率，比如說PPL，或者說基於這種訓練，數據水印等等，它們似乎都有一些局限性，然後第二點呢，是說在未來，是不是還是會生成，一直走在這種檢測前面。

就是說當你用比較聰明的prompt，或者說用一種，生成手段的時候，就可以打破你這種檢測的方式，還是說檢測未來會走到，和生成並駕齊驅的位置，然後想請各位老師，回答一下這兩個問題，好的，關於檢測。

要不我們東老師先來，難題又拋給東老師了，這個，首先我沒有答案，你這兩個問題，我可能都沒有答案，但是，可能有一個困擾我的問題，就是說為什麼要檢測這件事，可能我沒有太想明白，因為就是說有一些。

比如說我們用AI，我們是去創造有價值，去創造好的，但是肯定就會有人，去用AI去做假的 差的，那麼就是說，在這種情況下，我們知道這個文本的鮮豔，可能是來於AI還是來於人，其實是有利於我們去判斷。

這種內容的，它內容的好壞，以及它的這種可信度，但人其實也會產生假新聞，是吧，謠言也是會產生，但是人產生假新聞，跟AI產生假新聞，它的量級是不一樣的，就是說當你，比如說我們談到這個認知慾。

談到認知慾去對抗，那麼其實這是一個大批量的，是一種就是博弈動態的，這種情境下，那畢竟生產的效率太高了，對 那麼就是說，去把這種趨勢，把AI生成這種趨勢檢測出來，對於這種整體的研判，是有些幫助的，好的。

趙老師有什麼想法嗎，對 我覺得這個問題可能，就是也可能，我覺得是比較超前的一個問題，因為我覺得這是，相當於AICC的，人工智能生成內容的一個檢測問題，我覺得至少在目前為止。

我自己不是特別看好這個topic，因為我覺得，現在至少到目前為止，還是沒有出現大規模，這種內容的一個濫用，因為它和圖片造假還不太一樣，圖片就是一上去，這個危害會很顯然，就比如說文本這段，我沒有想到。

很直接的一個損害，因為現在至少我看到的情況就是，我不知道你一常會接觸到，很多的AICC生成的文本嗎，對 在我的場景裡面就是說，我可能不能把它很詳細的，告訴大家，但是這個場景裡面，它是一個博弈的狀態。

就是說需要去做這樣的事情，我覺得可能一個更泛化的，可能因為時間關係，我就縮短我的回答，我自己覺得就是，你可以把造假的機器人，也就理解成一個人，剛才宋老師已經說了，其實人寫出來的，有損害的東西是很多的。

包括網上的，然後你機器可能也有一些造假的，沒有必要一定要把，人和機器的要給區別開來，我個人觀點，你可能比如說，你可以蠢一個這種，這種quality的classifier，我覺得可能更有用處。

或者說檢測這個假新聞，不一定是人的，還來自於機器的，這是我個人一些觀點，其實我覺得在您的觀點裡，就是它的真假，要比AI還是人生成更重要，對 因為其實現在網上的所有新聞，都是一個背後的一個人去造的。

那他有可能是真人，有可能是個機器，然後人有可能有好人也有壞人，就是你沒有辦法去控制，你得detect它出來，似乎有點用，但本質上我覺得沒有太大的幫助，好的，方便知道你是哪個公司的嗎。

我是中國航天科工二院，清零住所的，好的，其他老師還有補充嗎，您請坐 您不用站著，對 然後我也談一下，其實我覺得這個事，從技術來說，其實是挺難的，因為它和傳統的圖像信號，也不一樣，圖像信號畢竟還比較連續。

就你在裡邊搞一些小的噪音，那些沒人看得出來，但文本信號的話，要在裡邊去插入一些方法，能讓AI的這種東西，能被有效檢測出來，或者識別出來的話，其實還是挺有難度的，而且特別是像現在的AI模型。

其實它本來就是從人類大規模語料裡，去學習的語言模型，所以它說話就一定會非常像人，而且它越學得好，它就越像人，到最後就是模型大到一個程度之後，你就不應該看得出來，它到底是人還是機器。

對 然後所以說我覺得這個事，總體來說是有點困難的，但是其實現在大家能使用到的模型，在語言中往往也是有一些特徵的，這些特徵其實能讓大家知道，它是AI生成的，比如就前段時間不是有在論文裡。

發現什麼as AI assistant什麼的嗎，對，對 就這種，然後就有些特別愛用的詞，對 就這種很有AI風格的詞語，其實你也可以理解成是一種變相的水印，還有就像什麼總的來說，總之這種結尾的。

還有就是格式打得特別好的那些，看著都特別像AI，對 然後我現在因為也經常在網上，看到類似的一些東西，我都會在後面猜它到底是不是AI寫的，但總的來說就是要從技術上，就是真的去做到一個比較好的識別的話。

它難度還是挺高的，而且估計會有比較高的誤傷率，好 謝謝，好的 還有問題嗎，我們再請一位觀眾，好 請問那位女士吧，謝謝宋老師，我是環球時報的記者，我要問兩個問題，一個問題是從去年到現在，咱們大概市面上。

國內市面上大概有三百多個大模型，我們現在都說國內的大模型市場非常捲，有的人就認為現在大模型領域裡面，做的好像是百花齊放，但是小模型也就是說垂直領域裡面做的，好像是沒有說滿足市場的需求，我的問題就是說。

各位老師覺得大模型下一步要捲的話，可能捲哪個方向，是捲垂直領域呢，還是繼續在現在大模型的角度去，再有一個問題是關於中美之間的一些問題，這個問題可能比較，我們先答一個，要不然一會兒就忘了，好的 謝謝。

好 哪位老師先請，就是她說垂直領域的這個模型，其實不是很符合預期，接下來會有這方面的爆發嗎，我感覺垂直領域確實比較難，一是數據又少 是吧，然後要求又高，就是大模型還是有一點特點，就是說它比較能騙外行。

就是當你不是這個內行的時候，你問一個問題，總是覺得他說得很好，然後但是當你是內行，查你自己很熟的問題的時候，你就能看出它的漏洞，然後如果用在一個垂直領域，偏偏就是這種情況會比較多，就很關心這個領域的人。

然後還是蠻難的，要不賀老師，我不知道，因為我不太懂垂直領域的模型，但是我看最近好像教育模型挺火的，但我也不知道是談話一線，還是一個這個未來真的有可能的，因為教育模型就是像宋老師說的。

它那個題的難度沒有那麼大，可能因為它面對的，可能都是一些小學生 初中生這些，那對於預料也比較豐富，而且就是說對知識的要求，可能也沒有那麼高，不會說讓一個Domain Expert。

因為你面對的都是小學生 初中生，所以有可能沒有這種問題，但是具體它哪個垂直領域比較好，或者該怎麼落地，我其實也不太清楚，聽聽各位其他老師的意見，鐘老師和曾老師你們要答一下，曾老師請先，好的。

其實我覺得這個問題確實挺難回答的，特別是這種在垂直領域裡的模型，其實可以理解就是一個垂直領域裡的專家，然後現在大模型其實是一些比較通用的能力，比較一個就像一個接受過通識教育的人一樣。

然後怎麼讓這樣一個人能夠成為行業領域的專家，其實是現在大家都在探索的事，比較容易的想到的其實就你拿數據訊一訊，肯定是可以的，但這樣的方法的話，其實從效率上來說也沒有特別高。

所以我們現在也在去看有沒有一些其他的方法，像包括通過agent的方法，然後以及今天其實我聽了張老師的那個講了之後，我還在想能不能把一些能力怎麼就直接編輯進去，是不是就更快捷一些，鐘老師有補充嗎。

對我想一下，我感覺這個我大約從兩個維度，第一個就是說，就是說可能一方面呢，是剛才也說了是從2023年以來，其實這個大模型技術發展，或者模型本身的發展非常非常快，就是這個不好說是不是人類歷史上最快了。

但是至少是過去很長一段時間，大家可以看無論是信息技術互聯網手機等等，其實發展非常快的一個技術，在2023年這一年，所以我們現在的預期是說在這一年的時間，其實我們某種意義上可能是對它的模型本身的能力。

以及模型在垂直領域或者各方面的應用，其實set up了一個非常高的期望，其實我個人覺得這件事可能我們某種程度上，因為它發展非常快，我們某種程度上overestimate它的可能，短期內的可能性。

就是那個我想應該是Bill Gates那個講過，就是說我們其實在這種情況下，更容易overestimate短期它可能達到的效果，其實underestimate它那個長期的一個效果。

我們放在一個5年和10年甚至都不用20年的尺度，有可能大模型在各個領域的應用，可能會產生非常大的影響，然後這是第一個維度，第二個維度的話，有可能我們需要找一個example，不一定那麼好找。

但是從另一個層面來看，至少我個人能看到的一部分數據是說，包括我們自己的model as a service，那個API平台，智普的API平台，包括我們也大約了解一些友商，包括大廠雲廠商的包括微軟。

其實也release了部分數據，實際上模型的API調用的量，token產生的量是非常非常大的，然後這些用戶其實都是一些商業，甚至都不是IT，有IT有信息領域的，其實還有很多傳統行業的一些。

傳統廠商在嘗試用大模型，應用到日常的生產當中，就是說怎麼形容，就是說其實很多廠商很多行業，也在嘗試的過程中，我們可能再稍微耐心一點，給他一點時間，有可能從一個相對更長的time frame，時間片來看。

可能會有更大的一個效果，好的，你的第二個問題是，謝謝宋老師，第二個問題是外媒近期也關注到報導，有很多的報導提到，美國現在可能會針對人工智能領域的，一些技術，對中國實行封鎖，尤其是彭博社最近報導的。

就是可能要進一步限制中國獲得，用於製造尖端芯片的，全環繞山脊的晶體管技術，然後包括可能會限制高貸款內存，HBM的一個技術對中國的出口，想問一下各位老師，美國對中國的這種技術上的。

在AI領域的技術上的封鎖，會不會對咱們國內大模型研發，產生進一步的影響，然後怎麼去應對它，好的，哪位老師可以先講一下，張老師你要不要先來，那我就破端隱喻，簡單說說，我覺得影響肯定會有，首先我們看到。

比如說就以我們學校為例，現在就很難買到英偉達的卡，眾所周知的一些原因，然後包括很多國內公司，也買不到這些卡，它就會直接影響到算力的問題，但是我也知道咱們國內，像做得比較好的，像華為他們也在有一些。

這種生騰系列的卡，其實我相信我們國內很多企業，很多做芯片的公司，一直都在努力去把生態，把我們從底層的基礎設施，包括我們的訓練深度學習的框架，像國外我們現在都知道Pytorch。

國內也有一些像華為的Minusball，國內的像Pytorch，還有像我們清華這邊，還有寄圖等等框架，其實都在朝這方面努力，就是說我覺得肯定在，有一段時間我們可以有一個，完全自主的生態建立起來。

那個時候其實就不用管，美國的那些所謂的封鎖了，是，張老師還有補充嗎，沒有，好的，那我再幫大家問最後一個問題，那麼剛才也說到算力，其實大模型時代，我們知道非常重要的一個工具，就是要素就是算力。

那我們也因為身在高校，也會有這方面的一些資金，然後不如工業界，我想為各位，因為有在工業界的，有在學術界的，還有像東老師可能兩邊都有的，對，然後來逐一談一下，你們覺得在現在這個時代，工業界和學界相比。

有什麼優勢和劣勢，然後你們未來覺得，有什麼期望，讓自己所在的這個位置，可以更好的做大模型，大圓模型的研究，要不趙老師先來，好的，這個問題很難，這個問題就是，不是難回答，是難解決，因為我覺得現在可能。

整個高校最大的一個問題，就是能拿到的卡數太少了，然後所以導致的一個問題，是現在高校裡，可能就是說老師或者是學生吧，真正訓練過大模型的，實在是太有限了，因為資源就那麼一些，對，我覺得這個從長期來看。

肯定還是很不利的，因為學校裡面，可能很大的一個好處就是，我沒有什麼利益上的這個，我要做的事情，可能就是去把我的成果，去發出來，然後我沒有必要去遮掩一些東西，然後沒有必要為了KPI去做一些事情。

就是我們可以做，非常自由的一個探索，然後什麼技術，我們想公開我們就公開了，這是非常大的一個，比公司的一個優勢，就包括歐海，他們內部應該有非常非常多的，這個技術，但是他們這些人，可能永遠也沒有機會。

給他至少這一年去說出來，對，但從長遠來看，確實算力現在，基本上已經成為高校，發展大模型科研，我覺得最掣肘的一個事情，那現在也沒有特別好的一個方式，我覺得可能還是要和企業，包括算力中心。

去進行這種聯合性的一個開發，甚至我覺得是，經常會呼籲就是說，國家有沒有可能去，為高校的一些科研團隊，去配備額外的一些算力，去讓有一些，有能力去做大模型研究的人，能拿到這個算力，對，好的，那曾老師。

您的那個卡還是很充足的是吧，怎麼說呢，就是對於做大模型來說，卡永遠是不夠的，因為就是大模型，其實從目前來看，就是實驗還是很重要的，就是實驗比較偏多的話，其實我們就需要，投入很多的人去做實驗，對。

然後從目前來看，就是至少因為我現在在面壁，然後從公司這邊來說，我是覺得就是大模型的話，其實還是一個，就是科研的前沿工作，和工程化相結合的一個事情，因為其實在我們最開始做大模型，20年那段時間的時候。

就是當時國內甚至連能跑大模型的，就是那種集群都不存在，因為都沒這種需求，從我們當時從最底層的模型，真的搭起來，發現裡面有特別多工程上的問題，然後以及就是到後來，就是真的要做大模型的訓練，它的數據。

它的對齊，以及大模型相關的標註，以及怎麼我們利用Scaling Load，能批量的去跑我們的實驗，然後能夠通過我們的實驗，去更快的挖掘出大模型那些，還沒有被挖掘出的結論等等。

這些其實都是非常工程化的事情，同時大模型的研究，它其實還是處於一個非常快速的，一個在演進的狀態，所以的話其實它的前沿探索，也是非常重要的，所以我覺得其實真正要做好大模型，還是需要能夠將這種產學研。

相結合的一種形式，才能把它做好，非常好，張老師，我就簡單說兩條吧，首先一條就是感覺現在很多國內，就是學界的老師，一般都會考慮跟公司合作來做研究，這個能夠緩解卡的問題，這是一條，第二條的話。

就是如果說要學校做純這種學術的研究的話，現在大模型時代可能一些機理性的工作，可能更加適合一點，因為這個可能不太需要太多的算力，我們可能只要能夠解釋某一些現象，可能在一些小規模的模型上能夠work。

同時在一個中等規模的模型上，也能夠驗證它的結果，我覺得就已經能說明這個東西還是合理的了，非常好，董老師，我想想，首先非常支持各位老師講的，我們可能肯定是需要找到一種產學的方式。

尤其在咱們國內能夠讓更廣泛的人，咱們同學咱們實驗室咱們老師，包括跟業界一起來探索大模型的發展，但是從另一個角度來看，其實現在此時此刻大模型，當然只是我個人的觀察，就是說大模型的所謂的前沿探索。

所謂的大家都在迅模型，其實某種程度上它已經變成了，有一點像那個包雲剛老師提到那個重工業科研，其實它本質上或者說現在的本質，實際上就是工業界更擅長的一個事，工業界實際上在刷點。

在提升這個模型的performance，在一步步往前推這個模型，Empirically的推模型的這個能力的邊界，其實某種意義上，其實現在有一點像那個，大家也經常舉那個例子，就是說其實有點像那個。

我們現在就有點，業界有點像把這個萊特兄弟一樣，把飛機送上天，現在飛100米高，目標是飛101米高1000米高，但是最終如果說要把這個飛機，做成今天這個A380，什麼這個空客787。

Sorry波音787這種，可能還是需要空氣動力學，風動實驗這些更理論的東西來指導，怎麼更好的設計飛機，怎麼更好的指導訓練模型的各種，這個參數的設置，各種decision的決定。

可能更多的需要理論的來支持，所以我覺得這個學界，其實在這方面還有很大的空間，當然可能是一個delay的過程，然後緊接著這個，我其實我們也經常在討論的一個事，其實如果我們換個角度來想，怎麼來形容呢。

其實你看GPT-3是2020年年初放出來，在GPT-3上用RHF，也是2020年就放出來一個版本，然後Skilling Law，如果你看那個Paper Open，也是2020年初放出來的。

那也就是說某種程度上，無論是我們學界還是我們業界，不管國內國外，其實大家都是某種程度上是，沒有意識到這件事，其實更多的是，就讓我們大家一起來探索一種可能性，一種機制，讓我們至少如果已經有前沿的可能性。

前沿的方向的話，我們能夠一起推進，然後最後的話我想想，就是卡多這件事，你說業界，咱們國內的業界，我相信相比OpenAI、微軟、Google，還是大概率有一定的差距，然後我其實也有一個。

一直有一個懷疑的點，就是說我們自己做實驗，發現就是說，我們在1B、6B、12B等等的模型，經常會發現非常exciting的結果，比如說更好的數據，更好的方式，更好的配比，更好的參數設置等等。

但是都不用scale到更大，scale到千億的時候，我們現在能scale到的程度，實際上之前在百億，在幾十億的很多結論都不成立，empirical的結論都不成立。

那也就是說如果scale到更大的一個程度，但是我們現在又沒有機會，從我們的視角，其實也沒有機會scale到更大的一個程度，實際上就是說我們現在的很多發現，很多觀察，很多論文，很多發表。

是不是真的合理這件事，其實我覺得其實，無論是學界和業界，其實都被算力鎖在這，至少目前此時此刻的狀態，當然最後我們肯定還得充滿信心，樂觀的無論是各個生態圈，大家一起來折騰，是的，太好了，賀老師。

我記得田中書有一本書叫做圍城，然後有一句話就是，城裡面的人想出去，城外面的人想進來，我覺得現在實際上就有點像這種情況，就是工業界，剛才實際上我們看了很多，之前老師在工業界的slides裡面。

有非常非常多exciting的，各種各樣的現象，也發現了各種各樣的問題，但是作為學術界的人，實際上我們對此一無所知，因為我們並沒有過這樣的經驗，然後去做，所以如果要去想辦法。

能夠去達成一個比較好的一起推進，我覺得最好的辦法就是，把這個圍城的牆打破，能夠想辦法，讓工業界和學術界的人一起去看，一起去解決問題，只不過是說大家所採用的策略，解決的角度是不一樣的。

只有這樣才能夠最好的，推進整個的東西往前走，因為我想到open AI裡面，實際上有很多很多做理論的人，包括各種各樣的數學背景的人，也有很多編程背景的人，大家都是一起去推進的，只有這樣的話。

才能把一個東西做到極致，非常好，所以說到算力，儘管是一個很沉重的話題，大家還是看到了希望，那麼到最後呢，除了這個扎心的話題，我再想一個比較樂觀的結尾給大家，所以每位老師能不能暢想一下。

假如你沒有算力的限制，你有無限的卡，你這一年或者說你未來，最想做的是什麼topic，也給在座的各位觀眾有一些啟發，趙老師要不請你先，我的話我還是希望就是說，比如說如果真的有無限的卡。

能不能訓練出一個商業水平的大模型，因為學校裡面的算力確實比較有限，如果是真的放開，那你算力到了，能不能達到商業的水平，還是想了解裡面的秘密，對其實我一直有個好奇的點，你看scaling law。

它是一條非常直的線，我一直在想這個線的盡頭是什麼，如果我們真的到達了盡頭，它會得到一個什麼樣的模型，我其實對這個特別好奇，如果真的無限都算力，我估計會去盡頭看一看。

scaling law的盡頭是不是鐵領，是吧，張老師請，我其實挺期待這個，如果有這麼多卡的話，能不能真的把transformer，變成像transformer一樣的這種能力，因為我們其實做很多。

不管是記憶體分析也好，完全沒有辦法去做，100B以上的這種實驗，甚至這些模型開源的也很少，這種真正的能力很強大的很多能力，可能是跟一些小模型的機制，可能是有點不太一樣的，它這個背後的原理又是什麼。

如何去真的把這些模型的背後的這種，底層的原理給挖掘出來，我覺得我挺想研究研究的，還是好奇，東老師請，有更多的算力，其實這個假設性的問題，我們也經常問我們團隊自己的人，如果突然給我們十萬張卡我們幹啥。

我可能沒有一個，無論是一個特別的想法吧，其實可能更多的是，如果我真的有十萬張百萬張的卡，我們可能更多的是，讓我們team裡的這些有想法，有創造力的同學，有活力有精力的同學，讓他們的人均卡量上來。

我感覺自然就會有好的結果，好的一個好的環境，如果我有非常非常多的卡，那個時候一定是，我老婆早上起來的時候給我一個嘴巴，說醒醒別做夢了，該去上課了，太幽默了賀老師，那我們今天的論壇就到此結束。

謝謝各位堅持到最後，謝謝大家，謝謝。
# 2024北京智源大会-大语言模型 - P8：圆桌讨论 - 智源社区 - BV1zE421N7UJ

啊首先啊我想问各位嘉宾呃，就是在因为各位都是做啊大模型的，那么大模型的能力呢，我们也看到它呈现出非常明显的代际差，比如说我们看到GPT3，G p3。5，G p4，以及我们非常期待的未来的GPT5。

大家都猜测说每一代的能力也现在已经看到的，包括猜测都发现它们相差是很大的，那么想为各位老师嗯，你们觉得是什么关键的要素，可以产生这样的提升，要不啊有请赵老师先说，请嘉宾先生，好的好的，那曾老师先说吧。

啊非常感谢啊，就是其实我今天在我的那个PPT里，也放了一张和sky law有点相关的图啊，然后那那个图其实大家仔细看的话，我觉得它的大模型发展的奥秘，基本上都藏在其中啊，为什么呃。

就是模型代际之间会带就会有巨大的效果差异，其实它也是来源于skin law，就是我们去看那个图啊，它有两个轴，一个是横轴，一个纵轴，两个轴都是取了对数之后，然后他的那个表现是呈一条依次曲线。

然后这样一个就是因为它满足这样的关系，所以当我们对我们的训练算法，对模型的就是各种呃理就是理解加深之后，我们能够把那个曲线它就相当于平移一下，往下平移一下，这样它带来的提升也是指数级的提升。

所以这样的一种性质带来了就不同代际之间，模型架构能够有，那模型效果能够有一个非常明显的变化，同时就是包括我们做mini c p m，为什么能够战胜自身几倍的模型，而不是比自身多多少B参数的模型啊。

其实也是因为这个原理嗯，所以曾老师觉得啊是skin law啊，这个这个优势，然后他什么也不用做，就可以有这样的代际差，那不知道其他老师有没有不同的意见，东老师也是真正参与训练模型。

大模型skin law也在你的那个talk里多次被提到，你觉得除了这个还有什么呃关键的要素吗，嗯呃我觉得skin love，首先肯定是非常fundamental的一个呃factor，或者甚至是最重要的。

有可能是大概率是最重要的一个factor，然后除此之外的话，其实今年很多那个报告也提到，其实呃无论是GPT还是我们我们自己的模型，咱们国内其他的团队的模型，其实大家也可以看看到。

从2023~20到今年2024，这一年多的时间，其实大家都推出了好几代，其实大家如果看各自的模型，其实应该是国洋提到，好像是说就包括拉玛自己也是对吧，其实就看各自一个模型，family之内的话。

看呃同样的size的话，同样的computer的情况下，其实模型的效果也有很大的提升，其实很大程度上，可能那个主要的变量还是那个数据质量，或者数据的多样性，或者数据的配比方面的一些探索。

然后呃除此之外的话，我猜可能还有其他元素，可能我我们贺老师或者其他老师，可以再对其他老师有补充吗，对东老师提到也非常重要，数据对我要不我简要补充一下呃，其实我以前也简单短暂的在工业界工作过嗯。

我个人觉得还有一个因素，其实是其实整个大模型，因为这几个模型都是闭源模型啊，我们先不考虑开源的模型，BI模型其实背后它其实是个系统工程，我我理解就是说，其实它背后到底是从我们用户query进去。

到返回输出，整个过程我们是不知道的，它背后到底是一个模型在工作，还是甚至有多个模型在工作，我们也不知道，我觉得它是个系统工程，就是说它很可能为了考虑一些安全因素，甚至他也可能会收集一些用户的数据等等。

它会有各种各样的机制，包括有一些啊敏感的信息进去以后，他肯定是有一些策略去做一些处理的啊，然后我们看到有些非常好的结果啊，到底是一个模型出来的，还是多个模型一起来做一些啊处理的等等。

我觉得这是个背后是个很复杂的系统工程，呃，所以说这也是我们现在不知道一些，那个像open AI等等，甚至很多模型效果这么好的，可能是一个因素之一对，但不知道曾老师和冬老师，后面是一个模型还是几个模型呃。

我们是开源的啊，开源纸嗯，明白透明的呵呵，我们是呃很多是开源的，这个非常明确，比如说我们的6B模型，从一代二代到三代，其实呃基本上呃从架构，从参数量，如果fix那个computer的话，其实也能看出来。

然后呃背后的那个system其实也是那个语言，Part，也是一个模型，对，非常感谢，那贺老师有没有什么补充的，这块我是真不懂，因为真的没有接触过，但是我觉得可能数据量和数据质量。

肯定是两个最关键的因素之一对，然后我觉得数据质量方面，可能除了预训练的数据质量以外，可能同样比较重要的，也是by qing时的数据质量，比如说如果做一些RLHF，那显然一些非常高质量的训练数据。

肯定会对你模型最终的效果，有着一个非常重要的影响，嗯没错，那如果是提到数据的话，嗯大家有一个担心，就是大模型现在已经啊吃下了这么多的数据，又速度这么快，那如果现在产生数据的数量，速度没有超过这个大模型。

这个训练的吃数据的速度，会不会有一天这种数据会成为一个发展的瓶颈，不知道各位怎么想，好的，曾老师能不能换个顺序，可以可以要不这个我我先来回答，好的，赵老师，你先呃刚刚可能那个可能我我也接宋老师。

那问题可能两个问题，第一个就是怎么去看待这个模型进展呃，我觉得这个其实很有趣的一个事情，就是呃大家可以去考虑，就是就是比如说人类的保健的这个学科，就是比如说人吃什么东西会成长。

或者是人成长需要什么维生素，这个其实要到古代那个时间，大家可能完全是搞不清楚，我觉得可能大模型训练呃，在数据这个方面和这个可能有一个类比，就是现在大家可能准备好多数据，然后去训练，但是就是在早期。

人们可能完全搞不清楚什么样的数据，会出什么样的能力，但我觉得大概到现在这个情况，可能很多大厂，包括可能在座的很很多老师已经大概会知道，比如说什么样的数据，可能会出什么样的能力，就像你吃了什么样的东西。

然后你可能呃比如缺锌或者缺钙，可以很快的去补上，对我觉得这是非常有趣的一个呃一个事情啊，然后我自己觉得可能现在像3。5，像四甚至五，就数据量和skating肯定很重要，但是对于这个的深刻理解。

可能也是呃非常非常重要的，对，就比如说有一些能力就很难去提升，比如说像推理能力，还有一些比如说数算数的计算能力，那么这些靠什么数据吃这个什么样的数据，去把它给补充上来。

我觉得这是很很关键的一个呃一个一个问题嗯，然后我觉得这个东西都得随着时间尝试啊，然后去包括一些科学探索才能慢慢摸清楚，然后第二个可能问题也比较有有趣一点，就是说现有的数据是不是够支撑。

现在去做这样的一个呃一个一个事情啊，首先我我我觉得可能可能很多这种就是超级，就我们这我称为超级公司，因为他有卡太多了，资源也很多，我觉得他们可能考虑的数据呃，能比我们想象的可能还是多很多的。

所以我觉得他们至少现在，像就是GBT5这个级别啊，我自己推测，可能数据还没有成为它现在的一个瓶颈，因为他们可能有多种的，比如说私有数据，比如说多媒体数据转文本数据，然后可能还有很多源去获得数据嗯。

但如果再往后走，我觉得很有可能，数据会成为一个很大的一个局限嗯，一个一个限制点，然后这是一个方面，另外一个方面就是呃，现在可能现有的数据未必是最好的，一个这个大模型的一个实物啊。

然后可能现在已经有很多还工作开始做了，包括我们自己开始做的就是这种合成数据啊，现在合成数据有的时候，对于特定能力的激发是非常非常明显的，对可能是我个人的一些观点嗯，太好了，所以食物不光有天然的。

还有人工的人造的食物，对好，那贺老师这方面有什么呃，我觉得数据来看的话，现在其实一个趋势，就是用一些人造的数据来做呃，而且实际上从我们人的学习过程中来看，是人造数据也是非常重要的。

因为我们可以看我们所有的考试题，某种意象实际上都是人造的，因为知识本身是一个非常泛的东西，那我们OK在学校的时候，会把知识抽象成很多门课，然后在每门课上又把知识抽象成很多个知识点，而你所谓的考试的卷子。

实际上就是这些知识点的某种有机的呃，这种整合起来，所以如果采用这种和人类学习差不多的，这样的办法去生成数据，有可能能够突破这种数据的这种界限，同时呢也让模型学到一些更具有泛化的，这样的一个过程。

好的东老师有补充吗，呃我想想这个问题，我感觉我的回答会比较乱啊，就我我感觉呃几个维度，第一个呃我想想怎么形容，就是说呃，我们其实现在如果只讨论语言模型的话，我们现在用到的数据。

实际上某种意义上就是互联网或者计算机，过去三四十年呃，这个通过这个电子化的方式呃，把这个我们的人类很多语言记录下来了，在互联网上积累或积累记录下来的，甚至包括把我们这过去30年互联网之前的，千年的的。

无论是古籍啊，各种历史啊，这个积累啊，其实电子化了对吧，我们现在用的其实语言数据大部分是这块，但是从呃我诶我我有点不记得是哪个统计，好像是大约是有个统计是说互联网上呃，现存的电子化的数据。

其实只占我们人类产生当下产生语言，或者产生这个文本，所谓的这个text的大约1%到5%之间，我我不太确定具体那个数字对吧，也就是说实际上如果从这个角度，我们理论上可用的数据还有无限多。

理论上也没有叫无限多吧，至少还有20倍到100倍的一个空间，当然这个东西怎么将它电子化，怎么让这个模型或者是算力呃，consumer可能是一个比较难的问题，然后从从另一个视角的话呃。

就是刚才也提到了合成数据，其实其实比如说我们呃在做那个把这个呃模型，这个context length，由128可以推到email lion的时候，email on token的时候。

其实也面临着关于数据，当下非常实在的数据缺失的，一或者是缺少的一个问题，就是说比如说在预训练阶段，我们想把这个context ten，即使我们算力上计算上可以推到支持EMAI，在这个前提下。

它其实我们目前，我们至少我们team能够access到的预训练数据，积累的预训练数据其实超过EMILLION，这种token的数据其实只占呃，从条数的角度，instance角度可能也只有1万条。

所以某种程度上呃，我们也不得不利用已有的数据，利用已有的模型做很多合成数据的这个尝试，来提供给这个模型做预训练，其实我就以这个这个超长文本为例呃，其实我们某种程度上也在做这个呃合成数据呃。

然后呃然后还回到刚才那个第一个点，其实就是说我我我我我们一直也在呃，部分我们团队部分同学，还有我自己其实一直在想一个问题，就是你看呃，就是说我们这个大模型到底是要学推理，还是要存知识还是boss。

就是说如果仅仅是推理的话，我我我感觉某种意义上是说呃，数据我们可能并不需要无限的数据，帮我们提升模型的这个推理能力对吧，就是这当然这只是个假设，我大概率我我的一个猜测就是如果是存知识。

那自然是你有新的数据来，新的知识来，他要尝试把它存下来，但如果单纯的这个这个让模型，提升它的推理能力，是不是，我们一定是需要无限的数据，来提升它的这个推理能力，其实我我我们也没有想明白。

或者没有验证明白的一点，就是说比如说我们自己的模型呃，三代四代，一代二代到三代四代，在同样的computer，同样的model参数下呃，这个用更越来越高质量的数据模型的无。

就是以这个benchmark衡量出来，这个推理能力是越来越强了，就这个过程当中，其实到底我们这个数据，这个质量优化的极限在哪里对吧，是不是真的需要海量数据，其实是一个开放的问题，对。

也是我们团队也也一直在想验证和回答的，一个问题，是是非常深刻的见解，那那个呃张老师对我记着东老师刚才的观点啊，其实表达两个观点，就是嗯合成数据，我觉得其实对于现代的大模型是非常重要的。

嗯我最近该在跟学生讨论一个问题，就是我们现在正在做合成数据，到底是在对这个世界，或者这个信息空间在做差值呢，还是说有可能去做外推啊，也就是说这个世界其实有很多数据啊，有可能有可能是一个人造的。

还有一些可能是真实的，那这个如果这个空间可以通过合成数据填满，那会发生一个什么样事情，还是说我们可能突破这个现有的空间，去做一些全新的东西啊，这个其实现在我也不知道答案是什么。

但但我觉得比较有趣的就是说，那这个到底这些空间要不要被填满，其实刚东老师其实就提到了，这个跟这个相关的一个观点，所以我觉得挺好奇这个事情，就是说是不是对于所有的情况，我们都需要这么多的数据去去去用。

当然还有另外一个观点啊，呃其实现在有很多合成数据，我们看到互联网上有很多这样的数据啊，其实它带来了一个问题嗯，就是带来了一个数据治理的问题啊，因为我们看到现在有很多这种QA的这种呃。

社区问答上面有很多机器生成的答案啊，我们有很多合成数据被公开，但它的质量其实不一定都特别好，那随着时间推移，这些数据量达到非常巨大的时候，如果没有一个有效的治理方案啊。

这些数据可能会影响我们未来模型的训练啊，甚至我们都不知道这些数据是真的还是假的，甚至我们都不知道这些数据到底是是，是那个是哪个模型产生出来的，都有可能，那那个这些数据。

将来如果一旦进入到我们训模型的pipeline里边，进入进入到我们这种rag系统里边，那会带来一个比较严重的影响，我感觉对宗老师对这方面呃，对我其实刚是没想好，哈哈呃，其实数据这个说。

说起来对大模型训练还挺重要的，特别数据量，所以我一直觉得呃也许我们就是呃数据，其实现在确实能容易收集的数据，会变得越来越少嘛，因为大家已经积累数，那些数据肯定是比较容易收集的啊。

然后我觉得我们可能会到达某一个临界点，那个临界点会在什么时候呢，就是当我们的模型，它能够和现实世界交互的时候，它能自己就去创造出一些新的数据，我觉得这样的话，可能才能为我们带来新的数据增量。

以及源源不断的新数据，能够让模型根据自己和世界的交互来，不断地实现自我的进化，我觉得这个可能才才是一个，比较好的长期解决方案，是的是的，听了你们的非常有启发啊，让我感觉到就是说一是说真的我的组里也是呃。

就是自从有了大模型之后，我那个标数据的那个费用就下降了很多，有同学们都是首选先声数据，然后而且有的效果还是非常惊人的好，甚至是现实中不太可能因为隐私的关系，收集不到的数据，他们也能造出来。

对那么接下来我想嗯问诸位一个问题，就是呃因为今天咱们是这个大语言模型啊，为这个咱们的标题语言肯定是啊，这个是非常重要的一个模态，但是它也只是世界的一部分，那你们认为啊，以语言为核心的大模型。

会是描述世界知识的最终模型吗，要不请赵老师先我我这个我先我先抛砖引玉，我先说一下个人的这个呃这个这个观点吧，对呃，首先就是呃，现在可能语言模型可能已经可以，拓展到多模态了，然后先铺垫一些context。

然后现在可能有两种方法，然后第一种方法相当于是这个呃，在语言模型上进呃，加上一些对齐的，已经训好的这种呃vial encoder啊，然后这种是比较廉价的一个方式，核心还是借助于这个呃底层模型的那个能呃。

那个能力啊，这个我们认为可能还是非常轻便的一个，一个方式，但我觉得这种方式，本质上还是语言模型为驱动的啊，整个backbone全是语言模型为驱动的，那么第二个方式就是这个呃。

现在可能也有人叫原生的多模态模型，就是他会把这个所有模态的数据，全部统一去token化，然后去TRA这个一个联合的一个呃一个模型，可能可能germany ally，可能就是这样的一个呃一个一个模型对。

然后其实这里我也有一些疑问，我觉得我也可以呃抛出来和大家一起去探讨，就是说呃比如说建模这种呃，比如基础性的这种动态的任务，那么你这种原生的模型，是不是有一些是多模态上面的，一些核心的优势啊。

那么比如说那么再往高说，比如说比较复杂的一些多动态的任务，它是不是这种优势会更大，现在可能就是大家可能还是呃能够去做出，原生的多动态模型，但是对这两个问题，现在我觉得探讨还是都在benchmark上面。

就是大家还是没有去把这个底层的这个原生，多动态的模型，这个优势呃能够说清楚啊，然后呃另外的一个，我觉得可能比较关键的一个问题，就是现在这种建模多模态的方式，就有可能不是特别适合有些模态啊。

比如说像呃图像啊，声音啊，尽管现在GPTS可能是它它它可能就据传嘛，可能是这种原声的或者是怎么样去称的，但是呃我自己是感觉，这个有可能对有些摩擦并不是很友好，但是有什么更好的方式。

我现在还是很难能想到对是的，曾老师嗯对，然后我其实我，我其实非常喜欢那种原声的动作态，但是好像现在看起来第一是训练成本也比较高，第二是好像效果也没有说，就真的非常的突出，所以其实现在从我们的路径上来说。

我们还是先有语言模型，再有其他模态啊，当然这个话我觉得从未来来看，也许也得看技术的发展，我个人是觉得纯靠语言，一种模态的信息应该是有限的，特别是比如呃如果我们没法真正的去感。

就能能能够通过去视觉去看的话，我们就很难去想象一些三维的，一些实际空间中的一些些，就那那种知识掌握那种知识，掌握那种推理的能力，所以我觉得这个也许未来更多模态是有必要的，但是以什么为核心。

可能后边就不会有核心的概念了，因为如果真是原生动模态，就是真是端到端的啊，他可能会我觉得可能未来真的会往这个方向走，所以曾老师比较支持原声派，哈哈对，那张老师呢，对我其实挺认同刚才赵老师跟曾老师观点啊。

就是这种原生的多模态模型嗯，因为我们想象一下这个人你从出生开始的时候，你是先睁眼看世界的对吧，那个时候你还不会说话，你甚至也估计也听不太懂，这个父母那时候在说啥，慢慢的你牙牙学语，学会了说话。

其实呃我记得好像是nature还是science，有篇文章是那个就是在那个小孩子头上，戴了一个那个那个那个那个pro gopro，然后他们就相当于在模仿那个那个，其实就是一个多模态的语言模型，有点像啊。

那个打个比方，然后尽量进入了大量的这种视频的这个信息，然后去学习，但我们现在的确这个多模态的这个架构，还是嗯包括学习稀有效率，还让跟跟人比还是差距很大的，呃但是我有个观点就是如果从更长远的角度讲。

如果说你是说世界模型，还是用现有这个架构的话，其实资源消耗实在是太庞大了，我觉得感觉还是要嗯很多共同的一些学者，来去共同探讨，怎么样去未来去优化这套学习的模式，对好的那东老师呢。

对我我还没有一个明确的这个答案，因为呃，就是说你看呃，如果如果我们是现在是是所谓的artificial，这种human intelligence的话，呃就让模型或者让这个算法有这个能力的话。

或者尝试去模仿，或者是甚至原生这种能力的话，那刚刚才张老师也提到这个小孩这个问题，那那那从某种意义上，小孩虽然不会说话，但是他可以知道他应该干什么对吧，应该吃饭应该干什么，即使他不会说话呃。

好像是说明语言也没有那么重要，但是从另一个视角呃，好像如果没有语言的话，可能这个这个这个小孩，或者是说这个生物的那个limitation也比较举，比明确会棒的，在一个一个困难一个地方对吧。

所以所以我我因为既然我们是个panel，我就是的是的，一定要有点冲突，对我就尝试，除了一个，可能我们真的还是需要，或者主要靠语言来建立这个呃世界模型，对对对嗯，而且是不是推理。

这个部分就是语言模型非常独特的这个啊能力，您觉得推理是不是需要在语言上去做，而不能在其他模台上去做，对这是好问题，就是我感觉好像也我个人的感觉，好像是也也都可以对吧，因为因为你看从从咱们进化到咱们今天。

这个人的这个总数来看，那个那个类人猿的进化角度来看，其实语言产生，好像语言学家的定论，大约是语言只是产生于10万年前左右，也就说在几上千万年的这个进化，到今天人这个过程当中，其实大部分时间是没有语言的。

那那其实就是我们的祖先为了生存下去，对世界的观察，对世界的理解在在整个世界当中生存交互，其实好像它也有世界模型，是对对是，但是从技术的角度，就像刚才是赵老川，是郭阳讲的。

就是说可能呃建模语言目前相对更容易些，或者换句角度来讲，建模多模态，目前我们还没有找到一个呃更好的方式，当然token nize，可能也也也是目前我们有的一个思路是，但其实要是跟动物比的话。

我们的语言确实是我们的一个优势是吧，嗯丰富到如此的啊，丰富的语言的时候，他可能会强一点，就是推理或者抽象的推理，长期的嗯，诶还有我可以反问一个问题吗，其实我一直也没有想明白，我不是不同意。

我只是没想明白，我们为什么一定需要建模世界模型，或者需要世界模型，就我们创造出来这个模型或者是算法，一定目标是为了这个这个这个这个人类智能吗，或者是对贺老师可以对我我来说吧。

因为这个跟那个我想说的差不多，就是我是觉得知识本身是一个很虚的东西，我比如说吧我们看到这个呃从树上苹果落下来，那它这个本身我们看到的东西也是一个知识，那动物它不会说话，它也能看到这个知识。

那对于我们人来说，我们有语言，我们有这个能说这个OK万有引力定律，我这个苹果为什么说这个受到重力的影响，才能够掉下来，我们有这个文字版的，所以你说前面那个东西是知识吗，它肯定也是知识。

那它对应的实际上就是世界模型，那后面这个东西呢它就在自然语言里面，它也是知识，但我个人还是认为自然语言模型是必不可少的，因为我觉得自然语言是知识的一个，非常干净的一份数据，我们刚才讲大模型。

很多的之前的老师都说这个数据质量很重要，OK有一个比较好的数据质量，我们可以学一个非常小的model，它可以达到很好的效果，但我觉得在知识面前，语言实际上就是知识最高质量的一个数据，但是我们也知道。

最高质量的数据有可能它是不够的，因为世界上存在着很多我们不知道的，没有用办法用语言形容的，甚至都没有写到我们书里面的知识，那所以在这个时候，为了去解决所有的长尾的东西，我们可能还是需要世界模型。

但是这些所有的东西可能都是要从语言模型，这份最干净的数据出发去展开的，但是语言模型怎么和多模态建立一个，比较好的联系，那之前几位老师不知道，我也不知道对，不知道有没有回答东老师的问题，还需要其他老师。

还对于这个为什么要构建这个世界模型，有补充吗，好的好像是SARA出现的时候，大家突然非常热议这个呵呵，对物理世界的一个建模，嗯那现在我可能先啊稍微填一下，把这个啊问题留给我们的观众。

这个机会还有15分钟，那有没有是呃观众特别想问各位嘉宾的问题，大家可以举手，好的，已经有了是，好各位各位老师好，那个嗯很荣幸有这样一个学习的机会，就是我想问一个关于数据质量的一个问题。

就是刚刚很多老师都讲这个数据质量很重要，就我想问一下，怎么去判断这个数据质量好还是不好，然后呢就是说如果你知道这个数据质量不好，你怎么去提升它的质量呢，就是我想问这样一个，具体有没有特定想问的老师。

嗯没有，因为我觉得在座的都是这方面的专家，好的啊，对那我们请要不曾老师有实际嗯，好的好的嗯，非常感谢啊哈哈，非常感谢对我的肯定啊，呃是这样的，就是呃什么是好的数据，其实如果从一个最直接定义来说。

就是呃这个数据拿给模型训练之后，它在评测级上表现上涨了的数据，那肯定都是好的啊，但是呃等训完了再判断它是不是好数据，这个肯定是就就已经太晚了嘛对吧，其实我们更想要的是，能够通过数据一些其他特征。

能够和他训练之后，在最终表现上的一个变化能够挂钩，而这件事的话其实就非常复杂，包括预训练什么是好数据，什么是SFT的好数据，其实都是呃不太不太容易去定义的啊，然后在我们的实践里边。

其实我们尝试了很多规则，做了很多实验，然后但但具体其实也没有一个是什么，特别容易概括的一个观点，就说什么样数据一定就好，就有时候他有点反直觉，好的，要不我们请赵老师也补充一下，赵老师。

我知道他训练玉兰的时候，为树毕业花了很多心思，对这个这个问题感觉就像知乎，还像好多上面都被问过很多次了，嗯我觉得他比较困难的一个问题，其实还是我最早说的那一个问题，就是说呃大模型的能力其实很有趣。

他就跟刚才给我，就他跟那个你的数据，就像他这个小孩的食物一样嗯，但是说什么食物它吃进去可能以后等到训完，可能是111两个月后会有些什么成长，这个事情现在还是很难有科学的东西去去，去给他搞清楚啊。

但这个事情一旦去搞清楚之后，呃，以后这个模型对数据的需求量，就有可能会锐减啊，但现在可能还没有到那个阶段，但现在可能比较公认，可能比较常用的方式就是呃启发式规则洗一下。

然后去轻量级的V那个那个分类器再去洗一下，然后如果洗的再细一些，可能很多人会用GBT4去再洗一下啊，但这些可能就是这个pipeline，可能你如果看那个falcon，或者是百川那个有一个论文。

那个图就会越来越少，所以你原来的数据比你你你从CC里面，common crowd里面，你拿到的数据可能是比如说是几10T的，你最后一洗完可能就很少对，所以现在另外的一个很常见的一个途径。

可能很多公司都已经用了，就是改写数据啊，有些数据原来质量很差，但它的内容其实还还是有有一些意义的，那么这个时候可以上一些可能，功能比较强的模型，比如说像GBG4给它去重写。

那就很很有可能原始的内容就留下了，这但是这个形式也会变得很好，然后另外的途径就是说这个你可以顺一些，比如说称一些拉玛三嗯，你去微调一下，让他去重写，因为GPG4毕竟那个接代价还是还是很高的，对，然后嗯。

然后这大概是可能比较就是我说的是规则性的，因为我我没在公司待过，这，这个是是就是自己大概可能公开的一些消息，去摸索到的吧，然后另外可能非常重要的，就是说这个数据以什么形式去呈现给模型呃。

也是呃非常非常重要的，就同一批数据，如果最后他以一个什么样的格式，去让这个模型去看，让他去学嗯，可能也是很重要的，所以说也很常见，就是说有很多人可能会集体把这个预训练数据，去加上一些呃格式标签。

或者是去进行一些特殊的这种格式的重排，可能也类似改写吧，对这可能大概是我知道的嗯好的，谢谢张老师，那我们现在刚才讲了很多数据的问题，其实大模型这个机理啊，我们很多时候我们在尝试的时候。

也还是不是很理解了解啊，就像刚才说数据的也需要很多启发式，缺乏一些理论性的工作啊，那我们在座的也有非常啊资深的做理论研究，做这个解释性的，我们想问你们说，如何从工程实践中更好地总结出来这个规律，探索呃。

本质来推动大模型的这个发展，我们可能先请那个贺老师就此来啊，因为您的主要做了一些很重要的理论工作，对我我觉得做理论或者是做一些比较，fundamental的东西，在现在其实还挺难的。

我我觉得主要这种东西主要可以分为两类，第一类是一些这种回顾性的，比如说我现在已经知道这个东西work了，然后只不过是说我想知道他为什么work，我希望知道它背后的机理是什么，比如说K神经网络他表现很好。

那为什么比如说大圆模型要用思维链，为什么为什么用这种in context learning，它会变好，那这种相当于是说我知道问题了，我甚至说我几乎已经知道答案了，我只是说想让你用一些数学告诉我。

这个答案真的是对的，那这种东西的话，其实相对来说就是就像我们考试，知道给你一个考题，你去做一样，但是这种东西可能更缺乏一些，实际上的一些就是往提，怎么推动这个东西往前走。

但如果真的是有这种前瞻性非常强的，这种理论工作，那基本上就是一个影响力非常大的东西，比如说我能够记得起来的这种工作，就是比如说gun和瓦萨斯坦干之间，你可以觉得马萨自然概是一个很理论的东西。

但是它解决了干里面的一个很多的问题，然后也引发了就是对这种如何去度量，两个distribution之间的差别，包括最近的像这种DPU，如果大家做大模型呢，同学可能也知道，OK我原来都是用这种PPO很慢。

但是我去想办法用这种比较快的，比较stable的办法去做，然后这种东西只要你做出来，基本上都是一个就是非常非常重要的东西，但是这种东西做起来也很难，因为它解决的实际上就是所有人都想解决的，最难受的问题。

比如干训练很慢，KPPO训练很不稳定，那我就是想办法去解决嗯，可能会受到的，就这个赛道可能会很卷，因为就是大家都会关心这个，然后我觉得这个是很困难的，对是的，我们理论工作非常的上游，一旦是做了很重要的。

就可能会影响很多下游，那其他老师还有补充吗，张老师，您有什么对我打一个这个不一定恰当的，比方啊，就是现代大模型的这种机理或者理论研究，有点像以前物理那个开普勒的那种，开普勒时代其实有点像。

就是说我们会有一些数据，有一些现象，然后总结出一些经验性的规律，但是这个牛顿定律在哪，现在好像还我不知道有没有啊，现在这个嗯这个是个问题，包括现在很多的这种，我们发现的比较有非常work的一些方法。

是发现了这个这个原理，包括transformer，也是先先有了这个transformer以后，才会有人去解释，包括理解它背后为什么是这样子，为什么会有FIN，为什么会有TENTION。

这并不是因为基于一个理论去造出了，Transformer，而是反过来有了这个东西以后，反而去解释这个事情，所以这个也就说明了，其实背后的这个核心最根本的fundamental的理论，我们现在还没有对。

这个这个是我就我想补充的一点对，但可能他科学的发现也是非常需要直觉是吧，就是是的是的，可能数学家也是有一个先有直觉，再有一个呃理论的支撑，还有其他老师想要补充的吗，呃对其实对，然后其实我我一直也挺关注。

就是这方面有没有什么新的理论出来的，因为训练大模型，它毕竟也是一个呃成本非常高的事嘛，如果能有理论指导，其实能让我们更好的深入理解，大模型到底是怎么工作的，但确实也能看出来。

现在在大模型方面其实是实验快于理论，就是实验已经做的非常快，已经得到一大堆结论了，然后但是很难有对应的理论，甚至很有很多，就我我我了解到有很多都是做出实验之后，发现效果很好，在想为什么很好啊，就这样对。

所以其实我我我倒是特别想要，能有一些这样的理论啊，但反正现在的话，我们还是在以一种实验科学的方法去搞大模型，就是做各种实验，然后去总结其中，理解其中的一些规律吧，没错刚才贺老师的工作就给我印象特别深刻。

就有时候一些理论分析完了，就可以防止我们，就帮助我们节省一些浪费的时间是吧，我们就不用在那个地方再花时间去做实验了，对好的，那现场我们再把一个问题留给现场观众啊，前排的那个朋友嗯。

旁边有对这边呃各位老师好，想请教一个关于这个AI文本生成的这种检测的，就是一个问题，就是说现在其实充斥着很多这种AI生成文本，它有些是对的，有些是深度伪造的，甚至有些是有害的。

那么其实区分这个AI生成和人类的文本，它其实是一个现在研究的对于一个方向，然后呢，但是现在有一个什么样的问题呢，就比如说2023年open AI，它自己原来有一个训练的工具，是基于g p t two的。

但是由于效果不好，他后面自己把这个项目关停了，然后就是说现在是呃，就到目前为止，在生成和检测似乎就是说生成还是处在上风，就是检测还没有办法特别精准的，把生成的这种是AI检测出来。

那么就是说想请教您两个问题，就是一是呃现在有没有什么，就是说比较值得去做或者值得去研究的，这种检测的方向，因为传统的话是基于这种统计概率，比如说PPL，或者说基于这种训练数据水印等等。

他们似乎都有一些局限性，然后第二点呢是说在未来是不是还是会生成，一直走在这种检测前面，就是说你当你用比较聪明的prompt，或者说用一种呃生成手段的时候，就可以打破你这种检测的方式。

还是说检测未来会走到和生成并驾齐驱的位置，然后想请各位老师就是回答一下这两个问题，好的，关于检测，要不我们冬老师先来，难题又抛给董老师了，没有没有这个呃，我嗯首先我我没有答案。

你这两个问题我可能都没有答案呃，但是呃可能可能有一个我困扰我的问题，就是说为什么要检测这件事，可能我没有太想明白，因为就是说有一些就像我们比如说用AI，我们是去创造有价值，去创造好的。

但是肯定就会有人去用AI去做假的差的，那么就是说在这种情况下，我们知道这个文本的鲜艳，可能是来于AI还是来于人，其实是有利于去我们去判断这种内容的，就是判断它内容的好坏，以及它的这种可信度对。

但人其实也会产生假新闻是吧，谣言也是会产生的，但是人产生假新闻跟AI产生假新闻，他的量级是不一样的，就是说当你比如说呃我们谈到这个认知欲，谈到认知欲去对抗，那么其实这是一个大批量的。

是一种就是博弈动态的这种情景下的，效率太高了，对那么就是说去把这种趋势，把AI生成这种趋势检测出来，对于这种整体的研判是有些帮助的，嗯好的，赵老师有什么想法吗，对我觉得你这个问题可能就是。

也可能我觉得是比较超前的一个问题，因为我我觉得这是就相当于AICC的，这是人工智能生成内容的一个检测问题，嗯我觉得至少在目前为止啊，就我我自己不是特别看好这个这个topic。

因为我觉得现在至少到目前为止呃，还是没有出现大规模呃这种内容的一个滥用，因为它和图片造假还不太一样，图片就是一上去这个危害会很显然，就比如说呃文本这段，我没有想到。

很直接的的一个直接的一个一个一个一个损害，因为现在至少我看到的情况就是，就是就是我问你日常会接触到很多的，AI机器生成的文本吗，啊对在我的场景里面，就是说我可能不能就是把它很很详细的。

就是给就是告诉大家，但是这个场景里面他是一个博弈的状态，就是说需要去做这样的事情，我我我觉得可能一个更泛化的，就是可能因为时间关系我就缩短我的这个回答，我自己觉得就是你可以把这个造有造假的。

这个这个这个机器人也也就理解成一个人，就刚才宋老师已经说了，就是其实其实人写出来的就是有损害的东西，是很多的，就包括网上的对，然后你机器可能也有一些造假的，就是没有必要。

一定要把这个人和机器的要给区别开来，我个人观点啊，就是你可能比如说你可以创一个这种这种，quality的这种classifier，我觉得可能更有用处，或者说检测这个假新闻不一定是人呢，还来自于机器的啊。

就我个人一些观点，就是其实我觉得在您的观点里，就是它的真假要比这个AI还是人生成更重要，对，因为因为因为其实是现在网上的所有新闻，都是一个背后的一个人去造的呀，啊那他有可能是真人。

有可能是就是就是是个机器，然后人也有可能有好人，也有坏人，就是你没有办法去去控制你，你给它detect，它出来似乎有点用，但本质上我觉得没有太大帮助，对啊，好的方便知道你是哪个公司的吗，我是中。

我是中国航天科工二院706所的，嗯好的，其他老师还有补充吗，您请坐，您不用站着啊，对然后我也谈一下，就其实我觉得这个事从技术上来说，其实是挺难的，因为它和传统的图像信号也不一样嘛。

图像信号毕竟还比较连续，就你在里边搞一些小的噪音，那些没人看的出来，但文本信号话要在里边去插入一些方法，能让就是AI的这种东西能被有效检测出来，或者识别出来的话，其实还是挺有难度的。

而且特别是像像现在的AI模型，其实它本来就是从人类大规模语料里去学习的，语言模型，所以他说话就一定会非常像人，而且他越学的好，他就越像人，到最后就是模型大到一定程度之后。

你就不应该看得出来他到底是人还是机器对啊，然后所以的话，我觉得这个事总体来说是有点困难的啊，但是呃其实现在嗯大家能使用到的模型，在语言中往往也是有一些特征的，有这些特征其实能让大家知道它是AI生成的。

比如就前段时间不是有在论文里发现什么，as a AI assistant什么的吗，对对对对，就就就这种啊，然后这些特别爱用的词儿对，就这种就是很有AI风格的词语，其实你也可以理解成是一种变相的水印。

还有就像什么总的来总的来说呃，总之这种结尾的，还有就是格式打的特别好的那些啊，都看着都特别像AI对，然后我现在因为也经常在网上看到，类似的一些东西，我都会在后边猜他到底是不是AI写的。

但总的来说就是要从技术上，就是真的去做到一个比较好的识别的话，它难度还是挺高的，而且估计会有比较高的误伤率，好谢谢好的，还有问题吗，我们再请一位观众，嗯好请问那位女士吧，谢谢宋老师啊。

我是环球时报的记者，我要问两个问题，一个问题是嗯从去年到现在，咱们大概市面上，国内市面上大概有这个300多个大模型，我们现在都说国内的这个大模型，市场上非常卷啊。

嗯有的人就认为现在这个大模型领域里面做的，好像是百花齐放，但是呢小模型也就是说垂直领域里面做的，这个好像是没有说满足这个市场的需求，我的问题就是说嗯各位老师觉得大模型嗯，下一步要卷的话。

可能卷哪个方向是卷垂直领域呢，还是得继续在现在这个大模型的这个角度去啊，再有一个问题呢，是关于中美之间的一些这个问题，哈哈嗯这个问题我们先答一个，要不然一会就忘了，好嘞，谢谢嗯好哪位老师先请。

就是他说垂直领域的这个模型，其实好像不是很符合预期，然后接下来嗯会有这方面的爆发吗，我感觉垂直领域确实比较难，一是数据又又少是吧，然后要求又高，就是大模型还是呃有一点特点，就是说他嗯比较能骗外行。

就是当你不是这个内行的时候，你问一个问题总是觉得他说的很好，然后但是当你是内行，查你自己很熟的问题的时候，你就能看出他的漏洞啊，然后如果用在一个垂直领域，偏偏就是这种情况会比较多，就很关心这个领域的人。

然后还是蛮难的，要不贺老师，我我我不知道，因为我不不太懂垂直领域的模型，但是我看最近好像嗯教育模型挺火的，但我也不知道是昙花一现，还是一个这个未来真的有可能的，因为教育模型就是像宋老师说的。

他那个题的难度没有那么大，可能因为他面对的可能都是一些小学生呀，初中生呀，这些那对余料也比较丰富，而且就是说这个对知识的要求，可能也没有那么高，对不会说让一个抖妹expert，因为你面对的都是小学生。

初中生，所所有有可能没有这种问题，但是具体他哪个垂直领域比较好，或者该怎么落地，我其实也不是不太清楚，听听各位其他老师的意见，东老师和曾老师，你们要答一下，曾老师请先啊，好的对。

其实我觉得这个问题确实挺难回答的，特别是这种呃在在垂直领域里的模型，其实可以理解就是一个垂直领域里的专家嘛，然后现在大模型其实是一些比较通用的能力，比较一个呃，就像一个接受过通识教育的人一样。

然后怎么让这样一个人能够，成为行业领域的专家，其实是现在大家都在探索的事啊，比较容易的想到了，其实就你你拿数据训一训肯定是可以的，但这样的方法的话，其实从效率上来说也没有特别高。

所以我们现在也在去看有没有一些其他的方法，像包括通过agent的的方法，然后以及今天其实我听了那个呃啊，这张老师的那个讲讲了之后，我还在想，能不能把一些能力怎么就直接编辑进去，是不是就更更更快捷一些。

东老师有补充吗，嗯对我呃，我想想我，我感觉这个我从大约从两个维度，第一个就是说呃，就是说可能一方面呢是呃刚才也说了，是从2023年以来嘛，其实这个大模型呃，技术发展或者模型本身的发展非常非常快。

就是呃这个不好说是不是人类历史上最快的，但是至少是过去很长一段时间，大家可以看，无论是信息技术，互联网，手机等等，其实发展非常快的一个技术，在202023年这一年，所以我们现在的预期是说。

在这一年的时间，其实我们某种意义上，可能是对它的模型本身的能力，以及呃模型在垂直领域或者各方面的应用，其实set up了一个非常高的期望，其实我个人觉得这件事可能我们某种程度上，因为它发展非常快。

我们某种程度上o s t mate它的可能呃，短期内的可能性，就是那个我想想是应该是bill gates那个讲过，就是说我们其实在这种情况下更容易o s mate，短期它可能达到的效果。

其实安under timeet的它那个长期的一个效果，如果我们放在一个5年和10年，甚至都不用20年的尺度，有可能大模型在各个领域的应用，可能会产生呃非常大的这个影响，然后这第一个维度。

第二个维度的话呃，呃有可能我们需要找一个example，不一定那么好找，但是从另一个层面来看，至少我我我个人能看到的一部分数据是说，包括我们自己的那个model aza service，那个API平台。

质朴的API平台，包括我我我们也大约了解一些友商，包括大厂云厂商的呃，包括微软其实也release部分数据，实际上模型的这个API调用的量，token产生的量呃是非常非常大的。

然后这些用户其实都是一些商业，甚至都不是IT有IT有信息领域的，其实还有很多呃传统行业的一些呃，传统厂商在尝试用大模型呃，这个应用到日常的这个生产当中呃，就是说怎么形容呢，就是说其实很多厂商。

很多行业也在尝试的过程中，我们可能在稍微耐心一点，给他一点时间，有可能呃从一个相对更长的time frame呃，那个时间片来看，可能会会有更大的一个一个一个效果，对对对，好的你的第二个问题是。

谢谢宋老师，第二个问题是呃，外媒近期也关注到报道啊，有很多的这个报道提到，就是美国现在可能会针对啊，人工智能领域的一些这个技术对中国实行封锁，尤其是彭博社最近报道的，就是可能要进一步限制中国。

获得用于制造尖端芯片的，这个缺环绕山脊的晶体管技术啊，然后包包括可能会限制高呃，高带宽内存HBM的一个技术，对对中国的出口，想问一下各位老师，就是嗯美国对这个中国的这种技术上的。

这个在AI领域的这个技术上的封锁，会不会对咱们国内大模型研发呃，产生进一步的影这个影响，然后嗯怎么怎么去应对它，好的嗯，哪位老师可以先讲一下，张老师，你要不要先来，那那我就抛砖引玉啊，简单说说呃。

我觉得影响肯定会有嗯，首先我们看到这个比如说就以我们学校为例啊，这个现在就就很难买到那个英伟达的卡嘛，啊这个这个众所周知的一些原因对吧，然后包括很多国内公司也买不到这些卡。

它就会直接影响到算力的这个问题，但是我我我也知道，咱们国内像比较那个做的比较好的，像华为，他们也在有一些这种嗯升腾系列的这个卡，呃，其实我相信我们国内很多企业啊。

很多做芯片的公司一直都在努力去把这个生态，把我们从底层的基础设施，包括我们的那个呃大新训练深度学习的框架，像那个呃国外我们现在都知道排球拍都呃，不那个国外都知道那个PTORCH。

那国内也有一些像国啊华为的minus sport啊，国内的像那个paddle paddle啊，还有像我们呃清华这边还有那个G图等等框架，其实都都都在朝着方面努力，就是说我觉得在肯定在很有一段时间。

我们可以有一个完全自主的一个生态建立起来，那那个时候其实就不用管，美国的那些什么所谓的封锁了，对赵老师还有补充吗，没有好的，那我再帮大家问最后一个问题，然后那么刚才也说到算力。

其实大模型时代我们知道非常重要的一个工具，就是啊必要素就是算力，那我们也因为身在高高校，也会有这方面的一些啊，就是资金啊，然后不如这个啊工业界，我想为各位因为有在工业界的，有在学术界的，还有像东老师。

可能嗯两边都有的对，然后来呃逐一谈一下，就你们觉得在现在这个时代啊，工业界和学界相比有什么优优势和劣势，然后你们未来觉得嗯有什么期望，让让自己所在的这个啊，这个位置可以更好的做呃，大模型。

大圆模型的研究，要不赵老师先来好的，这个问题很很难，这个问题就是不是难回答，是难解决，因为我觉得现在可能整个高校最大的一个问题，就是能拿到的卡数太少了啊，然后所以导致的一个问题是。

现在呃高校里可能就说老师或者是学生吧，真正呃训练过大模型的实在是太有限了，因为资源就那么一些，对我觉得这个从长期来看肯定还是很不利的，因为学校里面可能很大的一个好处，就是我没有什么利益上的。

这个我我要做的事情，可能就是呃去把我的成果去发出来，然后我我没有必要去遮掩一些东西，然后没有必要为了KPI去做一些事情，就是我们可以做非常自由的一个探索，然后是什么，其实我们想公开，我们就公开了对。

所以这是非常大的一个一个B公司的一个优势，就包括欧I，他们内部应该有非常非常多的这个技术，但是他们这些人你可能永远也没有机会给他，至少这这一年去说出来对啊，但从长远来看，确实算力现在基本上已经成为高校。

发展大模型科研，我觉得最掣肘的一个一个一个事情，那现在也也没有特别好的一个方式，我觉得可能还是要和企业，包括算力中心啊去进行这种联合性的一个开发，甚至我觉得是经常会呼吁，就是说那国家有没有可能去呃。

为高校的一些科研团队去配备额外的一些算力，去让有一些有有能力去做大模型研究的人，能拿到这个算力，对好的，那曾老师嗯，您的那个卡还是很充足的是吧，呃怎么说呢，就是对于做大模型来说，卡永远是不够的啊。

因为呃就是大模型，其实从目前来看就是实验还是很重要的，就是呃实验比较偏多的话，其实我们就需要投入很多的人去做实验对，然后呃从目前来看，就是至少因为我现在在面壁嘛，然后从公司这边来说。

我是觉得就是大模型的话，其实还是一个呃科，就是科科研的前沿工作，和工程化相结合的一个事情，因为其实在我们最开始做大模型，就20年那段时间的时候，就是呃当时国内国内甚至连能跑大模型的。

就是那种集群都不存在，因为都没这种需求，从我们当时从最底层的模型真的搭起来，发现里边有特别多工程上的问题，然后以及就是到后来就是真正做大模型的训练，它的数据，它的对齐以及大模型相关的标注。

以及怎么我们利用sk in law，能批量的去去去跑我们的实验，然后能够通过我们的实验，去更快的挖掘出大模型，那些还没有被挖掘出的结论等等，这些其实都是非常工程化的事情啊，同时呢大模型的研究呢。

它其实还是处于一个非常快速的，一个在演进的状态，所以的话其实它的前沿探索也是非常重要的，所以我觉得其实真正要做的好，大模型，还是需要能够将这种产学研相结合的一种形式，才能把它做好，非常好，张老师呃。

我就简单说两条吧，首先一条就是感觉现在很多，国内就是学学学界的老师，一般都会考虑跟公司合作来做研究啊，这个能够缓解卡的问题啊，这是一条嗯，第二条的话，就是如果说说要学学校，做纯这种学术的研究的话。

现在大模型时代可能嗯，一些机理性的工作可能更加适合一点，因为这个可能不太需要太多的算力，我们可能只要能够解释某些现象对吧，可能在一些小规模的模型上能够work，同时在一个啊中等规模的模型上。

也能够验证它的结果，我觉得就已经能说明这个东西还是合理的了，对非常好，董老师嗯，呃我想想，首先呃非常支持各位老师讲的，我我们可能肯定是需要找到一种产学员的方式，尤其在在咱们国内。

能够让呃更广泛的人跟咱们同学，咱们实验室，咱们老师呃，包括跟业界一起来探索大模型的发展，但是从另一个角度来看，其实现在此时此刻，大模型我我我当然只是我个人的观察，就是说呃大模型的所谓的前沿探索。

所谓的这个这个大家都在训模型，其实某种程度上它已经变成了，有一点像那个包云岗老师提到那个词，重工业科研，其实它本质上呃，或者说现在的本质，实际上就是呃工业界更擅长的一个事，工业界实际上在刷点。

在提升这个模型的performance，在一步步往前推这个模型呃，IMPERCOLATE的，推模型的这个这个能力的这个边界对吧，其实某种意义上，其实现在有一点像那个大家也经常举那个例子。

就是说其实有点像那个我们现在就有点工业界，有点像把这个这个莱特兄弟一样把飞机送上天，现在现在飞100米高，目标是飞101米高，1000米高，但是最终如果说要把这个飞机呃，做成今天的这个A380啊。

什么这个这个这个空客787呃，Sorry，风洞实验这些更理论的东西来指导，怎么更好的设计飞机，怎么更好的呃指导训练模型的各种呃，这个这个参数的设置啊，各种design的决定可能更多的需要呃理论的来支持。

所以我觉得这个学界其实在这方面还有很大的，呃空间呃，当然可能是一个delay的过程，然后紧接着这个，我其实我们也经常在讨论的一个事，其实如果我们换个角度来想呃，怎么来形容呢。

其实你看GPT3是20年年初放出来呃，在GP3上用RHF，也是2020年就放出来一个版本，然后skilling law，如果你看那个paper open也是2020年初放出来的，那也就是说某种程度上。

无论是我们学界还是我们业界呃，不管国内国外，其实大家都是呃某种程度上是呃没有意识到，这件事，其实更多的是需要我们大家一起来探索，一种可能性，一种机制，让我们至少如果已经有前沿的呃，可能性前沿的方向的话。

我们能够一起推进，然后最后的话呃我想想就是卡多这件事，你说业界咱们国内的业界，我相信相比open微软，google还是大概率有一定的差距，然后我其实呃也有一个一直有一个怀疑的点，就是说我们自己做实验呃。

这个发现就是说我们在1B6B，12B等等的模型，更比如说更好的数据，更好的方式，更好的配比，更好的参数设置等等，但是都不用skill到更大skill，到这个这个千亿的时候。

我们现在能SSKILL到的程度，实际上之前在百亿，在几10亿的很多结论都不成立，imperial的结论都不成立，那也就是说如果SK到更大的一个程度，但是我们现在又没有机会从我们的视角。

其实也没有机会死SK登到更大的一个程度，实际上就说我们现在的很多发现，很多观察很多论文，很多发表是不是真的合理，这件事其实我觉得其实无论是学界和业界，其实都被算力锁在这，至少目前此时此刻的状态。

当然最后我们肯定还得充满信心呃，乐观的就是无论是各个生态圈，大家一起来折腾，对对对嗯，太好了，贺老师，OK那个我记得钱钟书有一本书叫做围城，然后有一句话就是城里面的人想出去，城外面的人想进来。

我觉得现在实际上就有点像这种情况，就是工业界，刚才实际上我们看了很多，之前老师在工业界的slides里面，也发现了各种各样的问题，但是作为学术界的人，实际上我们对此一无所知，因为我们并没有过这样的经验。

然后去做，所以如果要去想办法，能够去去达成一个比较好的一起推进，我觉得最好的办法就是把这个围城的墙打破，能够想办法让工业界和学术界的人一起去看，一起去解决问题，只不过是说大家所采用的策略。

解决的角度是不一样的，只有这样才能够最好地推进整个的东西往前走，因为我想到open i里面，实际上有很多很多就做理论的人，包括各种各样数学背景的人，也有很多编程背景的人，大家都是一起去推进的。

只有这样的话才能把一个东西做到极致，非常好，所以说到算力尽管是一个很沉重的话题，大家还是看到了希望，那么到最后呢，除了这个扎心的话题，我在想以一个比较乐观的结尾给大家，所以每位老师能不能畅想一下。

假如你没有算力的啊，限制你有无限的卡，你这一年或者说你未来最想做的是什么，topic也给在座的啊，各位观众有一些启发，赵老师要不请你先呃我我我的我的话，我很还是希望就是说，比如说如果真的有无限的卡。

能不能不能训练出一个商业水平的大模型，因为学校里面的算力确实比较有限，如果是真的放开，那你算力到了能不能达到商业的水平，对好还是想了解里面的秘密，呵呵对，其实我一直有个好奇的点啊，你看skin law。

它是一条非常直的线，我一直在想这个线的尽头是什么啊，如果我们真的到达了尽头，它会得到一个什么样的模型啊，我其实对这个特别好奇，如果这无限多算力，我估计会去镜头看一看。

对skin love的镜头是不是铁岭是吧，呵呵好，张老师请对哎，我其实挺期待这个如果有这么多卡的话，能不能真的把这个transformer变成，像transformer一样的这种能力啊。

因为我们其实做很多，不管是机理也分析也好，那个完全没有办法去做呃，100币以上的这种这种实验，甚至这些这些模型开源的也很少啊，那这种真正的能力很强大的，很多能力是可能是呃跟一些小模型的机制时。

可能是有点不太一样的，那这种背后它这个背后的原理又是什么啊，如何去啊，真的把这些模型的背后的，这种底层的原理给挖掘出来，我觉得我挺想研究研究的，对嗯还是好奇对，给东老师请这个更多的算力对。

其实其实这个假设性的问题，我们也经常问我们团队自己的人，如果突然给我们10万张卡，我们干啥哈，对呃我我可能没有一个，无论是呃一个特别的想法吧，其实可能更多的是，如果我真的有10万张百万张的卡，我可能会。

我们可能更多的是让我们team里的这些呃有想法，有创造力的同学，有有有有有活力，有精力的同学，让他们的人均卡量上来，我我我感觉自然就会有好的结果吧，嗯好的一个好的环境，如果我有非常非常多的卡。

那个时候一定是我老婆早上起来的时候，给我一个嘴巴说醒醒，别做梦了，该去上课了，好的太幽默了，贺老师好，那我们今天的论坛就到此结束，谢谢各位坚持到最后。


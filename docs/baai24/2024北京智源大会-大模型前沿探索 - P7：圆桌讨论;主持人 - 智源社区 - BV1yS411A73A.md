# 2024北京智源大会-大模型前沿探索 - P7：圆桌讨论;主持人 - 智源社区 - BV1yS411A73A

感谢各位讲者能够参加我们的原作，在开始我们的原作之前，有人问过我一个问题，我想分享给大家，是这样的，就是说大家说大模型时代来临了以后，给各行各业带来了很多的挑战，很多人都说很多行业没有了。

或者说就业机会产生了大量的萎缩，那么对于我们来说如何应对这个挑战，在这个问题我给了一个比较形象的比喻的回答，是这样的，大模型时代来了，就有点类似于在以前，马车时代和汽车时代的一个变化。

马车时代来的时候很多马车夫，然后养马的人员会说，我们未来是不是职业会消失了，然后我给出的一个答案是说，虽然说马车行业会消失了，但是汽车行业发展起来了，汽车的上下游的产业链，包括城市快速路 高速公路等。

新鲜的事物都出来了，我们可能要看得更长久一些，然后发掘出来更多的机会，然后可能会对这些时代变革带来的挑战，会有一个比较好的应对，然后在今天我们想针对大模型，对我们所有人带来的挑战，展开一个探讨。

我们接下来将会从大模型的科研技术创新的角度，以及产业的角度，最后对我们每个人，可能会产生什么样的变化的角度，三个方面来阐述，然后下面开始我们的第一个议题，是大模型的幻觉和安全问题。

大家都知道大模型发展至今，虽然说幻觉问题，较两三年前已经有了很大的进步，但是还是面临着很多的挑战，包括安全问题，即使大模型的各个厂商，做出来了非常大的努力，但是仍然有非常多的安全问题被攻破，被出现。

所以说想请各位嘉宾来分享一下，幻觉和安全问题的一些理解，好 谢谢，然后我们接下来由双永博士，按照这种方式来进行，您先第一个，好的 好的，叶全博士说这个问题，是关于幻觉和安全，其实幻觉和安全。

我个人认为从两个方向来讲吧，因为刚才其实，我也在讲，电信其实在做很多的应用场景的落地，其实从应用角度来讲，确实对于幻觉是，这个肯定是要避免，安全问题肯定是要这个，也是要避免的。

所以这个其实是要从一个产品维度，带着产品维度的思考，那么怎么样从问题的维度，甚至说产品形态它的输入控制上，做很多的一些限制，还有包括从答案生成的结果上，那我们怎么样通过这个，也是在产品和系统维度。

做很多的一些限制来控制这个，当然模型本身的持续提升，肯定是要继续的，但是就像叶娟博士也提到，虽然这个幻觉和安全的问题，我们持续在提升，但是现在离这个100分，还只是说差距越来越小，但是并不。

从目前这个模型本身的它的，原理来看，基本是不太可能实现100分，完全控制的，所以还是要从上下游的这种，输入输出的产品形态也好，系统维度去进行很多的控制，那这是一个方面 从应用场景，那其实在大模型。

我这里面大模型，可能我们单指这个羽翼大模型，那羽翼大模型本身来讲，那安全和幻觉在有些维度上，它可能是不希望限制，比如说在真正的一些常文写作，或者在文学创作上，它可能就是需要一些幻觉，甚至说一些安全问题。

甚至在我们一些场景上，可能叫反社会反人类的这种话语，但是在出现在一个小说里，好像是可以接受的，所以这个可是不同的应用场景，所以其实说我们要给它一些不同的，一些定义吧，所以我觉得从这两个角度来讲。

当然我们现在目前可能更关注的是第一点，从这个问题本身来讲，其实我们更关注的是第一点，然后在这个维度上其实刚才，在技术上也提到了，从SFT到DPO等等，各种维度的这些限定上，我们要持续地加强。

因为有些时候其实我们的限定，包括安全和幻觉的场景的限定，其实也是在一个特定的维度上，甚至在这个问题本身，它是有一些国家和地域的一些不同的，对吧 那同样的一个言论，可能在不同的模型，不同的地域上。

它可能对它的理解也不一样，所以其实就目前来讲，可能一个世界维度的同义模型，在这个问题上估计就做不到，对吧 它可能在一些数学能力上，全世界是统一的，但这个维度上就相对来讲就很难去统一，所以这也是一个点。

那这个其实也就涉及到我们，在使用一些，因为现在可能有的厂商是自己做模型，还有的是用掉一些GPT等等的接口，那在这个问题上可能涉及到的处理方式，就又会不同，那时间问题可能要不我就先说这么多，豪翔博士。

对 我是比较同意那个宋博士观点，因为这个幻觉也好 安全也好，就是在我看来你是针对用户说的，对吧 那幻觉，有人觉得幻觉不好，那幻觉还意味着创造力呢，就你从那个 而且你从那个机理上看。

对吧 它就是next token prediction，对吧 我的预测空间放窄了，可能幻觉就小了，但我有的时候我就要它，在很大的空间里面预测，所以看的是你要它什么能力吧，所以就是说。

反正我建议就是从技术上改进，也没有必要 对吧，那就是 你像一个人读了好多书的时候，你人脑有的时候都记错了，都会出现幻觉，你还非要要求机器就是绝对不出现，那可能就不太有必要吧 对，然后你就从应用的场景上。

对吧 那我们就可以挑一些，幻觉没那么大危害的场景，优先用一用 对吧，然后你要说这个特别特别严格的场景，那我就干脆就不用或者是少用 对吧，那只能是从这个方向来限制，就安全也是一样的，就有的时候可能。

叶全你觉得安全，然后我觉得不安全，那我就说这模型不安全，那其实不是这样的，我们对这个模型来讲也是不公平的 对吧，就还是针对用户来讲的，对 我个人观点 先说这么多，对 刚才孙博社和敖博士刚才讲了。

从用户 从应用那个角度来讲，那我就从技术这个角度，来思考一下幻觉和安全，首先是先讲幻觉，首先我个人觉得吧，幻觉这个词该怎么去定义，大模型 如果纯NLP的大模型，它有它幻觉也许吧，但是像多模态的。

就是你给个视觉的输入，然后让你去回答，其实它这里面幻觉它有可能又不一样，为什么 你去说是吧，你有可能你说的东西和那个图没啥关系，那这种算不算幻觉，所以有些东西就看，从技术上看如何去定义，至于像刚才。

敖博士说的 其实就是next predict，你有可能就像我们做成语接龙，从技术角度，你接错了一个词，那有可能后面接接接 击鼓传花是吧，你后来就传着传走了，你反正是找那些比较接近的。

有可能在训练过程当中，有可能你走了一步 是吧，到后面就走走走走，然后它就产生那种幻觉，这是技术角度，但是是不是可，先不从用户角度，是不是可以解决呢，我觉得这个就在于什么，其实如果 假设。

假设你如果只是希望它是记这个东西，只是把那些数据集给记住，你的模型非常大，你那个数据集是有限的，如果记住了，你训练那个损失降得非常非常低，并且你给的那个题目是一个exactly，就是一模一样的。

如果你损失降低了，那这个东西其实它是不会产生幻觉的，但是在不会产生这种幻觉的过程当中，就像刚才尔博士说的，有可能它没那个发散力，它有可能在做的过程当中，它没那个diversity，又没那种随机性。

像很多深层模型，它其实要强调一个随机性，就像大家如果现在要做，视觉做扩散模型，为什么扩散模型它会比GAN效果好呢，是因为扩散模型它每一步，它都有一个A+加了一个noise，它那个清晰度会大一点。

传统的GAN它只是在，刚开始的时候随机采样一个，之后就是一个函数音色，属于这个diversity，所以这里面要有一个tradeoff，所以从技术的角度来看，我个人觉得幻觉这个问题。

首先一定要很好的定义好，你要定义好了你才知道它到底是不是问题，然后再把它解决，如果咱们要再去把它定义好了以后，之后的话从技术手段，其实有可能是从那个什么优化，从理和或者从数据界有可能去，往前去走的。

而不是一个宽泛地在，从用户那个角度它是一个幻觉的，至于安全性这个问题这个就比较大的，安全的话它分两个层面嘛，就是像王博士我们做那个，科技项目，安全的话如果从，它有个security和一个safety。

safety有可能是指什么，它有可能是指有些描述，它有可能不是安全，这个安全，对A是有安全的，就比如说有些眼泪是吧，但是对B是不安全的，那另外一个安全性是什么，就从技术上，像神级王那种催逐性。

它那种对抗鲁邦性，它本质上，它有一些催逐性，像以前大模型出现之前，对抗攻击这个其实是一个，非常active 至少在高效，它是一个active的方向是因为，那个成本比较低相对，像大模型来的一样也是。

就说这个方向相对来说，你不需要训，你就只要用它 你去分析它就行了，所以在这个方向上，它其实就是本质上还是那个模型，那个鲁邦性，它本质上就是，因为我们需要梯度是吧，如果你能够超过那个梯度，和最后要弄死。

那你这个东西解决不了的话，它肯定会有方式，无论你是让它孕育，还是对它进行攻击，还是进行一些其他的，让它想你指定它去说什么，还是下毒，它都有一种方式从技术上，能够使得它不安全，好 这是我的一个见解，谢谢。

好 再见 博士，嗯，这个大模型的这个幻觉问题，就是可能大家就是通常所说的，就是说在生成一些结果的时候，它可能会产生一些不准确的，或者是一些虚构的这样的一些信息，那么可能对于某一个领域的话，某些领域的话。

确实会是这种挑战，刚才各位专家说的我也都同意，那么这个幻觉问题是怎么产生的，可能主要是因为就是说它在，它是在这个大规模的多样化的，这种数据上进行训练，然后呢，这个模型的话。

是通过这个模仿这个数据里面的一些pattern，来生成这个最后的结果，那么这样的设计的话就会导致我们的，这个模型在一些领域上面，它可以表现出来比较强大的，这种语言处理的能力，比如说我们刚才也有专家讲到。

就是在一些吟诗啊或者是写作呀，这种一些任务上面，这个可能幻觉问题反而是一个好事，但是呢，就是说在有些领域，比如说像我们这个问题里面提到的，这个财务啊 金融啊，包括我们的一些医疗啊等等，包括决策呀等等。

一些领域可能这个幻觉问题，它是一个致命的问题，所以我们可能也需要一些策略，或者是一些措施来缓解幻觉，或者是朝向解决这个问题，去做一些事情，那么比如说，我们可以结合一些专家系统。

或者是集成一些领域的这种专家知识，设定一些规则，来去缓解这样的一些问题，因为现在已经有这样的一些方式了，比如说让这个大模型在输出结果的同时，也给出它所依据和参考的这个出处，那么这样的话可以在一定程度上。

缓解它的这个幻觉问题，所以我们确实也还是需要在这个方向上面，做一些研究和探索，来就是发挥这个大模型，在处理这个大数据啊，处理一些复杂计算，它的上面的一些优势的同时，然后呢也能够去降低，它在一些领域上面。

可能存在的一些风险和隐患，好 谢谢，好 谢谢 谢谢所有专家，我感到非常的开心，是这样的，就是说在以前的时候，比如说去年的时候，大家讨论幻觉的时候，很多观点都是说幻觉安全问题，是一个必须要解决的问题。

但是今天的社会专家让我学习到了，可能幻觉安全之类的问题，我们要辩证性地看待，甚至来说有些情况下，幻觉可能是属于创造力的源泉所在，在不同的场景 不同的应用中，我们可能要辩证性地看待这些问题。

以及我们如何定义好幻觉问题，包括我们定义好这个问题以后，然后用什么样的技术方法 技术手段，去有针对性地解决 缓解等等，甚至利用这一个维度的信息，来去做好我们的应用，做好我们的科研工作等等。

非常开心能够学到这些，然后下面一个问题，可能也是目前大火的一个问题，就是动态方面，目前的话，OpenAI在今年年初的时候，领先发布了Solar，然后目前一个趋势是，无论是国内还是国外。

有实力的厂商都在大量地跟进，然后我想请问几位专家，如何看待这个方向，是跟进还是说不跟进，是坚持语言模型，还是要坚持多模态，走具身智能还是说哪条路线，然后这次的问题我们从赵健博士开始。

然后反过来顺序 谢谢，我觉得现在确实是OpenAI，一直在引领着全世界的人工智能，前沿的发展和进步，然后国内的话就是，智原一直在引领全员的方向，实际上我觉得，其实我们也有很多独特的优势。

在国际上我们现在创新的能力，创新的人才也都在不断地提升，所以一方面我们是跟进，他们的一些技术发展的潮流和趋势，另外一个也是利用我们的一些，既有的一些优势，比如说我们大场景 大数据，我们在很多的子领域上。

有快速落地 有快速迭代的，这样的一些能力，所以我们也是可以在很多的实际应用里面，不断地去找到新的问题，然后不断地去找到新的方法，我觉得相比于国外的话，我们在这些方面是有优势的。

然后也坚信我们后面会走出来一条，有中国特色的人工智能发展的道路，谢谢，黄磊博士，这个问题好像有点大，比较偏前沿区域策，首先第一就是，大模型其实，在讲动物太子时期，我还是再强调一下大模型这一点就是。

首先大模型它能统一的原因是什么，我们语言能够描述各种各样的任务，我们以前人工智能它是强调，要任务 分任务是吧，现在我们语言能够描述任务，那么它其实至少语言这块它是个B级，它的输入是语言 输出是语言。

这个是个close的级，所以大模型先从语言这个方向走，那么多模态，那这个就不一样，因为多模态你看怎么定义，你如果输入全部是多模态，你的输出是语言，其实这一条路其实是没啥问题，为什么。

因为现在大家的一个思路，至少在我做小尺寸多模态大模型的时候我发现，你其实一个Pipeline是怎么做的呢，就是利用现有的语言能力，然后你自己做多模态的每一个模态，它和语言之间。

我做一个数据的一个对比的 无论是什么，这种是数据其实可以构造的，不搞就像clip最早这么弄，然后再去顺一遍，再用无论是像语言模型训一样，对齐了以后用全程文本这一套，基本上是能够走通的，其实难就难在什么。

你的输入是多模态的，你的输出是语音和多模态，如果你不经过语言这个输流，就是现在有很多你到了语言，然后语言再调整到输出，那你难点是什么，你的那些多模态，你能不能描述你的那个任务，这是一个最核心的一个难点。

你如果描述不了那个，或者你有可能能够描述任务，但是你那个信息量，就是你那个比如说图像，因为我最早做视觉，视觉它那个描述它就非常不精确，你没法精确地描述你，就是现在有一些方向做纯视觉的大模型。

就是只把所有的任务的问题，全部把它变成图像，就是你目标检测的话我也不说什么，我就直接那个框给框出来，只以视觉那个方式去做，的确是可以能够，类似于那种接龙一样的方式，做出一个效果，但是那个效率非常低。

训起来就要非常多的数据，然后效果也没那么好，但是一旦把语言介入，把语言做一个输入，你就发现它的效率会非常非常高，所以我个人觉得如果按照人去，按照通往AGM吧，我觉得语言还是一个输流。

虽然我不是做NOP的，但是我不可否认的确语言是个输流，因为语言的话至少，我们从历史上，文字是吧 我们是有了文字，我们才有一个传承，文字那个信息量就非常大，我们能够读古是吧。

同样的我们能够和人去交流也是语言，所以它那个信息量非常大的情况下，所以以它作为一个接口，我觉得再把动物态给接进来，我觉得，我先不说是AGM，但是我觉得这应该是一个，应该是一个不错的一个方向 至少。

这是我的一个理解，好像不是，对 我的观点是这样的，就是如果一味地跟进美国，那就一直被牵着鼻子走 对吧，人家发布SORA也好，对吧 GPT-4也好，人家可能有更先进的 对吧，已经基本上ready了。

然后过一阵儿一发布，然后咱就乌泱乌泱跟着去，这个就会很被动 我感觉，刚才我其实特别同意刚才黄老师讲的，就是语言是人类对这个世界的一种编码，而且编得还挺好 对吧，就比较高阶的一种编码，比如你动物态对吧。

现在大家一说动物态，就是视觉 语音，语音可能跟文字还比较相关，特别是视觉，视觉可能是，就是某种程度的低阶编码 我理解，就至少没有语言编得那么好，所以就是说，多模态模型 大模型，我觉得可以做，但是呢。

不一定是按照老美的那一套理解，就我的理解大概是说 你看，如果说这个多模态大模型是世界模型，是对世界的一种什么，somehow这个仿真也好，或者这个大个的，那谁是生活在这个世界上的呢，是我们人啊。

就我们人每天感知世界的这个角度，对吧 视觉也好 语言也好，那我们其实在这个世界上生活，还产生了好多数据，比如说咱们每天，衣食住行 诡计的这些数据，这些数据，咱们中国比老美多多了，对吧，那这也是一种模态。

那人在地球上生活，所产生的这些数据，那也是对世界的一种编码 对吧，那是不是我们可以去，主导就是训练一些，至少在这个模态上，增加一些诡计类型的呀，或者是就是人在社会上，生活所产生的这些数据，这些数据可能。

一是美国没有我们多，第二就是人家，可能也不想 不能用 对吧，隐私赚大的，当然我们可能对这方面的要求，没有人家那么高 对吧，就咱们可能对隐私的这个要求低一些，而且咱们有隐私计算框架嘛。

还是能保护咱们个人隐私的，就把这些东西拿起来，那是不是就可以扭转过来这个局势，对吧 我们可以产生另外一种，定义的多模态大模型，里面包含了人在社会上，生活所产生的这些数据，然后训练出来了以后。

是不是就能够，牵着美国鼻子走，这是我的观点，首先我是觉得多模态这个方向，肯定是要做的，但是我非常同意，郝老师说的这个，我们是不是要，出SORA就学SORA，出4O就学4O，这个可能一直就追不上。

这个例子，我在想这个，可能举一个另外一个例子，比如这个中国的汽车，刚才您提到的是马车和汽车，我们应该提到的是这个，我想提到的是这个，传统汽车和新能源，真的按照原来的这个发展路径。

我们在这个燃油机 发动机，还有这个安全上，其实如果真的按传统汽车去追赶的话，那可能到现在，我们就像在这个，追SORA和追4O一样，但其实在新能源这个方向，其实走出来一个自己特色的路。

其实在这个维度我也在想，这样的追赶可能一直是在追赶，其实在别的维度上是不是有一些，新的切入点，其实我自己想的是，比如就在无人机这个场景，针对无人机它的这种感知上，它可能不是这种像语言类的。

它可能就是各种声音类的，因为如果是战争无人机，它可能要对这种炮火声 枪弹声，它有更多的感知，针对民用的话，可能是一些比如汽车 鸣笛等等，避免碰撞等等，其实在这个维度上，我们是不是可以有一些特色的。

这种多模态的能力去产出，我就适配在无人机上，然后我就比如中国的这个，假设比如大疆这个品牌，那之后可能就是搭载了，最适合无人机的这种多模态模型的一个，更先进的这样的一个能力。

那其实我们在某一些维度上去超越，其实还好，如果真的是在通用的这种，文声视频也好，或者是这种多模态输入，多模态输出方向上，那可能首先最难的一点就是在数据积累，因为这个数据积累其实不是说。

比如像刚才我提到这个鱼大模型的样，可能大段大段的文本拿过来做基础模型，这个以前有的问答拿过来直接做SFT，它可能不是现成的，好多数据是要重新去构建的，光是在数据构建这块，可能追赶的时间就很长。

所以我觉得是可以想别的切入点，这是我的一个输入，好 感谢几位嘉宾，解答非常精彩，就比如说举个例子，然后敖博士刚才您提到的，就是属于方向是否要追随，双永博士提到的这个新能源汽车，确实可能对于我们来说。

既要脚踏实地还要仰空升空，我们可能要发现，对于我们来说 对于我国来说，我国的优势是啥，比如说我们有新世代发明，我们的电子支付等等各种方面，生活娱乐方面都做得非常好，那么把这些相关的数据，给收集整理起来。

是不是就能够开辟一种新的路线，然后是不是可能会引领一下，大模型的发展，我觉得这是属于我们在座的，青年科技工作者，我们在座的都属于青年科技工作者了，可能都要常思考的一些问题。

有可能会走出来一条不一样的道路，最后达成双永博士提到最后的目标，是不是我们也能在大模型领域，能诞生出来我们的一个大疆，如果能诞生出来，那绝对是属于我们非常好的一个进步，好 然后我在接下来。

跟各位嘉宾探讨下一个问题，也是一个比较宏大的问题，就是AGI它路在何方，然后像是昨天开复博士提到了一个问题，它目前像是巨神智能从来不投，然后它只投一些它认为，现在能发展到的角度。

但是有另外一些专家学者的观点是属于，可能是属于巨神智能就是未来，就要全部的凹进去，那么以及是否还有其他的道路呢，有巨神智能 有其他的路子，有可能这个巨神智能不是人形的，也有可能是人形的，还是说其他形态。

还是说各种其他的可能性，还是说一个纯物理，或者说纯信息时代的一个这种形态呢，比如说大家看过《头号玩家》这部电影，它就是一个纯信息的一种形式上的这种AGI，不知道这一个问题大家怎么看。

这次由双云博士来开始，好的，其实感觉这两个问题还是有很多的相关性，因为其实AGI通用人工智能，最开始语言弹幕行让大家看到这个希望，但其实现在感觉越来越不满足于这个单模态。

后来这个从文声视频到这个文本语音和图像视频，但其实在我看来好像，这些模态先加入到AGI这个方向，或者叫多模态大模型里面，是因为这些之前在经济学习领域做得比较深，但真的要谈到AGI或者叫巨神智能。

这个方向或者叫世界模型，那我们模仿人类，人类其实听到的不光是别人说的话，看到这个文字以及一些这种视频，其实在我看来，他可能收录到的信息是非常多样的，因为其实包括人的联想。

那我看到这个视频可能我想像后面有大屏幕，还有包括这个声音，我可能听到的声音不光是大家在说话，可能各种什么汽车鸣笛啊 甚至铲轿，对吧 都能让我想起什么古代的一首诗，其实这种维度。

所以其实我们现在的这个多模态，离这个巨神智能在我看来可能还是比较远，它没有实现人的这种全面的一个功能，包括我对自己，包括人其实还有一个点，在于对历史的一个理解，那其实我对历史理解是可能过去三十多年。

好多事情的一个总结，但是现在就这个模型本身来讲，它的输入的限定长度是非常有限的，它不可能做到这一点，所以其实很多很多问题都还没有解决，所以可能只是在这个路上的一个初步的探索，可能现在欢呼还有点早。

好像不是，我个人反正比较看好巨神吧，就是我觉得巨神是把不同条件路线给统一了，就其实咱们就计算机学科，然后现在讲这个Embodied AI是吧，那人家那个机器人学科就一直都在做这个事，都多少年了。

然后还有包括控制的，那现在就是大家好不容易就相当于是，一个共识了对吧，但我觉得就是说Embodied的这个内涵倒是，可以探讨一下，就是它到底是，说是人形的一个什么AI，然后去替代人。

还是说跟人更好的什么，那个叫做共生啊或者怎么样，就包括这个原来很多人研究什么脑机接口，我觉得都可以纳入到所谓的这个巨神的，范畴里面来，然后可能更需要的是说，就特别是科研界吧，我这个自黑一下。

就科研界总是说我要去当那个老大对吧，就是Embodied的就计算机学科要先做出来，而不是你控制领域，或者是你不能是你机器人领域，那其实到了现在这个阶段，我觉得大家还是应该这个合作吧。

就为了所谓的什么人类命运共同体，各个学科应该是贡献出来对吧，你擅长那个机械控制，你擅长机器人的，然后我们擅长算法的，合作起来大家共同实现这个东西，可能会加快这个所谓通向AGI吧，否则的话还是各做各的。

然后自己想从自己的优势出发，把别人的这些全都包围，那可能会比较低效，这个问题比较宏大，首先第一AGI这个概念，这个定义啊，这个反正肯定，因为定义这个本来是最难的，所以它本身就。

但是我就感觉现在我们好像对AI的要求，太苛刻了是吧，又希望它能干啥，都又需要比人好，各种各样能力都有是吧，但这个是好的，这是什么，至少我们有一个目标在那，这是好的，那么至于。

Embody的是不是通向AGI那条路或什么，但我个人觉得，就是Embody的，就是每一个技术它的发展，它肯定有一个历史感，就到了这个点的话，的确应该是Embody的AI了，为什么这么说呢。

就是如果我们是按照人，AI是我们是按照模仿人去的话，人的话其实叫什么，我们学院经常会提的就是，感知 认知 决策，这个我们经常说的，那感知的东西是吧，就视觉给它接进去，认知的这块东西的话。

也有可能有知识表示，但是NLP这块东西，它是能够得到一个输出是吧，就是像DeepMind他们做的时候，像他在做决策的过程当中，他也是把语言模型接出去，有那种action，也是当做语言的这种输出。

所以之后就是真正的决策，决策的过程当中，你做完决策你不是说，我嘴巴说出来，或者写了一段字就行了是吧，但还得要一个actor 一个行动，就像我们人是吧，我们嘴巴得动一下，我的声音才出去，我手动一下是吧。

我才能够干个啥是吧，那脚动一下才能够走啊，所以这个行动肯定是要必然的，如果按照这个方向，那为什么，那这个时间点，为什么in body-dye，为什么活埋，是因为我们感知和认知，在大模型这个驱动下。

大家觉得，哎 好像差不多了是吧，你如果你的输入，像我刚才讲的，如果你的输入，是视觉的或者语言的，你的输出是语言，这个东西其实应该是很快，这个我不能这么说，但肯定是比较快，所以只要你的决策。

因为我们人去想这个决策的过程当中，你肯定是能够用，语言能够描述的，这是可表达的，那这样一来，那之后就是你一个行动了，所以这样串起来，在这个时间点它去活，这也make sense，所以这是我的一个理解。

好 赵健博士，嗯 对，这个AGI的话，可能大家就是普遍认为是，它是跟人类的智力水平相当的一种，智能的这种状态，或者是能够完成人类所能完成的一些，这种智力水平的一些任务，这样的一个智能化的这种系统。

然后呢也有很多说法认为，这个大模型啊或者是世界模型啊，是通往这个AGI的一些必由之路，但是呢可能现在大家也都或多或少的认识到，大模型有这样那样的一些问题，然后世界模型它可能实现起来，就是说它要跟世界。

它要能够理解世界，然后要能够跟这个环境来进行一些交互，要有这个物理规律的这种认知，它可能实现起来是非常困难的，所以我认为这个AGI它，它的这个实现路径的话，可能肯定是一个渐进式的。

是一个分阶段的一个过程，在不同的时期会有不同的代表性的，或者是大家聚焦的一些方向，来朝着这个最终的这个目标，来这个演进，但是我觉得现阶段的话，跟这个AGI的这个目标还是距离挺远的其实。

就是从这个底层的这个学习机理，或者是机制来讲的话，我觉得可能现在咱们这个模型的训练和学习的方式，跟人的这个学习方式，就是有很大的区别的，现在大模型的这个，就包括咱们之前专家们做的这些报告。

现在大模型学习的这个方式还是，读万卷书的方式，可能人并不是这样的，人不需要去读一堆的书，我才能认识一个事物，然后也不需要花费那么多的，这个所谓的算力或者是资源的开销，来去认识一个事物。

它可能是一个长期的这个知识和经验的积累，然后再加上对一些新事物的一些理解，但是这些理解可能是一些模糊的，然后它就会获取到这种新的知识或者是新的技能，所以我觉得现在咱们这个优化或者是学习的这个方式的话。

可能还是需要这种颠覆性的创新，那么未来才会有一个通往AGI的一个更好的方式，好 谢谢，感谢 感谢几位嘉宾，我觉得这一个问题我问对了，然后学习到了很多，是这样的 就是说。

包括AGI目前的话大家已经有了一个目标，但是如何实现它，目前的路径是否可行，是否有更多的路径，是否可以探索出来其他的形态，包括多核学科的融合，不同技术的交互等等各种方式。

目前的话确实是没有一个达成一个统一的状态，但是这正是我们巨大的机遇，如果像其他的一些已经成熟的技术那样，那可能这个对于我们来说，尤其对于我国现在的状态而言，反而是一个不是那么有利的状态。

但是现在这种状态下，反而这一个事情，能成为一个有效激励我们所有人，长期前行的一个方向，下面向各位嘉宾请教一个产业方向的一些问题，主要是两个方面，第一个是属于产业的方向，然后目前的话。

很多人都在讲AI+的场景，那么大家认为有哪些场景，会兼具这种研究和落地的价值，这是一个方向性的问题，然后另外，有了方向，很重要的一个点就是风险，那么我们选中的方向，有哪些潜在的可能性的风险呢。

会带来什么样的危害呢，以及有了这些风险，那么可能在座的各位专家有什么，应对风险的建议呢，好 这一个问题请赵建博士那边，这个方向的话，我觉得其实有很多方向都是非常有价值的。

然后前期的话我们也经过了一些思考和论证，我们觉得现在我这边的话，主要有三个方向也在探索，一个是刚才我也在报告中介绍过了，就是无人机的综合管控，那么不管是从反无人机的方向来思考。

还是说从这个低空经济运维的方向来思考，就是因为后面咱们国家的低空资源，也逐步放开了以后，肯定也要建立一套空中的这种交通规则，那么需要对空中的目标，它的运行，包括一些情况来进行探测，来进行管控运维。

所以这个可能也是一个很好的方向，包括跟各个领域的一些技术做一些结合，然后第二个的话，就是这个临地安防，临地安防我们认为仍然具有很大的研究和落地的价值，因为现在不管人工智能发展到什么样的一个程度。

大家都在做一些那样炫酷的一些研究，但是实际上人工智能最好落地的一些场景，还是在安防上，安防能够创造很大的价值，包括在电信这边，我们有很多，在全国各地有很多很多的摄像头。

然后安防仍然是其中一个很重要的一个方面，然后在这个里面，就是刚才我讲的这个无约束条件下，其实还是存在很多种挑战，我们需要去解决，然后第三个的话，就是我们现在也是在结合大模型，多模态和生成式，做一些事情。

就是做一些agent相关的，智能体相关的一些工作，因为这个温达不是也指出，智能体研究可能有四个方面是比较有价值的，一个是反思，一个是规划，一个是使用工具的能力，然后还有一个是多智能体的协同。

我们现在主要是在做这个，利用大模型来做一些工具使用的，一种应用牵引的研究，我们认为这些方向的话，可能未来构建这种智能化的私人助手，智能化的这种助理，会是一个很好玩很有价值的一个方向。

然后这个安全风险的话，可能存在几个不同的方面吧，昨天我在那个新同院，开这个人工智能伦理方面的一个会，就是这个工信部那边制定了一个，关于这个人工智能科研和开发的，一个人工智能伦理方面审查的一个办法。

然后在里面我们也提到了很多这个，可能潜在的风险和解决的对策，可能主要包括几个方面啊，一个是 简要说一下，一个是数据的安全和隐私，一个是模型的误导和不实信息的传播，还有一个是网络的攻击和模型的安全。

然后还有一个是这个偏见和不公平，那么针对这样的几个风险的话，我们认为可能从几个方面来进行这个，采取一些措施，可能有一些缓解，一个是净化我们的这个训练数据的来源，还有一个是提升模型的准确性和透明度。

然后再有一个是加强模型的安全性测试，和伦理安全方面的监管，好 谢谢，我在高校 也不在产业，所以我这个没法给一个具体的，那我就讲点虚的 是吧，我感觉就是首先第一，在咱们国家是吧，首先你要说产业方向。

其实看上面那个文件，一般是面向国家战略需求，面向人民的生命健康 是吧，但还有一个 像我们高校说面向世界科技检验，这个不是产业的事，所以这是一个虚的，那么之后如果真要去，要真要考虑方向的话，怎么去思考呢。

我个人觉得就是，首先你也得要知道你那个场景，那个产业的场景，因为我没做产业，所以我只能根据我自己的理解，你那个产业的场景对于这个效果，就是它那个精度，或者那种可控要求有多高，如果你是一个非常对于精度。

就是让它回答非常，就不能让它出错，或者不能让它弄的话，我个人觉得目前大模型，还没到这个水平，就是传统的那种小的小模型，专业化的模型，它其实也还没到那个水平，所以这是，但如果你能够容忍它出错。

有时候它还能够它出错，它还能够比较有趣 是吧，那种娱乐性质的，我个人觉得这是肯定是没什么问题的，但只要你能够，让它输出 控制，控制它输出的那些内容，不违反法律或者不违反一些什么样的事情，这个是可以的。

但这里面最重要的原因是什么，还是从技术那个层面，就现在虽然这些模型，效果是不错，但是如果当你玩多了以后，它其实很重大的一个问题是什么，它很多东西它不可控，其实这是一个技术问题，但也有可能通过一种什么。

产品那个方式，像以前咱们做搜索引擎是吗，可以什么名单那些东西可以控制，但从技术手段上，从模型那个训练，包括它那个优化技，那个层面，这个可控性的确是很难的一个问题，至少从技术上，这个是我的一个理解，谢谢。

对 我的理解就是反正AI包罗万象，就我还是拿大模型举例子吧，然后同样是来自科研院所，所以场景举不出来，我就举行业吧，就反正我个人认为，就是行业数字化程度高的，然后数据格式比较统一规整的。

肯定是优先落地的，就比如说金融 电信，肯定是优先的对吧，然后相比其他的可能更传统的，比如说什么农业可能的，它可能就要稍微滞后一些，然后对我现在一个风险，我自己个人挺担心的，就是现在我看，反正我接触到的。

各个行业的同仁都说，我们要搞行业大模型，我跟金融企业合作比较多，国有四大行都要做自己的，所谓的行业大模型，每个行搞一个，就将来你真的说，一旦大规模落地了以后，我对能源就很担心，对吧，所有的。

你想所有的实体 市场主体，然后都有自己的一个，所谓什么垂鱼大模型，然后每天跟那跑，对吧，那我们消耗的最多的，其实最后是电力，那可能整个对国家的民生，都造成影响，所以我的建议就是。

大家在行业大模型的构建上，还是要稍微审慎一点，或者说得有一个统筹吧，其实重复建设也不太有必要，还是大家联合起来，可能比如说，电信行业的一个大模型，行不行 对吧，对吧，银行业的就一个。

然后用的时候也是类似于共享，那这样的话可能也会造成，避免造成一些资源的浪费，我就说这么多，我个人理解，其实AI+可以分成两个维度，第一个就是，之前完全没有使用AI的场景，那么现在添加到AI。

然后还有就是之前其实已经是AI化的，只是现在因为这种大模型，或者技术的提升，把AI的能力做进一步的，也是对应的提升，可能分成这两个方面，第一个我先说这个提升吧，其实现在因为大模型最开始。

大家可能引起大家的注意，就是在交互方式上，突然它能问什么问题都能回答了，现在包括又添加了各种的模态，其实我觉得在各类的传统的，对话相关的维度上，都可以做一个AI+，相当于是AI技术的一个提升。

比如像刚才提到智能客服，比如像家庭陪伴，还有甚至像博物馆讲解等等，但凡涉及到交互的，其实都可以做在AI维度上的一个提升，然后另外一个点的话就是，之前完全没有AI现在要基于大模型也好。

或者更新的AI技术的一个添加的话，其实现在反而倒不是很有明确，有这样的方向，因为确实即使没有大模型出现，之前AI已经发展了很多年，但凡能AI化的，其实都已经得到很多的探索。

所以我觉得更多的还是一个AI技术的提升，这个AI+我觉得是在原有AI的基础上，去加更多的AI的一个深度，就是这样一个点，然后我就补充这么一点，好 谢谢宋永博士，感谢几位嘉宾，就是说各位嘉宾从AI+。

从行业 从能源，以及大模型的这个行业大模型等等，各种角度来分析了这个问题，让我感受到行业大模型，目前的发展探索之路，可能还很漫长，需要我们所有人共同努力，然后接下来的话，我们收集了现场的一些问题。

然后这些现场的问题，是针对每一位嘉宾的，然后为了节省时间，我们就每一位嘉宾，然后直接简短地回答一下，第一个是给宋博的一个问题，在产业应用的层面，强化学习是必要的吗，相对SFD有什么优劣事，强化学习。

这个其实跟我刚才讲的内容是很相关的，其实在我们实践来看，强化学习确实是非常有必要的，因为就像我刚才也提到，可能在不同的场景，我们对模型的要求也是不同的，而不管是电信也好，其他各个做这种产业化的厂商。

那其实我们提供的能力，不管是对内对外，甚至就包括对内来讲，其实在不同的场景，我们也需要有不同能力，模型能力的限定，那其实在这个基础上，我们不管是这个场景化的SFD，还是场景化的这种强化学习。

包括这种PPO和TPO，其实都是非常有必要的，我们需要针对某些特定的场景化的能力，做定向的提升，那这个时候的话就是，就会涉及到这样的一个点，所以我觉得这个问题的答案肯定是肯定的，谢谢 谢谢邵韵博士。

下一个给敖翔博士的问题，请问在算力有限的情况下，您在大模型应用，尤其是聚焦于对小模型的应用方面，有什么更多的思考与启发，对 报告里展望也提到，就是说将来如果能够在参数训练层面，能够结合的话。

可能是一种更好的方式，简短回答就是这些，好的 谢谢敖翔博士，给黄磊博士的一个问题，在回归和生成任务上，LN网络是否有万能学习能力，在回归和生成是吧，对，首先第一就是因为我刚才讲的是一个分类。

然后因为机器学习就两个问题，因为包括数据也就只有两个，一个是离散的 一个连续的，离散的问题基本上是分类，然后连续的问题是回归，回归这个问题，现在我们这个结果是没有，但是我们现在学生在做的，在过程当中。

基本上从直观上应该是可行的，但是那个不是无穷深，有可能是无穷宽 还有一些别的机制，这里面简单透露一下，但是还在做 因为那个，整个数学的证明非常非常长，所以这是一个结果，至于生成这一块，因为刚才我讲的。

因为生成这一块的话，这怎么去定义啊 因为，我说过机器学就两个问题，一个回归和一个分类，如果你的生成如果是一个，如果是按那种predict，像token这种预测，它一个分类的那种，它就是一个分类问题。

如果你是像那个什么，视觉那种直接去拟合那个，那它就是一个回归问题，所以你是可以拆解的，但至于这个拆解过程当中，如何把那个条件信息，把这个理论给加进来，这个其实也是一个理论的研究问题，就是关于条件的这种。

从数学上往上走，这是我的一个回答 谢谢，好 谢谢黄磊博士，给赵健博士的问题，大模型会给各行各业赋能，当下未来大模型行业，会增加哪些就业岗位，对个人的技能学历有哪些基本要求，最后一个是什么 对个人。

对个人的技能和学历有哪些基本要求，一个直观的感受，我觉得现在，我不知道大家以前看deep learning的paper的话，可能大家发现这个deep learning的paper里面的公式非常少。

然后现在如果看大模型的paper的话，或者是看这个基于大模型做一些，其他问题的一些paper的话，可能基本上就找不到这个数学建模了，所以我觉得可能更多的技能的需求的话，是一个系统工程方面的这种技能。

或者是系统工程方面的思维，就是说从一个解决问题的视角，问题导向或者是需求导向，然后去做这个科研也好，或者是应用的创新也好，未来的这个可能比较好的一些方向的话。

我们现在是在做一些基于agent的方面的一些研究和应用，就是围绕这个衣食住行用等等不同的方面，来构建这种智能体，或者是叫智能的私人助手，那么实际上在不同的领域的话，都有一些关键的技术。

可以去跟大模型做一些结合，然后呢捆绑在一起，构成一个整个的pipeline，来给老百姓的日常生活中所面临的方方面面，来提供这种赋能和智能化的支撑，实际上现在也有很多这方面的研究在不断地涌现出来。

包括智能医疗啊 智能法律顾问啊，然后这种智能穿搭呀 智能剪辑呀等等，实际上我们也是现在不断地在这些垂直的领域，结合大模型 多模态理解和生成式等等，来做一些这种前沿的探索和应用的创新。

也是欢迎大家如果感兴趣的话，到我们电信研究院这边来，我们一起来做这些方面的一些有价值的事情，谢谢，谢谢赵建博士，最后一个问题是给我的，如何客观评估数据的质量，然后这个地方我的看法是这样的。

首先你自己要定义好什么是高质量的数据，我举个例子，广告 黄赌赌这类信息是你需要的数据吗，很多人可能答案是否定的，但是我们从另外一个角度来思考这个问题，广告本质上来说是属于人类创意的一个结晶。

很多广告的创意都非常好，那么你适当地学习一下这些创意性比较强的广告，会对你的模型能力是否有提升，这是第一个角度，第二个角度 黄赌赌相关的信息，我们举一个例子，一个小朋友他在他的这个生长过程中。

比如说从小学到大学，如果完全没有接触到黄赌赌的信息，那么当他步入社会以后，对黄赌赌信息之类的这种，分辨力以及抵抗力会是什么样子的，但是如果在他的成长过程中，我们适当地教导他这方面的信息。

告诉他什么是好的 什么是不好的，那么当他步入社会以后，会不会有其他的表现呢，这一个问题也可以反映在这个大模型的训练过程中，你对数据的理解，好 我就讲这么多，最后非常感谢全场的所有的观众和全场所有的嘉宾。

谢谢大家 今天的论坛到此结束，謝謝大家，謝謝大家。
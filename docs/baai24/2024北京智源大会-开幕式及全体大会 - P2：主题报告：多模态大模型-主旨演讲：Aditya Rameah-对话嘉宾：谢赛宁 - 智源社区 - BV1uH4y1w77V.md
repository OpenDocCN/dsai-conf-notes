# 2024北京智源大会-开幕式及全体大会 - P2：主题报告：多模态大模型-主旨演讲：Aditya Rameah-对话嘉宾：谢赛宁 - 智源社区 - BV1uH4y1w77V

能在这里发表演讲是我的荣幸，呃，我是Open AI视频生成的负责人，今天我想谈谈一些观察，关于，生成建模在过去的几年里一直在发展，我看到的事情正在走向何方，嗯，所以我想先谈谈呃，一个相当古老的结果，呃。

至少在深度学习方面，所以在2021年1月，我们发布了一篇关于大理一号的博客文章，规模很大，至少在当时，文本与量化图像联合训练的自回归变压器，嗯，我们决定这样做的原因是因为我们看到了生命的最初迹象。

带转换器的建模语言，我们想知道同样的技术是否可以扩展到模型，其他方式。

![](img/a8c89c84fd8693cea392fb1228c8040a_1.png)

最后效果还不错，模型能够将标题作为输入，把它转换成量化的图像补丁。

![](img/a8c89c84fd8693cea392fb1228c8040a_3.png)

所以它的工作方式是，您有提示符，您可以像普通语言模型一样建模，然后呃，我们还训练了一个，图像的vq自动编码器，图像的补丁只是增强了，与用于建模文本的正常词汇，整个被压扁的呃。

字符串只是由单个转换器建模为单个序列。

![](img/a8c89c84fd8693cea392fb1228c8040a_5.png)

所以呃，最酷的是，呃，我们和达利一起看了缩放，就像我们今天看到的语言模型的伸缩一样，所以一开始如果你训练，呃，一种小尺度自回归图像模型，你可以看到灯光和反射，重复对象。



![](img/a8c89c84fd8693cea392fb1228c8040a_7.png)

在小范围内为事物着色的能力，然后稍微大一点的规模，可以绘制具有多个属性的对象，改变艺术风格之类的。

![](img/a8c89c84fd8693cea392fb1228c8040a_9.png)

一旦你增加了更多的比例，您可以看到文本呈现之类的内容，成分概括，也是图像语境学习的标志，所以我们试着做一些事情，比如给达利·瑞文的累进矩阵，哪些是视觉智商测试，模特看到了，第一个呃。

这个网格里的八个元素，最后一个角，我们还尝试了图像到图像的翻译，在那里你给模型，呃，上半部分的图像，并要求它在下半部分画一些东西，这些东西开始起作用了，有时候。



![](img/a8c89c84fd8693cea392fb1228c8040a_11.png)

呃，拥有十亿参数模型，所以我们想知道如果你进一步扩大规模会发生什么。

![](img/a8c89c84fd8693cea392fb1228c8040a_13.png)

所以在阿里之后，我在想，你知道的，这是学习智力的好方法吗，呃，因为你在训练一个模特，压缩视觉世界中的所有像素，这似乎是一项相当困难的任务。



![](img/a8c89c84fd8693cea392fb1228c8040a_15.png)

有很多信息需要建模，有一些，当时有一些研究，暗示这不是真的该走的路，嗯。

![](img/a8c89c84fd8693cea392fb1228c8040a_17.png)

所以马克，呃，以前训练过的IGBT，这是第一个大规模的图像自动回归变压器。

![](img/a8c89c84fd8693cea392fb1228c8040a_19.png)

这个模型不是以文本为条件的。

![](img/a8c89c84fd8693cea392fb1228c8040a_21.png)

但从这个模型中真正巧妙的发现是，仅仅通过学习充分好地压缩图像，模型学习视觉世界的底层结构，最终也得到了很好的图像表示，嗯，例如，当您放大这些igpt模型时，他们开始在金雀花探针上得到很好的结果，但是。

这比剪辑和剪辑同时发布的效率要低得多，作为多莉一号，剪辑背后的想法是学习文本和图像交汇处的任何东西，所以如果你想象有一个带有文本和图像的维恩图，Clip使用对比损失来尝试学习信息，那是在两者的交汇处。



![](img/a8c89c84fd8693cea392fb1228c8040a_23.png)

这最终是数量级的，比igpt更有效地从图像中提取智能。

![](img/a8c89c84fd8693cea392fb1228c8040a_25.png)

我当时的结论是大理一号是一个有趣的项目，很高兴能继续努力，但这并不是如何提取的关键途径。

![](img/a8c89c84fd8693cea392fb1228c8040a_27.png)

来自视觉世界的智能。

![](img/a8c89c84fd8693cea392fb1228c8040a_29.png)

嗯，现在我要谈谈剪辑是如何工作的，它如何提取图像和文本交汇处的信息。

![](img/a8c89c84fd8693cea392fb1228c8040a_31.png)

我相信你们中的很多人已经对这一切都很熟悉了，但是剪辑学习一个图像编码器和一个文本编码器。

![](img/a8c89c84fd8693cea392fb1228c8040a_33.png)

所以文本编码器接受提示，图像编码器拍摄图像，在训练过程中给出了夹子模型。

![](img/a8c89c84fd8693cea392fb1228c8040a_35.png)

嗯，一个带有标题的配对图像列表，文本编码器对所有标题进行编码，图像编码器对所有图像进行编码，损失函数鼓励两个编码器匹配表示，嗯，每个图像及其相关标题。



![](img/a8c89c84fd8693cea392fb1228c8040a_37.png)

剪辑在它出来的时候是一个很大的范式转变，因为不需要手工制作的标签来训练一个好的分类器，做起来既耗时又痛苦，我们可以利用互联网上的自由文本，学习一个同时适用于所有领域的好分类器的模型。

所以如果你想把动物分类，您可以为动物的类别构造一个提示列表，你想分类的，然后现在，可以使用图像嵌入的点积，你想用所有的标题分类，然后取Softmax并使用这些分数来确定图像属于哪个类别。



![](img/a8c89c84fd8693cea392fb1228c8040a_39.png)

在这一点上，我你知道。

![](img/a8c89c84fd8693cea392fb1228c8040a_41.png)

似乎图像表示学习开始进化，呃，最初，深度学习有一些成功的初步迹象，我们都知道的金雀花分类纸，在那里，你训练一个分类器，它只是从图像中提取一些信息，即，呃，图像属于哪个类别的标签，嗯，许多年后，呃。

夹子出来了，现在我们能够利用互联网上的自由文本，学习通用分类模型，这样你就不需要那么多手工制作的功能工程了，过了一会儿，呃，最终，图像字幕器也是可伸缩的视觉学习者，所以与其用这种对比损失来建模。

文本和图像的交汇处是什么，我们可以训练一个有图像编码器的感知模型，查看图像并重建标题，就像一个学习从图像中预测文本的语言模型，所以随着时间的推移，事情似乎一直在简化，也许我们可以问一个问题，最终的结果。

我们最终会做什么，因为我们的失败，预算增加，所以看起来目标函数已经改变了，我们从图像中学习的方式已经改变了，当我们得到越来越多的计算，事情似乎变得更简单了，所以我想提供一个猜测，关于事情可能在哪里发展。

然后嗯，这就是我接下来要讲的。

![](img/a8c89c84fd8693cea392fb1228c8040a_43.png)

所以IGPT，T建议大规模生成模型自动学习数据的底层结构，最终产生良好的图像表征，考虑类似的结果是否也适用于文本到图像模型是很有趣的。



![](img/a8c89c84fd8693cea392fb1228c8040a_45.png)

事实上，它是这样做的，不久前出了一份报纸，你的扩散模型其实是个零点分类器，其基本思想是，即使你在建模给定文本的图像分布，该模型可转换为分类模型，而且它的工作方式和剪辑没有太大区别，呃，给了一个图像和呃。

候选标题，您可以使用扩散模型，呃，计算图像与标题匹配程度的分数，做这个比夹子贵多了，但如果你忽视这一点，它的工作原理相似，因为，它给你一个兼容性或相似性评分，在图像和候选标题之间，而这篇论文表明。

实际上，呃，稳定的扩散能够得到好的Imagenet探针，这是一个令人惊讶的结果，所以现在这让我们从一个范式，我们将文本作为模型的条件，或者更确切地说，我们正在根据图像来调节模型，和学习文本的模型。

到一个范例，我们将文本作为模型的条件，然后学习图像中所有剩余的熵，但不清楚这是否有效，也不知道我们受到了多大的打击，在额外的计算方面，我们需要花费来做到这一点。



![](img/a8c89c84fd8693cea392fb1228c8040a_47.png)

所以当我们研究多莉三号的时候，我们的一个发现是训练文本成像，生成模型变得更高效，因为您训练的标题更具描述性，所以如果你在真正描述性的标题下训练一个模型，它，在较短的字幕上的性能也更好。

由于它被训练在更长的字幕上，所以这表明有方向性，也许我们可以变得更好。

![](img/a8c89c84fd8693cea392fb1228c8040a_49.png)

用语言作为脚手架的无条件模型，这里有一些直觉来描述我的意思，所以呃，这里的第一列，呃，添加了不同噪声水平的图像，添加到图像中的噪声是为了表示，呃，其余不确定的信息，我们试图模仿，嗯。

所以如果图像中没有噪声，你想解释，呃，图像中的一切，你可以用标题来做到这一点，就像一个微不足道的标题，只是描述，你知道图像中每个像素的颜色，所以说，如果你想象把文本训练成图像模型。

得到这样一个描述性的标题，图像中没有不确定性，因为它可以读出像素值并呈现它们。

![](img/a8c89c84fd8693cea392fb1228c8040a_51.png)

你不需要深度学习，如果你在图像中添加一点噪声，嗯。

![](img/a8c89c84fd8693cea392fb1228c8040a_53.png)

模特要学的东西很少，就像表面的细节和纹理之类的，嗯所以现在有一些不确定性，呃，剩下的不确定性已经确定，可以用一个真正描述性的标题来解释，现在如果你在图像中添加大量噪声，有很多不确定性。

为了解释图像的其余部分，那是仍然存在的信号的剩余部分，你只需要像这样一个简短的标题，最终你知道，如果你在图像中添加大量噪声，呃，模特要学习一切，然后嗯，你知道的，呃，没有标题与。



![](img/a8c89c84fd8693cea392fb1228c8040a_55.png)

你知道的，只是纯粹的噪音，因为一切皆有可能，我们在这里的每个阶段都学到了什么，所以如果你有一个正在学习翻译的模型，你知道图像的像素值，它可能并没有真正学到任何有用的东西，如果你有更多的失败。

然后你可以学习一个模型来翻译真正的描述性图像，真正描述性的标题变成图像，直觉上，它可能不会学到很多，因为你给它的标题太描述性了。



![](img/a8c89c84fd8693cea392fb1228c8040a_57.png)

图像中没有太多的不确定性让它学习。

![](img/a8c89c84fd8693cea392fb1228c8040a_59.png)

如果你有更多的失败，你可以，呃，期待模式发挥作用，也许甚至用更短的标题，所以现在呃，标题为模型提供的拐杖更少，然后它在图像中建模更多的熵，最后，如果你有很多技能，也许你可以用。



![](img/a8c89c84fd8693cea392fb1228c8040a_61.png)

呃，完全没有条件反射，这里的想法是。

![](img/a8c89c84fd8693cea392fb1228c8040a_63.png)

也许呃，超描述性字幕培训，是一种帮助在小范围内对感知相关的位进行优先级排序的方法。

![](img/a8c89c84fd8693cea392fb1228c8040a_65.png)

你可以希望从真正描述性的标题培训中获得转移。

![](img/a8c89c84fd8693cea392fb1228c8040a_67.png)

到简短字幕培训。

![](img/a8c89c84fd8693cea392fb1228c8040a_69.png)

所以最终，呃，你可以放大模型，在小规模上，希望它仍然可以是一个很好的图像生成模型，当你给它真正描述性的标题时。



![](img/a8c89c84fd8693cea392fb1228c8040a_71.png)

在大范围内，它可以学习语言难以描述的东西，填补了剩下的空白。

![](img/a8c89c84fd8693cea392fb1228c8040a_73.png)

所以这表明有方向性，也许我们可以交换，呃，从学习到示范文本，从照片上看，学习建立图像模型，给定的文本，它可能不是那么高的计算效率。



![](img/a8c89c84fd8693cea392fb1228c8040a_75.png)

击中从一个到另一个。

![](img/a8c89c84fd8693cea392fb1228c8040a_77.png)

最终，如果你在真正描述性的标题上放大一个模型，我们有证据表明，也许无条件建模任务的性能也会随着时间的推移而提高，这表明你知道最初我们不太使用文本，呃，我们只是在预测一些信息来训练图像分类器。

然后我们开始在训练模型的过程中更多地使用文本，像剪辑和图像捕捉器，你也知道，最终，我们，我们看到我们可以通过使用非常描述性的标题来训练良好的生成模型，呃，我们在大理三号和索拉做的，最终。

随着我们规模的扩大，也许语言只是变成了脚手架，以后可以丢弃的，你知道视觉世界可能是一个比文本更通用的界面。



![](img/a8c89c84fd8693cea392fb1228c8040a_79.png)

因此，这代表了对模型如何训练的思考的变化，呃，所以之前我们想修复一个数据集，并找到更好的目标功能和架构来改善感知，但就最近而言，我认为趋势发生了一点变化，这样我们就确定了目标函数和模型架构，意义，呃。

目标函数只是一个简单的极大似然目标，在那里我们试图重建一切，而模型架构只是一个变压器，我们将爬上数据集，意义，我们如何建模，不管我们要重建的是什么，呃，例如通过使用呃，更多描述性标题，然后呃。

我们如何对数据中所学到的内容进行优先级排序。

![](img/a8c89c84fd8693cea392fb1228c8040a_81.png)

所以接下来我将稍微谈谈发生了什么，当我们，呃，遵循这一范式，所以说。

![](img/a8c89c84fd8693cea392fb1228c8040a_83.png)

来自图像的文本，现在我们从文本中建模图像，随着我们不断增加计算，似乎语言的作用正在被纳入视觉。

![](img/a8c89c84fd8693cea392fb1228c8040a_85.png)

我们在达利二号上看到了一些有趣的事情，在那里你可以进行有趣的风格转换，所以你拍一张照片，你可以用剪辑嵌入算法，将更改应用于，呃，保留所有其他细节，但只改变一些，嗯，在达利一号上。

我们在上下文中看到了光的迹象，足够规模的学习，所以你可以给模型上半部分的图像，然后让它画图像的下半部分，对图像的上半部分进行一些更改，模型从来没有被明确地训练来完成这样的任务，但在足够大的规模下。

它最终还是学会了这一点，嗯，所以当时，感觉这可能是一条通往各种图像的通用接口的路径，操纵，图像处理任务，嗯，现在你知道我们开始得到可靠的视频生成模型，它表明在未来。

也许我们可以给模特看一张我们所拥有的照片，并要求它生成一个视频，为了得到我们想要的。

![](img/a8c89c84fd8693cea392fb1228c8040a_87.png)

嗯，这是我的简单观察，呃，也许学习压缩一切可能是正确的方法，毕竟，而语言只是使其实用的必要脚手架，最终可能还不够，呃，我们可能需要其他技巧才能，通过重建我们看到的一切来有效地训练视频模型。

但语言似乎能帮助我们到达那里，但最终可以归入视觉智能，最终这将给我们一个真正通用的界面，为了模拟我们想要的任何东西，这就是我的观察，嗯，我希望回答任何问题都很有趣和愉快，谢谢你，谢谢你。

谢谢你的精彩公斤。

![](img/a8c89c84fd8693cea392fb1228c8040a_89.png)

现在呢，我们有十分钟的时间进行问答，我想邀请纽约大学的助理教授，算法的作者签名Xen加入Q和A会话，嘿嘿，我听得见你听得很清楚，是呀，呃，是啊，是啊，这真是一次精彩的谈话，呃，谢谢分享。

但我在纽约大学当助理教授，我知道你也是从那里毕业的，很高兴终于见到你了，嗯，所以我准备了一些问题，但首先，我只想承认，就像，你知道的，伟大的贡献使你，你的团队已经，以及对整个人工智能领域的影响。

通过许多开创性的项目，在他们的世代和智慧中，嗯谢谢你，然后嗯，是啊，是啊，就像呃，我想我想开始这次谈话，嗯，我有一个问题，对嗯，这实际上是我从你以前的账户上看到的，一旦帖子发布，呃，报价。

语言模型被高估，不得不说，呃，从某种背景，我真的很喜欢这个说法，呃，但你能看到更多关于它的信息吗，就像你知道的，呃，你认为你们这一代人会走上，我会把我们引向每一只眼睛，你如何看待建模人类语言之间的关系。

与感官丰富的现实建模，是啊，是啊，我绝对认为，所以说，嗯，在任何给定的视频中都有很多信息可以拍摄，视频中的许多信息不容易用语言表达，嗯，例如，我谈到了瑞文的累进矩阵，你可以从一些类型的智力中学习。

难以建模的愿景，仅仅通过学习语言，嗯，所以我认为语言将是一个重要的部分，呃你们都知道，获得更智能的系统，可以对事情进行推理，在某一点上，呃，我想我们应该把语言和视觉结合起来，它是一种更通用的接口。

你也知道，我觉得，我确实认为模拟任何你想要的东西的能力，将是重要的一步，未来的垫脚石，牛逼，是啊，是啊，关于这个问题的后续讨论，你说的语言可以，希望它能成为你智力的脚手架，那么如何确保，就像，你知道的。

语言不是捷径，因为它确实提供了一个非常强的先验，就像我的，只是为了弥补视觉表现的不足，你对此有什么想法吗，我想我希望发生的是当你，你知道的，用真正的描述性标题训练文本到图像模型，它要学的东西不多，嗯。

但我们在大理三号看到的是，当您在描述性标题和一些简短标题上训练模型时，短字幕的性能提高，由于接受了更多描述性标题的培训，所以方向性，它让我们想到也许我们可以用语言来训练生成模型，并帮助他们更有效地训练。

但随着我们投入越来越多的规模，模型不太依赖语言作为条件信息，开始自己想办法，是啊，是啊，我们换个话题吧，把注意力集中在，你知道的，真正让Sara成为可能的天赋，因为你知道。

比尔和他和我一起研究扩散变压器，在他博士的最后一年，他的团队一直致力于长视频的生成，通过他在伯克利的博士学位，嗯，但想想就很了不起，你知道的，比尔和他的团队，他们的博士可以做这么大的，你知道的。

对实地的影响，背后有什么秘密吗，你知道的，OPI的文化，或者喜欢这种情况发生的常规文化，就像，你知道的，真正赋予年轻的研究人员真正利用他们的激情和过去的经验，做出这样的贡献，是啊，是啊，这是个好问题。

嗯，我想有一些东西可以打开AI，使这种事情成为可能，其一是我们的招聘策略，这是完全不同的，我想从其他组织，蒂姆和比尔，当然有ph值，D和相当强的出版记录之前，他们来开放人工智能，但我们过去也招聘过员工。

只是因为我们更关注那些有前途的人，但可能没有机会获得正式的学分，例如，我想詹姆斯·贝克尔是达利三号的主角之一，并帮助将音频支持放入GPT 4O，他是那种人的好榜样，呃我想，第二。

也许我们的重点是有一个长期的研究目标，那不是真的受，实地的逐日或逐月变化或进展，那就是我们设定一个在未来足够遥远的目标，嗯，我们认为是可以实现的基础上，事情的发展，我们可以完全专注于此。

而不是对一天天变化的事情做出反应，嗯最后，我认为每个人拥有大量的GPU往往会有所帮助，是啊，是啊，我回到你身边，年轻曾经告诉我，你知道你大学时和他一起工作，你在想，你知道的，申请你的博士学位。

你的互联网睁开的眼睛，决定留在那里，嗯，你知道的，就像我也注意到一样睁开眼睛，呃，有许多非常成功的研究人员并没有真正经历过这些，你知道所谓的传统，有点像研究，正式研究培训，嗯，我想听听你的想法，比如。

你知道的，呃，你知道基本上高等教育的作用，现在，你觉得博士也被高估了吗，呃，以某种方式，然后嗯，我不确定你是否能看到，这就像这次活动中许多热情的面孔，我不知道你是否有什么建议，呃，你知道。

就像下一代的研究人员想在，爱，是啊，是啊，我想这是个好问题，嗯，我觉得，因为事物被统一成一种单一的范式，其中我们有一个可伸缩的体系结构，哪个是变压器，我们知道如何表示数据，呃。

即用于文本的bp标记和用于可视化数据的补丁，事情有点趋同，所以计算是获得更好结果的最重要因素，改变焦点，我想对于你在学术界从事的项目来说，我认为可解释性是一个方向，嗯。

也可能关注现有深度学习系统仍然失败的邪恶和任务，嗯和诸如此类的事情，我想现在读博士很难，期待在一些事情上得到最先进的结果，只是因为它，你知道所需的资源，比以前高得多了，是啊，嗯，但顺便说一句。

我知道喜欢，我希望你有这个研究访问程序，比如代理一些学分做MS和多模态学习的研究，所以谢谢你，我想你知道从我的角度来看，我认为有很多机会真正建立，工业界和学术界之间的这种伙伴关系和合作，嗯是的。

我觉得很多人都很兴奋，我们真的很喜欢你在社交媒体上分享的视频，对嗯，但问题是，我们还没有得到它，嗯和我，我相信你已经看过最近发布的，或许来自短视频公司质疑的清廉模式，也喜欢卢阿艾的梦幻机器模型。

所以我想听听你的想法，你知道的，你如何看待视频生成空间中的计算，我们期待着Sora的一些新的更新吗，是啊，是啊，这是个好问题，我觉得最重要的是，呃，那是我们的想法。

对于像发布一个强大的视频生成系统这样的事情来说，主要是安全的，它会对社会产生什么影响，嗯，我们要小心确保当我们发布像Sora这样的模型时，呃，你知道的，它是，我们知道它它。

人们不会用它来做错误信息之类的事情，模型的行为方式是在，人们的期望，我觉得要保证模型的安全需要做很多工作，为了能够，你知道，有一个自信的释放，但这是我们的首要任务，嗯，我认为总的来说，有竞争是很好的。

就像，它是，很高兴看到其他实验室和公司发布视频生成模型，也是，我认为有一个增殖，从事不同方法工作的人的激增有点像激发创造力，嗯，如果我回想一下像多莉二号这样的事情。

我们在谷歌大脑和Openai之间打了一场乒乓球，每个实验室都会发表一篇论文，某种扩散模型，例如rafl和alex写了论文扩散模型，图像合成中的bean，并引入了分类器引导。

然后乔纳森·霍和其他人发布了分类器免费指南，创新层出不穷，所以我认为在视频生成领域看到有趣的产品创新是很棒的，也是，我希望你们知道，我们可以更多地了解这些工具是如何有用的，在艺术家和创作者手中，酷。

是啊，是啊，谢谢你，我想我们几乎所有的时间，也许我可以再问一个关于创意世界的问题，所以每次去纽约的人工智能电影节，我问了所有，你知道的，艺术家和电影导演有一个问题。

就像你真正需要的视频生成模型的一个功能，令人惊讶的是，他们的答案都一样，他们说可控性或更好的可控性，所以我想知道这是不是你知道的，也许在它的下一个版本中看到了，会专注于球，或者喜欢。

因为我知道你和很多不同的艺术家合作过，嗯，你对此有什么了解吗，你认为你知道吗，语言将是最终的媒体界面，为创意世界提供更好的可控性，是啊，是啊，嗯，我想我过去说过的很多话，谈论的是语言的作用。

在这些模型里，我想，更好的可控性和减少老虎机方面可能是头号特点，我们也从我们共事过的人那里得到的要求，我确实认为这样做的能力以及重用角色和资产的能力，之前场景中的其他元素将是一个巨大的游戏规则改变者。

只是因为这似乎是第一件事，嗯，做出来，好让你知道，视频生成模型实际上在生产设置中变得有用，嗯，我觉得这有点有趣，因为我谈到了你是如何知道，我们很早就在大理一中看到了这些在上下文学习能力中的出现。

现在你知道这些能力是，在投入生产的路上，好啦，是啊，是啊，像我们这样的组织者可能会有时间再问一个问题，如果你不介意的话，嗯是的，所以我想问一些关于数据的问题，嗯，所以，因为我知道很多喜欢，你知道的，呃。

数据使用我的Sora可能来自网络视频，嗯，但你觉得这就像，尤其是走向阿吉的道路，就像通过一种真正的智慧，你认为像现在这样，像网络视频就足以支持这个目标，或者我们需要像，你知道的，发现新的数据源。

甚至像不同的感官媒介，呃，帮助解决这个问题，是呀，目标是的，这是个好问题，我觉得，我认为存在的数据，嗯，我认为我们可以通过扩大模型来继续取得很大的进展，因为有这么多可用的数据，嗯。

但我想很多有趣的事情会发生，一旦模型有能力成为自己的世界模拟器，你可以开始做一些事情，比如在上下文中运行，视频生成中的仿真，模特本身，嗯，这样我们就可以开始结合，你知道的。

所有来自现实世界环境的多样性和有趣的限制，开始学习有趣的东西，酷，谢谢你的真知灼见，嗯，我想在我们关门之前，嗯，我做了，你有什么想分享的吗，嗯，有观众在，尤其是去中国的人工智能通勤，否，我的意思是。

在这里谈话很愉快，很荣幸向大家介绍，所以谢谢你，有我这么好，谢谢你，是啊，是啊，和你谈话真的很愉快，嗯，让我们再次感谢一个细节。


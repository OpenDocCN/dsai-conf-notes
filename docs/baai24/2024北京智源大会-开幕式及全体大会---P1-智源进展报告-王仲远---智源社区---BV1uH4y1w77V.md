# 2024北京智源大会-开幕式及全体大会 - P1：智源进展报告：王仲远 - 智源社区 - BV1uH4y1w77V

尊敬的各位领导 各位来宾，各位专家 各位朋友，大家上午好，再次欢迎大家来参加今天的志愿大会，我是王仲远，非常荣幸能够从黄老师手中接过接力棒，在志愿大会上继续向大家报告。

志愿过去一年的研究和工作方面的一些进展，志愿研究院是2018年11月份成立的一家，人工智能领域的新型研发机构，我们致力于推动人工智能技术的原始创新，志愿的含义是智能的源头，我们希望能够成为学术思想。

基础理论 顶尖人才 企业创新，以及发展政策的源头，志愿大厦位于海淀区城辅路150号，这里也是海淀区人工智能创新街区，以及海淀区人工智能大模型集聚区的核心区，因此也非常欢迎大家来志愿大厦。

坐一坐进行学术的交流，志愿是一家非盈利性的科研机构，我们致力于人工智能领域前瞻性，战略性 原创性的研究和技术突破，我们拥有顶尖的学术顾问委员会，张红江博士是我们的顾问委员会主任，那么其余七位委员。

均来自全球最顶尖的学术机构的院士，在过去五年，志愿率先预见了人工智能大模型时代的到来。

![](img/e5ab7a614e5022ba7175468443bb4b05_1.png)

早在2020年10月份。

![](img/e5ab7a614e5022ba7175468443bb4b05_3.png)

我们就已经成立了一支百人的技术公关团队，开始进行悟道系列大模型的研发。

![](img/e5ab7a614e5022ba7175468443bb4b05_5.png)

在2021年3月份的时候呢，我们发布了悟道1。0。

![](img/e5ab7a614e5022ba7175468443bb4b05_7.png)

6月发布了悟道2。0，那么悟道系列大模型的发布，在当年都创造了中国首个全球最大这样的一系列的记录，那么进入到2022年之后，我们的悟道2系列大模型继续向多语言多模态，去持续地迭代，在去年的志愿大会上。

我们也发布了悟道3。0系列的成果，那么应该来说，志愿研究院与大模型这三个字是紧密的关联。

![](img/e5ab7a614e5022ba7175468443bb4b05_9.png)

甚至大模型就是志愿最早提出来的。

![](img/e5ab7a614e5022ba7175468443bb4b05_11.png)

进入到2023年，大模型从研究机构的科研成果开始向产业界，逐步地发展，我们也看到在过去的这一年，百花齐放，有越来越多的大模型在过去的这一年发布。



![](img/e5ab7a614e5022ba7175468443bb4b05_13.png)

那么如整个人工智能的发展浪潮，过去七八十年的这样的一个发展历程，那么以2023年为界，基本上可以分为两个大的阶段。



![](img/e5ab7a614e5022ba7175468443bb4b05_15.png)

在2023年之前，都属于弱人工智能时代。

![](img/e5ab7a614e5022ba7175468443bb4b05_17.png)

也就是整个人工智能的模型，它是针对特定的场景 特定的任务，那么需要去收集特定的数据，训练特定的模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_19.png)

那么比如说战胜人类世界围棋冠军的AlphaGo，它能够在围棋上下得非常好，但是它却无法直接用来解决医疗问题，无法直接用来做自动驾驶，虽然方法可以借鉴。



![](img/e5ab7a614e5022ba7175468443bb4b05_21.png)

但是针对不同的场景任务，都需要去做数据和模型的重新的收集和训练，那么进入到2023年，随着大模型的发展，人工智能将逐步地进入到，通用人工智能的时代，那通用人工智能最大的一个特点。



![](img/e5ab7a614e5022ba7175468443bb4b05_23.png)

就是它的规模非常的大，模型具备涌现性，同时它能够跨领域的通用性，那么在过去的这一年，Scaling Low是被反复讨论的一个名词。



![](img/e5ab7a614e5022ba7175468443bb4b05_25.png)

它的一个基本的含义呢，就是说随着模型的参数，以及训练数据量和计算量的持续的增大。

![](img/e5ab7a614e5022ba7175468443bb4b05_27.png)

模型的性能也持续的提升，但是如果我们回看。

![](img/e5ab7a614e5022ba7175468443bb4b05_29.png)

过去七八十年人工智能的发展历程，尤其是神经网络的发展历程。

![](img/e5ab7a614e5022ba7175468443bb4b05_31.png)

实际上Scaling Low并不是一个新鲜的事物，那么这张图的左边的部分，实际上是我2018年做的一张PPT，那么我们可以看到。



![](img/e5ab7a614e5022ba7175468443bb4b05_33.png)

事实上在人工智能过去的三次发展的烂潮，每一次新的人工智能技术的突破。

![](img/e5ab7a614e5022ba7175468443bb4b05_35.png)

都是伴随着模型参数，训练数据量，计算量的一个持续的攀升。

![](img/e5ab7a614e5022ba7175468443bb4b05_37.png)

所带来的人工智能领域的一个突破。

![](img/e5ab7a614e5022ba7175468443bb4b05_39.png)

那么进入到大模型的时代，我们看到大模型的参数，是在以量级。

![](img/e5ab7a614e5022ba7175468443bb4b05_41.png)

每年都以量级的，提升一个量级的速度在发展，在2018年时候。

![](img/e5ab7a614e5022ba7175468443bb4b05_43.png)

BERT的模型基本上还是一级的参数，到2021年GPT-3。

![](img/e5ab7a614e5022ba7175468443bb4b05_45.png)

就已经是1750亿的参数，到去年的GPT-4，业内普遍认为是1。8万亿的参数，可以看到它与人类大脑的参数。



![](img/e5ab7a614e5022ba7175468443bb4b05_47.png)

科学家们普遍认为人类大脑的参数，在100万亿到1000万亿之间。

![](img/e5ab7a614e5022ba7175468443bb4b05_49.png)

那么整个大模型与人类大脑的参数，其实从过去几年，从相差100万倍，到1000倍，到去年100倍。

![](img/e5ab7a614e5022ba7175468443bb4b05_51.png)

那么如果按照大模型的这个速度继续发展，我们会认为在未来几年。

![](img/e5ab7a614e5022ba7175468443bb4b05_53.png)

大模型的参数很可能就会，改善或者超过人类大脑的参数。

![](img/e5ab7a614e5022ba7175468443bb4b05_55.png)

这也是我们认为AGI时代，有可能会在未来几年。

![](img/e5ab7a614e5022ba7175468443bb4b05_57.png)

到来的一个很重要的原因，那么如果AGI时代会到来，它可能的一个技术演化的路径，会是怎样的呢，我们知道在过去几年，绝大部分的这个科研的关注度，包括咱们产业的关注度，都在大语言模型的突破。

但大语言模型依然是一种，单模态的模型，那么在这个世界上，除了文本这个数据以外，还存在大量的图像，视频 音频等等这样的多模态的数据，而这些数据量呢，可能是文本数据的，十倍 百倍 乃至千倍的规模。

因此呢在这两年开始，这些年开始也开始有多模态，大模型这方面的一些研究，但基本上呢产业界里面还是，针对不同的模态 跨模态，就有各自的模型，同时呢理解和生成也是分开的，那么我们认为从技术发展的路径来看。

最终会形成一种统一的多模态大模型，它能将理解和生成统一。

![](img/e5ab7a614e5022ba7175468443bb4b05_59.png)

它能将不同的模态数据进行统一，那么当多模态大模型能够理解，和感知 决策这个世界的时候。

![](img/e5ab7a614e5022ba7175468443bb4b05_61.png)

那它就会有可能进入到我们的物理世界，那么如果进入到宏观的世界跟硬件结合，那么这就是巨声大模型的发展方向，如果它进入到了微观世界。



![](img/e5ab7a614e5022ba7175468443bb4b05_63.png)

去理解和生成生命分子，那么这就是AI for Science，那么不论是巨声模型，还是AI for Science，亦或是多模态模型。



![](img/e5ab7a614e5022ba7175468443bb4b05_65.png)

都会促进整个世界模型的发展，最终推动人工智能技术向，AGI方向发展，那么基于这样的一些技术判断，智源研究院在，多模态大模型 巨声大模型。



![](img/e5ab7a614e5022ba7175468443bb4b05_67.png)

以及生物计算大模型上，将在未来几年持续地投入研发，那么今天也非常高兴，借着智源大会的这样一个场合，向各位朋友介绍一下，我们智源在大模型上的全家桶，那么今天的这个报告里面，会包含五部分的内容。

分别是我们在语言大模型，多模态大模型，巨声大模型，生物计算大模型，过去一年的一些研究方面的一些进展，另外一个工作是支撑，所有这些大模型技术迭代的一个基座，也就是一个算力集群的操作系统。

好 首先我们来看看智源研究院，过去一年在语言大模型方面的一些进展，我们知道过去这一年，其实各家公司 各家企业。



![](img/e5ab7a614e5022ba7175468443bb4b05_69.png)

都训练了大量的模型，尤其是大语言模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_71.png)

那么企业已经做的事情，智源研究院就不会再去重复地做。

![](img/e5ab7a614e5022ba7175468443bb4b05_73.png)

对于语言大模型的历史使命，在过去几年智源已经。

![](img/e5ab7a614e5022ba7175468443bb4b05_75.png)

为整个技术的推动，整个产业的发展做出了卓越的贡献，因此在大语言模型方面。

![](img/e5ab7a614e5022ba7175468443bb4b05_77.png)

我们主要要解决产业界的，共性的一些痛点，那哪些是产业的共性的痛点呢。

![](img/e5ab7a614e5022ba7175468443bb4b05_79.png)

比如说算力的缺乏，那么因此我们与中国电信。

![](img/e5ab7a614e5022ba7175468443bb4b05_81.png)

人工智能研究院一起联合研发了，一种基于伸展技术训练的。

![](img/e5ab7a614e5022ba7175468443bb4b05_83.png)

全球首个低碳单体，稠密万亿语言模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_85.png)

简单来说我们就使用了，行业里面不到10%的算力。

![](img/e5ab7a614e5022ba7175468443bb4b05_87.png)

也就112台A800，那这样的一个算力呢，我们就能够训练出。

![](img/e5ab7a614e5022ba7175468443bb4b05_89.png)

这样的一个Dense Model，万亿参数级别，同时在整个训练的过程。

![](img/e5ab7a614e5022ba7175468443bb4b05_91.png)

基于我们最优的超参预估技术。

![](img/e5ab7a614e5022ba7175468443bb4b05_93.png)

我们实现了整个训练全过程的，零调整 零重视。

![](img/e5ab7a614e5022ba7175468443bb4b05_95.png)

最为关键的是，我们不仅会将这个模型开源，我们还会将其中的技术细节。

![](img/e5ab7a614e5022ba7175468443bb4b05_97.png)

Loss曲线全部进行开源，那么这也是智源研究院。

![](img/e5ab7a614e5022ba7175468443bb4b05_99.png)

为开源社区，为整个产业界所做出的，重要的贡献。

![](img/e5ab7a614e5022ba7175468443bb4b05_101.png)

那么我们整个模型，其实依然正在训练过程中，我们对于在伸展技术训练的，这个中间的一个过程的版本，我们也进行了评估，那么评估的结果显示，我们的这个BPP的Loss曲线，确实要优于Lamma-Sray。

那么整个万亿级别的Dense Model，当我们把它训练完成之后，我们将把它完全地开源，也希望能够为社区训练，万亿参数的稠密模型，提供一个优秀的初始参数的版本，避免万亿参数模型，早期难以收敛的。

这样的一些具有挑战性的问题，同时基于这样的一个基座模型，所训练出来的对话模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_103.png)

我们也进行了一个初步的评测，结果显示它能达到GDP-4，80%到90%的水平。

![](img/e5ab7a614e5022ba7175468443bb4b05_105.png)

那么请大家要注意，我们仅仅使用了100余台的A800机器，来训练这样的一个模型，那么除了算力紧缺的这样的一个问题之外，大模型在产业界落地最重要的，另外一个挑战就是它的幻觉问题。



![](img/e5ab7a614e5022ba7175468443bb4b05_107.png)

那么在这边我也想向大家隆重地，再次介绍我们的BGE模型，那么我相信所有产业界的朋友，一定对于这个模型是非常非常的熟悉，那么因为它是全球下载量最高的，国产AI模型，也是最普及的开源项量模型。

那么我们的研发团队呢，基于这种创新性的无监督域训练，和多阶段的对比学习，以及构建了一个多语言，关联文本的数据集 CMTP，那么基于这样的一个高质量的数据集，以及我们创新的算法，BGE模型从发布之初起。

就一直保持国际领先的位置，那么也正是得益于这样的，又好用又轻量级的这样的模型，所以它在开源社区管受欢迎，我们可以看到它的下载量是持续的攀升。



![](img/e5ab7a614e5022ba7175468443bb4b05_109.png)

并且得到了全球主流大模型应用框架的集成，包括HackinFace，Lamma Index，LamChain等等，同时各家云服务产商像Azure，AWS 火山引擎，腾讯云 华为云 百度云。

都集成了BGE的模型，并对外提供商用，我想这就是智源研究院对于开源社区，对于整个产业界的一个重大的贡献，那么以上就简要的介绍我们在，语言模型方面解决共性问题的，一些研究的一些进展。

下面我想给大家报告一下，我们在多模态大模型的，过去一年的一些研究的进展，多模态大模型依然处于一个，持续的迭代和演进，技术路线还没有收敛，那么因此智源研究院，在过去的一年持续地在。



![](img/e5ab7a614e5022ba7175468443bb4b05_111.png)

视觉多模态领域发布了，各项领先的研究成果，引领整个开源社区。

![](img/e5ab7a614e5022ba7175468443bb4b05_113.png)

去年7月份的时候我们发布了，第一代的EMU，这是一个生成式多模态预训链模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_115.png)

去年12月份的时候我们发布了EMU2。

![](img/e5ab7a614e5022ba7175468443bb4b05_117.png)

它截至目前依然是开源社区最大，性能领先的生成式多模态大模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_119.png)

那么今年2月我们还发布了，EVA CLIP 18B模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_121.png)

它是开源社区最大，性能领先的180亿参数。

![](img/e5ab7a614e5022ba7175468443bb4b05_123.png)

视觉表征的CLIC模型，它也被用于非常多的，多模态大模型中的视觉编码器的部分。

![](img/e5ab7a614e5022ba7175468443bb4b05_125.png)

那么整个多模态大模型过去这几年，以及在未来的几年，我相信都会非常的火热。

![](img/e5ab7a614e5022ba7175468443bb4b05_127.png)

但是它的发展现状是，此多模态非彼多模态，我们知道在行业里面，各种模态的转换，已经有了很多优秀的模型，比如说像图像理解和视频理解，有GPT-4V，比如说像图片生成。

有Stable Diffusion DALLE。

![](img/e5ab7a614e5022ba7175468443bb4b05_129.png)

比如说像视频生成有SolarWheel，比如说像语音理解，有最近发布的GPT-4O。

![](img/e5ab7a614e5022ba7175468443bb4b05_131.png)

那么每一种模态之间，都有这样的一个主流的一些模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_133.png)

它们以多种模型的方式来存在，那么从技术路线上来看，到底是使用Diffusion Model，还是使用Auto-Regressive。



![](img/e5ab7a614e5022ba7175468443bb4b05_135.png)

到底是这种单一的跨模态，还是统一的多模态。

![](img/e5ab7a614e5022ba7175468443bb4b05_137.png)

那么到底是理解和生成应该分开，还是应该结合，那么到底是基于这种，组成式的 组装式的这种多模态，还是要原生的多模态。



![](img/e5ab7a614e5022ba7175468443bb4b05_139.png)

其实存在不同的技术路线的一些争论，那么智源研究院呢，以终为始我们，基于对于前面的技术路线的发展的判断。



![](img/e5ab7a614e5022ba7175468443bb4b05_141.png)

我们还是非常坚定地要走，统一原生的多模态的技术路线。

![](img/e5ab7a614e5022ba7175468443bb4b05_143.png)

我们去挑战整个行业里面，最难 最具有挑战性的一个技术路线。

![](img/e5ab7a614e5022ba7175468443bb4b05_145.png)

那么这个技术路线如果实现突破，相信对于整个产业界。

![](img/e5ab7a614e5022ba7175468443bb4b05_147.png)

对于整个社区，又将是一次重大的技术贡献。

![](img/e5ab7a614e5022ba7175468443bb4b05_149.png)

那么这就是我们正在训练中的额苗山，它是统一了文字 图像 视频。

![](img/e5ab7a614e5022ba7175468443bb4b05_151.png)

使用自回归的技术路线。

![](img/e5ab7a614e5022ba7175468443bb4b05_153.png)

那么实现了图像 视频 文字的输入和输出，并且具备更多模态的可扩展性。

![](img/e5ab7a614e5022ba7175468443bb4b05_155.png)

那么我们的额苗山系统。

![](img/e5ab7a614e5022ba7175468443bb4b05_157.png)

目前其实依然是正在训练的过程中，很坦然地讲 中间的技术难度和坑还是不少的。

![](img/e5ab7a614e5022ba7175468443bb4b05_159.png)

那么我们今天非常高兴地。

![](img/e5ab7a614e5022ba7175468443bb4b05_161.png)

借志愿大会的这样的一个场合，也跟大家分享我们训练中。

![](img/e5ab7a614e5022ba7175468443bb4b05_163.png)

目前的一些进展，那么整个额苗山的研发的目标。

![](img/e5ab7a614e5022ba7175468443bb4b05_165.png)

是原生的多模态世界模型，那么在这里原生指的是。

![](img/e5ab7a614e5022ba7175468443bb4b05_167.png)

我们从一开始就会将多种的模态进行融合，同时将生成与理解进行融合。

![](img/e5ab7a614e5022ba7175468443bb4b05_169.png)

能够扩展，并且由于是Auto-regressive的框架。

![](img/e5ab7a614e5022ba7175468443bb4b05_171.png)

它也能够进行持续的，可控的这样的一种交互。

![](img/e5ab7a614e5022ba7175468443bb4b05_173.png)

这是我们额苗山中间的一个checkpoint的模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_175.png)

目前能够具备的能力，所以这是它的图像生成能力。

![](img/e5ab7a614e5022ba7175468443bb4b05_177.png)

可以看到它的图像生成能力，还是非常非常地优秀，那么我想强调的一点是，它不是基于Diffusion Model，而是基于Auto-regressive的，这样的一个自回归网络的额苗山。



![](img/e5ab7a614e5022ba7175468443bb4b05_179.png)

同时同样的这样的一个模型，它也能够进行视频的生成，那么这是我们额苗山。

![](img/e5ab7a614e5022ba7175468443bb4b05_181.png)

当前一些视频生成的，一些中间的一些结果，我们可以看到它还是能够。

![](img/e5ab7a614e5022ba7175468443bb4b05_183.png)

去捕捉到整个这个世界。

![](img/e5ab7a614e5022ba7175468443bb4b05_185.png)

世界模型的一些规律，那么中间依然有不完美的地方，但是我们的模型依然在持续的。

![](img/e5ab7a614e5022ba7175468443bb4b05_187.png)

训练的过程中，同样这个模型也是基于自回归的网络，是与刚才的图像生成是同一个模型，那么还是同样的这样的一个单一的，统一的多模态模型，它还具备图像和视频的理解能力。



![](img/e5ab7a614e5022ba7175468443bb4b05_189.png)

比如说在右上角的这个视频，我们问它，它有什么感觉，我们的模型能够回答，它感到了一种幸福 兴奋的感觉，我们问右上角说这个人在做什么，它能够识别 理解，这个是一个失望的男人，正在看手机上的消息。

那么左下角的这张图片呢，我们在问说，诶 这个最近的这个，交通灯是什么颜色，我们应该怎么做，它也能够识别出其中的红灯，我们可以看到，其实红灯的这个信号还是非常的微弱。



![](img/e5ab7a614e5022ba7175468443bb4b05_191.png)

那我们的模型也能够理解，那么我们请它描述右下角的这个视频。

![](img/e5ab7a614e5022ba7175468443bb4b05_193.png)

它也能够去识别出这是一个动态的天空。

![](img/e5ab7a614e5022ba7175468443bb4b05_195.png)

上面有非常多的云，那么还是想强调一下，这跟刚才是同一个模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_197.png)

而且是基于一个自回归网络的额苗3，那么我们的EMU3模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_199.png)

它依然在持续的训练过程中，当模型训练完成，经过安全的评估，我们也会将其逐步地开源，如果各位朋友呢等不及，也可以先尝试我们的，上一代的这个额苗EMU1和EMU2，它们已经在市区里面进行开源。



![](img/e5ab7a614e5022ba7175468443bb4b05_201.png)

如果大家觉得还是不过瘾，也可以试一下我们一个，轻量级的图文多模态模型，Bunny，那么Bunny它是一个基于灵活的架构。



![](img/e5ab7a614e5022ba7175468443bb4b05_203.png)

能够支持不同的视觉编码器，像刚才提到的EVA Clip，然后也能支持不同的这个语言基座的模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_205.png)

然后能够实现这样的一个，图文多模态的一个轻量级的模型，所有的这个模型的，模型本身 数据 训练代码。

![](img/e5ab7a614e5022ba7175468443bb4b05_207.png)

我们全部都开源，那么这个就是致源对于整个开源社区。

![](img/e5ab7a614e5022ba7175468443bb4b05_209.png)

对于咱们产业界的一个贡献。

![](img/e5ab7a614e5022ba7175468443bb4b05_211.png)

更多关于致源在视觉多模态方面的成果，大家可以访问我们在，开源社区的一个主页来了解，那么接下来想给大家介绍的是，我们在巨声大模型方面，过去一年的一些工作进展。



![](img/e5ab7a614e5022ba7175468443bb4b05_213.png)

那么我们刚才也提到，多模态大模型能够帮助计算机，去感知和理解这个世界。

![](img/e5ab7a614e5022ba7175468443bb4b05_215.png)

那么接下来它就能够演化成一个智能体。

![](img/e5ab7a614e5022ba7175468443bb4b05_217.png)

那么我们也看到了最近其实像。

![](img/e5ab7a614e5022ba7175468443bb4b05_219.png)

Microsoft Copilot Apple Intelligence，那他们确实能够去控制这样的机器，开始使得AI手机 AI PC开始成为可能，那么我们也在过去的这一年。

研发了一个通用计算机控制的系统。

![](img/e5ab7a614e5022ba7175468443bb4b05_221.png)

叫Credo，它能够像人类一样看着屏幕。

![](img/e5ab7a614e5022ba7175468443bb4b05_223.png)

通过鼠标键盘完成计算机的所有的任务，反思过去总结未来。

![](img/e5ab7a614e5022ba7175468443bb4b05_225.png)

总结现在规划未来，那么这样一个在数字世界的agent。

![](img/e5ab7a614e5022ba7175468443bb4b05_227.png)

如果又进入到了物理世界，那么会发生什么呢，我们可以一起来看一个短片。

![](img/e5ab7a614e5022ba7175468443bb4b05_229.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_231.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。



![](img/e5ab7a614e5022ba7175468443bb4b05_233.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_235.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_237.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_239.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_241.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。



![](img/e5ab7a614e5022ba7175468443bb4b05_243.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_245.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_247.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_249.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_251.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。



![](img/e5ab7a614e5022ba7175468443bb4b05_253.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_255.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_257.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_259.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_261.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_263.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_265.png)

你好 并帮我打印备数里的文件，你好 并帮我打印备数里的文件。

![](img/e5ab7a614e5022ba7175468443bb4b05_267.png)

你好 并帮我打印备数里的文件，那么我们在这样的一个抓取上。

![](img/e5ab7a614e5022ba7175468443bb4b05_269.png)

也最终实现了技术的突破，那么这个技术呢。

![](img/e5ab7a614e5022ba7175468443bb4b05_271.png)

一样的今天大家可以在现场是体验得到的。

![](img/e5ab7a614e5022ba7175468443bb4b05_273.png)

机器人还需要行走起来，因此我们在过去的这一年也研发了一个面向技术中局的。

![](img/e5ab7a614e5022ba7175468443bb4b05_275.png)

端到端巨声导航大模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_277.png)

那我们知道过去机器人，它是需要依靠离线。

![](img/e5ab7a614e5022ba7175468443bb4b05_279.png)

提前建好的地图来实现导航，但是人类其实并不需要这样。

![](img/e5ab7a614e5022ba7175468443bb4b05_281.png)

人类完全依靠视觉，那么为了让机器人能够真正的智能化起来。

![](img/e5ab7a614e5022ba7175468443bb4b05_283.png)

我们也实现了一个纯视觉。

![](img/e5ab7a614e5022ba7175468443bb4b05_285.png)

纯Thin2Real的这样的一个解决方案，真正的实现了Radio Language In Action Out。



![](img/e5ab7a614e5022ba7175468443bb4b05_287.png)

所以右边的这个视频展示的是，我们在智源大厦的内部。

![](img/e5ab7a614e5022ba7175468443bb4b05_289.png)

包括刚才其实是智源大厦的天台，也是今天晚宴的一个位置。

![](img/e5ab7a614e5022ba7175468443bb4b05_291.png)

也非常欢迎大家去智源大厦参加我们的晚宴，那这个这是真正的在虚拟的环境里面。

![](img/e5ab7a614e5022ba7175468443bb4b05_293.png)

我们实现了训练，然后直接就能够在真实的场景中去进行放话。

![](img/e5ab7a614e5022ba7175468443bb4b05_295.png)

的这样的一个导航的大模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_297.png)

那为了将我们的这些大模型，巨声的大模型能够真正的进行落地，我们也与这个北京银河通用机器人公司，一起去基于它们迭代的这样的一个硬件，巨声的一个轮式的机器人，然后来将我们的这些模型和技术，进行了场景的落地。

那这个场景包括了像无人药店，包括了像家庭服务，我们可以看到最右边的这个视频里面，机器人已经能够去自动化的这样的清理垃圾，那中间的无人药店能够根据用户下单的这个药品，去自动的智能基于视觉的方案。

能够去拿正确的这样的药品，那么我们的机器人还能够去思考，比如说当我说我渴了，我们一起来看一下机器人会如何反应，我渴了，好的 给你打一口，对 如果告诉机器人我饿了，看看他的反应，我饿了。

现在有橘子香蕉营养的，橘子谢谢，好的，给你拿橘子，可以看到机器人能够根据用户的开放的指令进行思考，还能够与用户进行交互，再基于我们前面所提到的这种犯法的抓取能力。

能够真正的去实现这种通用的犯法的指令执行，我们也将这样的一台机器人其实带到了志愿大会的现场，在对面的会议中心的展厅中，如果大家有兴趣的话，可以去现场的体验一下，那么除了像无人药店家庭的场景以外。

巨声机器人在医疗场景也会有非常重要的一个落地，那么在过去的一年，我们联合了清华大学301医院，实现了全球首创的智能心脏超声机器人，并且在真人上实现了自主的超声扫描，我们将我们的机器人的心脏超声的结果。

与三位301医院高年资的心脏超声的医生，扫描的结果进行了对比，那么我们发现在准确性在高效性上，与人类的医生是基本持平的，但是它的稳定性和舒适性是显著的高于人类的医生，更为重要的是。

现在整个全国这样的一个超声机器，超声的医生是非常缺乏的，我们也知道经常在超声的科室排队也是排得最久的，那么它对于整个提升我们在超声这一块的，整个医疗的普及度和水平都有非常重要的意义。

我们也将这样的一个技术浮化出了一家公司，那么也非常欢迎大家关注我们的这个公司，那么在未来整个巨声智能依然有非常多的技术问题，非常多的产业落地的问题是需要被解决的，我们也将联合像清华北大中科院这样的高效。



![](img/e5ab7a614e5022ba7175468443bb4b05_299.png)

以及像银河加速进化等等这样的产业上下游的产业链，然后有希望有更多的生态合作伙伴，跟我们一起来解决巨声智能中的一些核心关键性的问题。



![](img/e5ab7a614e5022ba7175468443bb4b05_301.png)

包括像数据要素 包括像模型以及场景应用，欢迎全国所有对于这个巨声智能感兴趣的高效院所。

![](img/e5ab7a614e5022ba7175468443bb4b05_303.png)

企业与智源研究院联系，接下来我想给大家介绍的是，我们在生物计算大模型方面的一些进展，刚才提到了深层式人工智能已经推动了，整个人工智能领域的一些重大的突破。



![](img/e5ab7a614e5022ba7175468443bb4b05_305.png)

那么当它进入到微观的世界，我们是否可以用相似的这样的一个。

![](img/e5ab7a614e5022ba7175468443bb4b05_307.png)

深层式技术来解决生命分子的理解与生成的问题呢。

![](img/e5ab7a614e5022ba7175468443bb4b05_309.png)

这就是智源进行生物计算大模型研发的一个初步的思考。

![](img/e5ab7a614e5022ba7175468443bb4b05_311.png)

同时它对于整个产业界也有极为重要的意义，我们知道在药物研发领域有一个栓死定律。

![](img/e5ab7a614e5022ba7175468443bb4b05_313.png)

从新药的研发到它的上市，通常要耗费10年以上的时间。

![](img/e5ab7a614e5022ba7175468443bb4b05_315.png)

以及10亿美金以上的投入，那么其中30%是在药物设计。

![](img/e5ab7a614e5022ba7175468443bb4b05_317.png)

也就是在临传前的部分。

![](img/e5ab7a614e5022ba7175468443bb4b05_319.png)

这也是人工智能最能发挥的作用的地方，那么除了像化合物的这种筛选和预测以外。

![](img/e5ab7a614e5022ba7175468443bb4b05_321.png)

那么对于大分子的这种结构的建模和预测。

![](img/e5ab7a614e5022ba7175468443bb4b05_323.png)

也能够推升像基于RNA这样的。

![](img/e5ab7a614e5022ba7175468443bb4b05_325.png)

大分子的一些新药的设计，那么这也正是人工智能。

![](img/e5ab7a614e5022ba7175468443bb4b05_327.png)

对于医疗领域的一些可能性的贡献和突破，那么基于这样的一些思考。

![](img/e5ab7a614e5022ba7175468443bb4b05_329.png)

我们就设立了Open Complex的这样的一个项目，它希望能够研发统一的生物分子计算模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_331.png)

打通基础生物分子像蛋白质 RNA DNA。

![](img/e5ab7a614e5022ba7175468443bb4b05_333.png)

小分子之间的这种壁垒，并且能够研究生物分子之间的相互作用的关系。

![](img/e5ab7a614e5022ba7175468443bb4b05_335.png)

那么我们构建了一个全原子的生物分子模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_337.png)

它是一个decoder only的模型，那么我们可以一起来看一个短片的介绍。

![](img/e5ab7a614e5022ba7175468443bb4b05_339.png)

生成是人工智能技术的发展，正在加速人类对生命奥秘的揭示，了解生命的过程。

![](img/e5ab7a614e5022ba7175468443bb4b05_341.png)

必须观察和理解数十亿个生命分子间的，数百万种组合和相互作用关系，这一庞大的数字计算工程，无法用传统的物理方法高效完成，支援研究员开发的Open Complex。



![](img/e5ab7a614e5022ba7175468443bb4b05_343.png)

基于生成是人工智能技术，能在原子层面进行坦白质，RNA DNA小分子的结构。

![](img/e5ab7a614e5022ba7175468443bb4b05_345.png)

和相互作用关系的预测，精度达到超级计算机的水平，这样的能力使得科学家可以进一步理解生命的机理，未来我们希望逐步构建一套，微观生命科学的孪生系统，为人类理解自然本源带来新的可能，Open Complex。

开发者：陈杰，开发者：陈杰，开发者：陈杰。

![](img/e5ab7a614e5022ba7175468443bb4b05_347.png)

我们的Open Complex在国际权威的蛋白质。

![](img/e5ab7a614e5022ba7175468443bb4b05_349.png)

国际权威的版单CAMEO的蛋白质结构预测中，已经连续26个月稳居第一。

![](img/e5ab7a614e5022ba7175468443bb4b05_351.png)

那么无论是在精度还是宏观结构方面，都优于同期的模型像包括像α4II，那么除了像蛋白质结构预测以外。

![](img/e5ab7a614e5022ba7175468443bb4b05_353.png)

它还具备其他符合物的预测，像RNA DNA以及蛋白质的这样的符合物。

![](img/e5ab7a614e5022ba7175468443bb4b05_355.png)

那么我们也展示了我们的预测的结果。

![](img/e5ab7a614e5022ba7175468443bb4b05_357.png)

与Atom这样超级计算机的预测结果。

![](img/e5ab7a614e5022ba7175468443bb4b05_359.png)

那么最终的结果显示Open Complex，已经初步具备了通路预测的能力。

![](img/e5ab7a614e5022ba7175468443bb4b05_361.png)

那么左边呢在这边的一组实验中，左边是我们Open Complex的预测结果，右边是Atom超级计算机它的一个预测，我们不仅结果相似。



![](img/e5ab7a614e5022ba7175468443bb4b05_363.png)

并且我们没有像Atom那样的一些噪音，那么这就是生成式人工智能。

![](img/e5ab7a614e5022ba7175468443bb4b05_365.png)

所带来的一个技术的突破，我们能够使用非常少量的GPU就能够实现。

![](img/e5ab7a614e5022ba7175468443bb4b05_367.png)

原来只有超级计算机才能够做的事情。

![](img/e5ab7a614e5022ba7175468443bb4b05_369.png)

我们还将这样的技术呢应用在了，实时心脏的计算建模上。

![](img/e5ab7a614e5022ba7175468443bb4b05_371.png)

那么实现了全球首个，实时完身心脏的一个计算。

![](img/e5ab7a614e5022ba7175468443bb4b05_373.png)

通过GPU的这样的加速，能够将心脏的生物秒和计算秒。

![](img/e5ab7a614e5022ba7175468443bb4b05_375.png)

突破到了1比0。9，真正的实现临床应用的可能。

![](img/e5ab7a614e5022ba7175468443bb4b05_377.png)

我们也正与北大第一医院，安征医院 长庚医院 朝阳医院进行合作。

![](img/e5ab7a614e5022ba7175468443bb4b05_379.png)

将我们这样的技术应用在临床当中，以上就介绍了智源围绕整个大模型技术发展路线。

![](img/e5ab7a614e5022ba7175468443bb4b05_381.png)

我们所做的一些研究，那么很多的研究工作依然在进行，也请各位朋友可以关注我们在未来几个月，以及下半年持续的对于一些研究成果的发布，那么所有的这些研究成果呢。



![](img/e5ab7a614e5022ba7175468443bb4b05_383.png)

都要依赖于一个非常强大的一个基座，那这就是我们的一个算力集群的一个操作系统，在去年的时候我们发布了FragOpen 1。0，它是一个面向异构芯片支持多种框架的，大模型全站开源的技术基座。

经过一年时间的迭代，Frag 1。0升级到了2。0，整个技术的这个，质地向上的这个框架是更加的成熟，也更加的完备，比如说我们有这个面向不同芯片的算子库，我们有面向异构AI的计算的框架。

我们有数据处理的工具，也有这个整个各种各样的算法，和我们前面所提到的像Email BGE，这样的一些非常优秀的模型，那么这样的一个开源的，整个开源的一个系统框架，能够真正的实现一站式领先的。

高效应用的大模型的算法和工具，我们也与全球的主流的一些基金会合作，像Linux Foundation， IEEE， IMBA，以及HackinFace合作，能够希望促进整个开源社区。

在人工智能在大模型这个领域的，一个快速的发展，那么基于FragOpen中系统软件的部分。

![](img/e5ab7a614e5022ba7175468443bb4b05_385.png)

以及我们自研的九顶平台，我们也构建了一个为大模型而生。

![](img/e5ab7a614e5022ba7175468443bb4b05_387.png)

支持异构芯片的算力集群操作系统。

![](img/e5ab7a614e5022ba7175468443bb4b05_389.png)

这个操作系统在过去20多个月内，已经稳定的运行，支持了超过50多个团队来训练大模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_391.png)

能够支持8种的AI的芯片。

![](img/e5ab7a614e5022ba7175468443bb4b05_393.png)

我们也非常欢迎全国各地的。

![](img/e5ab7a614e5022ba7175468443bb4b05_395.png)

计算中心能够试用我们的FragOS，接下来可以看一个关于FragOS的短片介绍。

![](img/e5ab7a614e5022ba7175468443bb4b05_397.png)

用户在九顶启动训练任务时。

![](img/e5ab7a614e5022ba7175468443bb4b05_399.png)

可指定一种算力资源详细配置，开启跨不同AI芯片的。

![](img/e5ab7a614e5022ba7175468443bb4b05_401.png)

异构算力自动迁移功能，提交训练任务。

![](img/e5ab7a614e5022ba7175468443bb4b05_403.png)

平台依据FlagPath工具，在不同异构算力上的性能评估历史数据，将初始算力资源配置，智能映射至等效的其他算力资源，实现无缝高效的自动化异构资源配置，九顶平台启动全区算力智能调度。



![](img/e5ab7a614e5022ba7175468443bb4b05_405.png)

持续调度成功，平台基于Triton大模型算字库。

![](img/e5ab7a614e5022ba7175468443bb4b05_407.png)

实现任务跨AI芯片的自动迁移，集成的FlagScale进行并行策略的动态优化，充分利用集群的异构资源，提升训练效率 缩短训练周期，降低训练成本，FragOpen里面有非常多的模块。



![](img/e5ab7a614e5022ba7175468443bb4b05_409.png)

接下来我简单的介绍一下，其中FlagOS和FlagOpen中一些核心关键的组成部分。

![](img/e5ab7a614e5022ba7175468443bb4b05_411.png)

其中一个是面向大模型的开源Triton算字库。

![](img/e5ab7a614e5022ba7175468443bb4b05_413.png)

在大模型的算字库中。

![](img/e5ab7a614e5022ba7175468443bb4b05_415.png)

我们也统计了一下主流的大概通用的，有120多个算字。

![](img/e5ab7a614e5022ba7175468443bb4b05_417.png)

我们目前已经实现了48%的全覆盖，能够支持六大产商的多种AI的芯片。

![](img/e5ab7a614e5022ba7175468443bb4b05_419.png)

同时针对大模型专用的算字库。

![](img/e5ab7a614e5022ba7175468443bb4b05_421.png)

我们也有六个Attention，FlagAttention的算字，能够覆盖主流的Attention。

![](img/e5ab7a614e5022ba7175468443bb4b05_423.png)

并且依靠着智源研究院在大模型方面的前沿研究。

![](img/e5ab7a614e5022ba7175468443bb4b05_425.png)

也能够紧随算法的前沿去打造创新的算字。

![](img/e5ab7a614e5022ba7175468443bb4b05_427.png)

那么FlagScale是一个多元异构的并行的训练框架。

![](img/e5ab7a614e5022ba7175468443bb4b05_429.png)

我们也在业内首次实现了不同产商，跨节点RDMA直连。

![](img/e5ab7a614e5022ba7175468443bb4b05_431.png)

以及多种并行策略的高效混合训练，那么实现了首个多元异构芯片。

![](img/e5ab7a614e5022ba7175468443bb4b05_433.png)

Scale-up加Scale-out两阶段高效训练的千亿语言模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_435.png)

那么基于这样的一个异构芯片计算出来的模型。

![](img/e5ab7a614e5022ba7175468443bb4b05_437.png)

我们也将其在社区里进行了开源，今天我们还想发布两个数据集，一个是千万级高质量的指令微调数据集，我们知道SFT阶段在激发大模型的能力上是非常地关键，目前整个社区里依然非常缺乏高质量的SFT数据。

那么我们将开源千万级的中英文的高质量的一个数据，这样的一个指令微调数据集，我们的实验结果显示，它能够让非常多的开源社区的基座模型，能够达到或接近GDP-4的水平。

此外我们还将开源全球最大的中英文多行业的数据集。

![](img/e5ab7a614e5022ba7175468443bb4b05_439.png)

它覆盖18个行业的种类，总计3。4TB，我们在医疗和教育领域进行的Continue Training。



![](img/e5ab7a614e5022ba7175468443bb4b05_441.png)

SFT+DPO训练，结果显示它能够显著地提升通用基座模型在领域里的一个效果。

![](img/e5ab7a614e5022ba7175468443bb4b05_443.png)

我们的FlexScale大家相信也非常地熟悉。

![](img/e5ab7a614e5022ba7175468443bb4b05_445.png)

在上个月我们也发布了我们的志愿的板单和评测的结果。

![](img/e5ab7a614e5022ba7175468443bb4b05_447.png)

那么也非常欢迎行业里所有的大模型公司，能够使用我们的FlexScale。

![](img/e5ab7a614e5022ba7175468443bb4b05_449.png)

今天也非常高兴地跟大家分享。

![](img/e5ab7a614e5022ba7175468443bb4b05_451.png)

正是基于志愿研究院在开源开放这方面的承诺，以及我们对于整个社区持续做创新的这样的一些突破，那么我们FlexOpen系列的所有开源的模型框架工具。



![](img/e5ab7a614e5022ba7175468443bb4b05_453.png)

在过去一年的全球总下载量超过了4755万次。

![](img/e5ab7a614e5022ba7175468443bb4b05_455.png)

应该来说在全国内的AI机构中处于绝对领先的位置。

![](img/e5ab7a614e5022ba7175468443bb4b05_457.png)

那么这些优秀的成果呢，以及我们在前沿模型上的这些迭代，肯定是离不开优秀的人才，那么因此也想借今天志愿大会的这个现场，也打个小广告，欢迎大家截屏或者拿出手机拍照，那志愿研究院提供了非常宽松的科研的氛围。

高水平的平台以及全方位的这个福利的关怀，非常希望全球最最顶尖的人工智能人才，能够考虑加入志愿研究院，最后我们回到志愿大会，志愿大会在过去的五年已经成功举办了五次。

我们邀请了全球30余个国家和地区超过1000位的顶尖的专家，来志愿大会进行分享，其中包括11位的图灵奖的获得者。



![](img/e5ab7a614e5022ba7175468443bb4b05_459.png)

那么在去年的志愿大会上，相信大家也是留下了非常深刻的印象，像Hinton， Sam Altman， Tegmark， Rassel，他们都参加了我们的志愿大会。



![](img/e5ab7a614e5022ba7175468443bb4b05_461.png)

尤其是其中的我们在去年第一次设立的AI安全与对齐的论坛。

![](img/e5ab7a614e5022ba7175468443bb4b05_463.png)

我们知道随着深层次人工智能技术的快速发展。

![](img/e5ab7a614e5022ba7175468443bb4b05_465.png)

通用人工智能时代有可能会到来。

![](img/e5ab7a614e5022ba7175468443bb4b05_467.png)

那么AI所带来的安全的问题也是不容忽视的，那么志愿研究院致力于在AI安全上。

![](img/e5ab7a614e5022ba7175468443bb4b05_469.png)

我们进行技术突破和研究。

![](img/e5ab7a614e5022ba7175468443bb4b05_471.png)

确保人工智能在发展的过程中始终是造福人类安全可控，今年3月份我们的顾问委员会主任张宏江博士也发起了。

![](img/e5ab7a614e5022ba7175468443bb4b05_473.png)

志愿研究院举办了首届北京AI安全国际对话。

![](img/e5ab7a614e5022ba7175468443bb4b05_475.png)

那么也邀请了包括像Hinton， Benjel， Rassel， 姚先生， 傅盈， 薛蓝，等等全球顶尖的30余位的专家。



![](img/e5ab7a614e5022ba7175468443bb4b05_477.png)

并且我们共同签署了北京AI安全国际共识。

![](img/e5ab7a614e5022ba7175468443bb4b05_479.png)

那么在今年的志愿大会上我们也依然设立了我们的AI安全的论坛，明天一整天依然是大开云集。

![](img/e5ab7a614e5022ba7175468443bb4b05_481.png)

非常欢迎大家进行关注，在未来两天的日程中，我们的志愿大会上有20余个的论坛白产的报告，有非常多的朋友告诉我。



![](img/e5ab7a614e5022ba7175468443bb4b05_483.png)

看到我们的日程之后，第一个感觉是自己的分身乏术。

![](img/e5ab7a614e5022ba7175468443bb4b05_485.png)

那么我想这就是志愿大会的魅力所在，那么一样的我们今年的志愿大会依然是干货满满，我们有来自全球主流的模型的技术负责人。



![](img/e5ab7a614e5022ba7175468443bb4b05_487.png)

![](img/e5ab7a614e5022ba7175468443bb4b05_488.png)

项目负责人来介绍他们的最新技术，也有国内顶尖的各个大模型技术负责人。

![](img/e5ab7a614e5022ba7175468443bb4b05_490.png)

创业公司以及CEO CTO共同汇聚。

![](img/e5ab7a614e5022ba7175468443bb4b05_492.png)

同时我们也会对于大家对于大模型的各种关心的问题。

![](img/e5ab7a614e5022ba7175468443bb4b05_494.png)

进行全面的解答，所以非常欢迎大家能够享受未来两天志愿大会的日程。

![](img/e5ab7a614e5022ba7175468443bb4b05_496.png)

那么今天上午的开幕式呢。

![](img/e5ab7a614e5022ba7175468443bb4b05_498.png)

在我的报告结束之后，会有OpenAI的负责人，OpenAI Solar的负责人来介绍。

![](img/e5ab7a614e5022ba7175468443bb4b05_500.png)

在多模态大模型方面的一些最新的进展，然后我们也会对于通用人工智能进行一些讨论和对话。

![](img/e5ab7a614e5022ba7175468443bb4b05_502.png)

那么也请大家能够享受开幕式接下来的流程。

![](img/e5ab7a614e5022ba7175468443bb4b05_504.png)

我的报告就到这儿，谢谢大家，謝謝大家，感谢您的收听。
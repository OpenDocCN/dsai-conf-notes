# 2024北京智源大会-意识与通用人工智能 - P6：圆桌讨论 - 智源社区 - BV11b421H7JY

好呀非常谢谢各位老师刚刚的分享，我收获很大，然后呢就坦白来说啊，就是这个圆桌比去年要难很多，因为这个意识是什么这个问题呢，是不能问的，因为一旦问了这个问题呢，就是非常的哲学，我相信各位老师也很难在。

今天这个时间点哈，用各位这个科学的标准，回答出来什么是意识，所以呢我把这个问题换了一下，我们换一种方法来问对吧，这个AGI里面的G，它是什么，AI的意识应该是什么。

然后这个AI的意识和人类可能会有什么区别，对这个问题我非常好奇，因为我刚刚问了CHPT，他说这个AGI的G呢是General，但这个答案我不是很满意，所以我想请问一下各位科学家，要不然从刘老师开始，好。

那个就是标准的定义啦，然后就是AGI的G就是这个General，就是通用，通用的意思就是什么都能干，就是什么都能干的意思来讲，它其实有个定义，就是在一个开放环境里面做任何事情，就是我在这个会场里面。

我可以跟大家做报告，然后如果假设我们把这个改成一个party来，当然我不会跳舞也不会唱歌，就我可以当个主持人，对吧，包膜员，但是呢这个不够，因为我们假设要打篮球去，这就不够，我们需要到其他地方打。

但是呢我觉得这个G其实是一种偷懒的做法，在我看来这个G可能还有另外一层含义，就是生成式，Generative，那么其实这个我觉得这是我们人类之所以能够不断地成长，能够创造出来的一个关键。

特别是到现在我们以自身为模板，然后创造出来一个可能的全新物种，或者一个全新物种的一个火花，这其实也是来自于我们人类的G，就是Generative，罗老师，坐在刘嘉老师旁边不好，每次都第二个回答，不一定。

下次从那边开始，待会会换，那我们都知道AGI的G是Generative，刚才我在想就是通用的这个意思，但是我真的在想一个问题，就我自己的一个小的点，就我觉得可能是我们人就是认为只有我们是有智能的。

所以每当这个世界出现一些我们觉得不可能的智能的行为呢，我们就说它不够智能，然后我们就给它包装了一个词，叫你没有通用智能，所以这是我的一个感觉，然后你再问人说那请问什么是通用智能。

可能十年前的时候你说通用智能是说，你不会 你知道你不会跟我聊天，你只会具体的答案，那你今天不敢说了吧，你看我们主持人都问Chad GPT，而且回答得很好，所以我们今天又会说不对不对，这个也不够智能。

真正的通用智能是什么呢，其实我们也不知道是不是，就是但是，但是我觉得这个是我们人捍卫自己智能的一个词，就是这样的一个通用，但我的感觉就是，如果回到我们自身，我觉得通用还是指你的那种泛化能力吧。

就是不仅是Chad GPT这种语言，可能各个方面的泛化问题，比如刚才在我走上台之前，其实我没想我要干嘛，我也没有准备什么，但我可能会根据比如刘老师的回答，主持人的问题，还有大家的面孔。

我可能就会不停地在换答案，真的是这样，所以我觉得这个可能通用有这样一个，我一个非常小的点，其实刚刚两位老师回答的时候我在想一点，尤其是刚刚刘老师说，他说这个general是通用就对了，就是通用的能力。

然后我想其实很多事情我也不会，比如说打篮球我就不会，但是不是我们一定要要求这个机器人的这个G，要成为一个那么通用的一个东西，这个也是我觉得我比较好奇的一件事情，所以老师要不然您简单帮我们回答一下。

这个如果从AGI的角度上来讲的话，我觉得最开始刘老师说那个定义就，反正我理解到的最早的AGI的定义也是这么来的，我最早理解这个概念是从DeepMind，他们早期就说我们怎么样来解决问题。

We first solve AI，Then we use AI to solve everything，所以那个时候他的那个AI。

And use that AI to solve everything，那个AI其实就是我们今天讲的这个AGI，那么它其实隐含的就是，它要能够解决所有我们能够描述的。

我们认为可能有一个路径去能够解决的问题，当然你可能没办法很快就要求它说，你计算出这个整个宇宙的寿命，或者是什么这些地外的生命等等在哪里这些事情，但可能是一般在我们，至少是人类能力集合所形成的这样的一个。

这样的一个图包图集complex set里面，那么是要能够做得到的，那G等于意识吗，这个G这个AGI的这个G等于意识吗，我倾向于就是这个在这个过程中意识其实已经有了，好 谢谢 朱老师。

我想问Sue老师一个问题，就是她把这个AGI好像定义成了，我们人类所有知识的一个complex set，但如果从这个定义上一个单个的个体，比如说我就不具有general intelligence。

因为我是有专业分工，我只知道我自己很小一个领域的知识，你要去问我别的知识我都不知道，所以在这个定义下我们每个个体都没有general intelligence，然后我们想创造一个等同于全人类那么强大的。

在你的定义下的那样子的一个AGI，是这样吗 这是我的一个问题，因为今天好像是要调事，所以but anyway，然后我来说一说我的定义，那个我觉得我可能定义稍微有一丢丢的不一样。

是因为我觉得可能不一定非要从performance上定义，就是它能够完成我们general的一些各种各样的任务，maybe可以从能力上去定义，也就是说在我的想象里面。

AGI应该是一个可以学习去完成各种各样能力的，各种各样子的任务的这么一个智能，所以at the end of the day，它应该是有一个学习和adaptive的能力。

而这种学习也许不是像现在这样用海量的知识去喂它，而是它能够自主地去寻找它需要的知识，自主地去完成这样一个学习的过程 这样一个智能，而至于这个知识的边界到底是多大，可能就是一个变成一个哲学的问题了。

我觉得朱老师提到一点特别好，提到了这个主动性，其实在我的这个理解里面，我觉得这个主动性和我自己理解的它，应该是比较偏向于这个意识的一部分的，对 吴老师要不听听您的答案，对 我其实那个。

说AGI我从来没有serious对待过这个问题，真的 我在想那个智能的定义其实都有问题，我们倾向于人嘛，倾向于我们自己不会干的事情，别人能干 我觉得他很智能，比如像围棋，因为这个围棋特别复杂。

但是数学上它其实是一个相对简单的问题，它就收缩空间特别大，然后那个α够解决，大家太智能了，但是实际上我们生活中有很多东西，我们每个人都能干的，就是我们那些本能行为是吧，走路跑步 手眼协调你知道吗。

又说起这个手眼协调这种，就比如我知道我开车的时候，我就问那个教练，我说我怎么保证我开在路中间呢，他说你不用担忧，你一眼睛开到中间，你自然就开到中间去了，就是我们人在这种手眼协调做得非常非常好。

但是现在把它做成一个工程上的问题，我觉得是非常难的，做脑筋接口有个人告诉我，他说做了手眼协调是我们追求的最高境界，就是我们人其实有很多很多能力，只不过我们每个人都是，每个人都擅长，我们就认为他不智能了。

而把我们不擅长的东西当成很多智能，我觉得从这一点上说，智能可能是，它定义是成问题的，刚才陆萨说得好，我觉得我们人真正最厉害的能力是学习能力，adaptive，这个才是我们人可能区别于别的动物那个。

最厉害的地方，这个比较巧，我刚刚在台下看到了杜老师，杜老师是去年我们的嘉宾，然后也给了我们很多分享，我还记得杜老师去年的观点，大概就是，token的最小颗粒度应该是神经元，对吧 我没有记错对不对。

对对对，然后我们先把这个问题抛给杜老师，让杜老师也回答一下，然后下一个问题我们来邀请杜老师来提问，有有有有，抱歉，就是说你是说刚才那个，就ACI的G是什么，然后G代表着什么，意味着什么。

和人类的意识有什么区别和关联，我给个跟大家答案不太一样，也可能是一样，就是说G代表你有能力进行知识的外推，因为我用GPT用了很久，我现在已经能够很明确地判断出它的能力的缺陷。

就是说它的专业能力确实很强大，但是我很容易能测出它的缺陷在哪，就是做外推，我举个很简单的一个例子，就前几天高考数学题不刚出来吗，然后大家就在线测，其实测那个高考数学题是一个最好的一个办法。

因为数学题可以，因为首先有很多大模型，你说我就不一一说了，都自称自己解数学有多好多好，你也不知道他训练级是不是偷偷摸摸地把这些，数学题都训过一次，你也不知道，但是高考。

就是说每年的高考数学题一定是他没见过的，所以你一测，然后你就会发现，哪些好哪些不好，就发现这个差的还挺远，所以让我看的就挺有信心，然后类似的这种也是一样，我做科研的时候，我可以问他一些需要知识外推的。

所以我就认为有很好的，这个G应该能代表进行知识外推，这是我个人的一个小小的观点，杜老师要不然你给厂商的各位老师提个问题，对我这个问题可能比较尖锐一点，因为我经常和我是在人工智能学院。

经常和大模型的人在一起有讨论，然后他们有一个很奇怪的问题是我没想到的，就他们讨论AGI，大家知道AGI的历史，其实图灵本人，他认为AGI是不需要和真实世界进行交互的。

然后图灵本人他的这个观点听起来很奇怪，但是他得到了像以OpenAI为代表这种大模型的，他们这是一个流派，因为为什么，就是说有一个解释就是压缩极致能，就是说如果你有外部的世界，我不需要看外部。

我海量的数据，我把这个数据进行压缩完了以后，我也能学到，我就不需要和外界会有交互，然后还有另外一个流派当然就是以巨声为主，然后就是说我需要和一个真实世界进行交互，我要去进行交互。

所以我才能够把同一种AI给训练出来，这里其实有，就是我不知道各位专家是怎么看这个问题的，要不然我们从这个隋老师先回答，我看这两个其实没有矛盾，就是他在巨声我们讲交互的时候。

其实是因为没有一个好的压缩的呈现，比如说当我已经有一个很好的一个反振器，一个simulator，其实一个好的simulator本质是什么，本质一个好的simulator。

是对于一个复杂环境的一个极致的压缩，它规避了所有那些可能你simulate，不会出现的那些解空间里的东西，这是一个很好的一个压缩的方式，而巨声之所以讲要和这样的环境来交互，或者说要和真实世界来交互。

当我们讲和真实世界来交互的时候，永远是因为这个simulator本身还没有那么完美，也就是这个压缩层面上来讲，它其实没有做得那么好，所以这是我的观点，我赞同说本身压缩这是一个很重要的事情。

以及之所以今天我们在丰富的，高维的复杂的世界里面，仍然能够有效地做很多事情，所以我们能够有效去做的这些事情，大概率或者极大概率的是，它以一种可压缩的方式是可以被呈现的，所以我们能够找到有效的方法来做它。

而且我们可能解决不了的问题，要么可能它没有这样的压缩表征的，这样的一个呈现的方式，要么是我们还没有找到这种方式，这是我的一点观点，朱老师，看朱老师玩手机点名一下老师非常开心，我不知道我不做人工智能的。

我觉得首先第一，我觉得知识在人类的大脑里面肯定是压缩的，但是这个地方的问题是在于你到底要压缩什么，而且完了以后当我们把这个知识retrieve出来，要解决现实世界的问题的时候，我们还有一个解压缩。

我们要重新decode把它变成一个我们可以用的，一个新的在现实里面的一个可以用的representation，所以如果仅仅只是压缩，我觉得那只是故事的一半，你还要在新的环境下。

然后来生成这个新的可以用的一个representation，然后再把它来使用，所以在这个里面我不是做AGI，所以我很难回答这个问题，但是我觉得至少是从这个大脑的策略上来说。

我们要做这个compression它是一部分，但是最后我们怎么样有效地，除了有效地做compression以外，我们还要怎么样有效地再去把它decompress，可能是问题另外一个很重要的部分，吴老师。

对 其实这又涉及到一个智能的问题，我觉得如果从知识表达的角度，那个压缩可能就是一个高于数据压缩，抓住它最本质的结构，然后再用sampling的方法又生成了一个，其实它已经不是完全的，比如说猫是吧。

它生成了sampling出来，它不再是完全一模一样的猫了，但是它抓住了猫的结构，你看那个生成模型生成一个特别像的一个猫，但它实际上不是原来的猫了，就从知识表证的角度可能压缩是核心，但是我们这个智能不是。

我们智能是定义是，我们在这个对于我们人来说，我们在这个世界上我们和环境互动，我们能适应环境的变化，这个是最fundamental的能力，从这个意义上说它不交互它怎么会去，压缩只是一部分。

是我们那个internal model世界模型的部分，但是我们肯定要选用一个效应器是吧，给外界进行交互，我觉得在我的看来智能应该包含这样一个部分，不简单只是一些统计规则。

就是数据点和数据点之间的统计规则，那个就是压缩，我把那个统计的pattern给找到了，我把这个问题稍微延展一下，问一下刘老师，就是说刚刚几位老师都提到了这个压缩嘛对吧，就是这个压缩正好有点点这个。

echo这个杜老师去年的一个观点，是不是说把这个各个的神经元，把它理解成一个这个token的角色，形成一个token的一个样子，然后我们就可以得到这个世界，然后刚刚其实老师都提到了说。

压缩之外应该有别的东西，然后构成了我们人和机器智能不一样的地方，然后我也想问问刘老师就是，这个别的东西你觉得是什么，对，那个就是压缩呢然后就是我们简单而言，就是说至少有两种方式。

一种方式呢就是我去寻找它们之间的概率关系，对吧然后就是那个就是我们通常说的叫那个就是，叫那个因物，就是那个原来传统对NLP对大模型的一个说法，就是说它是一个概率因物，它首先根据概率第二它只能重复。

那么是这是一种观点压缩，还有第二种压缩的观念呢，这个是我们知道我们人肯定是有的，就是我们大脑里面在形成对这个世界的一个表征，这个世界是怎么运作的，我们的人的这种反应方式应该是什么样的模式。

在世界上应该是什么样的模式，比如在那个会场上，那么我的world model就是我不能到处跑来跑去，然后不能比如说现在正在一边分享一边吃饭，对那么这是这样一个规则，但是如果假设我们在那个饭店里面。

我们就可以一边吃饭一边聊天，就是我们有个关于世界运行的法则，这点我们东西是确定的，那么现在回到大模型上来讲，究竟大模型学习的压缩，它是一种概率因物的这种方式，学习的只是一种概率连接的这种观念式的方式。

还是它形成了一个关于这个世界的表征，我觉得这点问题的回答呢，它基于两个实验的研究，第一个是大的生物神经网络，和大的人工神经网络，它们有什么样的异同在表征上面，我觉得要回答这个问题。

因为我们知道人是一定有world model的，就要从我们的自己直觉上来感受，大模型有没有我不知道，但是我们可以在表征的层面上可以来看它，OK我觉得这是然后我们第一个必须要去回答的问题。

所以说这也是老科学加上AI，我觉得这应该是未来一个最好的方向，就不是之一，第二个我觉得我们需要解决的问题，就是回到你刚才所说的，它一定是要有交互，就是说刚才在前面老师也都提到了。

智能的一个本质是学习和适应，那么其实学习和适应本质上是一回事儿，我们只用了不同的词，那么这个事儿就需要一个反馈，那么在反馈当中其实机器有大模型有，比如说我们说一个简单的RLHF。

就基于人类反馈的强化学习，对吧，它也然后根据来学，但是我觉得这不够，为什么叫不够呢，当它没有身体的时候，它去然后和这个外部世界反馈，它的感觉和人的这种反馈是不一样的，为什么这么说呢也是出于我们的直觉。

我们通常有一句话叫做，读万卷书更要行万里路，对吧，现在Charter GPT它更多干的什么呢，它读了万卷书，但它没有行万里路，但是我觉得行了万里路之后，可能那种感受，和我们读万卷书的感受是完全不一样的。

所以说我觉得在这个时候来讲，那个就现在大模型，它没有巨身，如果假设它没有巨身，至少我觉得，它不像我们人类智能这样子，它是有区别的，因为我们现在把AGI的一个通俗的定义是，类人一样的智能，对吧。

像人一样的智能，那么如果从这角度来讲的话，我们现在顶多只能说大模型，它是AGI的火花，或者它是雏形，但它还不是真正的AGI，所以说我觉得从工程上来讲，无论是算力啊，无论是模型的复杂度啊。

我觉得这些都只是一个工程问题，我觉得下面如果它真的要出现，然后就是像我们人一样的智能，真的实现AGI的话，我觉得它需要解决科学的问题，就是你究竟学，你需不需要一个身体来学，需不需要巨神来学。

我的答案是yes，但这只是一个就像，我是当时在一个PPT学了，打了个括弧belief，这只是一种信念，但然后通常我们说信念很多时候都是错的，只不过然后就是，只不过我们愿意去赌一把，第二个就是回到刚才的。

就一定要去看生物的大脑，究竟长什么样子，罗老师，刚才老师都说这么多，我觉得如果想象把整个世界都压缩进一个大脑，就代表智能，我至少是肯定不同意的，因为我觉得，我不知道。

可能这个也是信息科学领域的傲慢的地方吧，就是好像你们总觉得这个世界上的知识是已知的，我们只要，我们现在有特别大的算力，我们有很多的办法去捕捉，我们理论上就可以把它压缩进这个人脑，压缩进某个agent。

我的感觉就是说不是，第一方面是，其实知识并不是一个确定的东西，就跟人类社会一样，如果人类社会，就是发展到今天，比如我们每天发生的事情都是如此的不确定，你觉得是因为，真的是因为我们了解不多。

还是因为它其实会，真的就像刚才吴老师说的那种，涌现出来的一些不确定的各种特性呢，所以我觉得这个世界它本身就不是一个静态的世界，不是说这个世界上，一共有多少多少比特的信息，我要知道就ok了。

然后我只要用算法把它压缩进来，我就变得智能了，我是完全完全不相信这一点的，我觉得这个世界上的知识根本没有办法衡量，它取决于这个世界里面，存在的人 存在的各种生物体，甚至于非生物体。

它们之间会产生出很多很多很复杂的东西，然后这些东西是，不能叫不可量化，但是它至少不是有一个upper limit的，然后对于一个人来说，你想一个宝宝出生在这个世界上，他也不是就是学很多东西对吧。

但他好像三胖好能够活下来，然后他背后的这个智能肯定不是通过一个知识压缩，它就是一种你可以叫互动的能力 适应的能力，对 我只是想强调说，这种用压缩的观点去解释智能，我是完全不同意的。

虽然我们自己实验室做一些研究，我们也借用压缩这个词，但是这个概念我是不同意的，我能追问一句吗，来，当我同意你的观点的时候想追问一句，难道我们刚出生的婴儿，他肯定不是一张白纸。

难道不是信息压缩在他的DNA里面吗，我同意，但是他不是整个世界的知识压缩在他的DNA里面，但是是这个世界最精华的知识，或者以他生存最关键的知识，对 没错，所以我觉得那个Daniel的讲得挺好的。

如果大家去看他的一些书，我也看得不多，大概就看了一两本，我觉得他里面讲的一点挺好玩，他其实就是说，我们现在总是对一个事情如果存在，比如说我们认为人有智能，我们就老是在找它的功能性，比如说。

我们说我们能适应环境，我们就说适应环境特重要，然后说这个地球温度特别perfect，因为高一度我们也要死，低一度我们也要死，好像就是老是在找原因，然后他的书里不停地强调，其实都是偶然的现象发生的。

然后他讲这个智能也好，意识也好，它发生的原因，你现在已经有了，你就老在问为什么，你就会觉得它是perfect，他就认为其实只是由于各种各种的随机的基因变化，导致我们人产生了一种非常奇怪的能力。

就是我们会制造很多思考的工具，就跟大家现在在问问题在思考，这种东西真的好像是别的动物没有的，这个思考的工具就是，你可以somehow用一些东西来做比喻，然后你会把外界的一些东西变成你自己的东西。

甚至于每一个人，我想刚才陆沙说得对，好像我们每个人看上去是单独的，但其实我们很多的知识都是分布在，我们身边的人，我们身边的工具，包括CHIGBT现在也成为我们的一个思考的工具，我觉得这个是一个内研化的。

总之我觉得人生下来，确实有一些根据进化以来所谓的压缩的精华，但我认为它不是一个已经知道的世界的压缩，它是在你之前的人类的这个进化史上的这些，由于随机的原因，导致的这些能生存的基因的进化的压缩。

但它还是不代表整个世界的压缩，这是我的观点，算是一个最必要的知识的压缩对吧，就是根据基因选择正好活到这个当下，你活下来的这些的最优的压缩，刚刚罗老师讲的让我想到吴老师最后的一个PPT。

就是里面有那个剑物和盾物，然后罗老师也举到了这个例子，就是说一个小朋友这个学习的过程，在我看来我觉得一个人的学习呢，它其实更像是剑物的，就是说我们在每一天的生活当中，去吸收到更多的信息。

然后是一个剑物的过程，但是呢我不知道这个，我不知道我理解对不对，请各位老师这个纠正我一下，但我看到的这个AI的每一代的智能的这个发展，它有点像盾物，就是说我把这个足够多的数据喂给它。

然后它的这个intelligence就会上一个台阶，对，所以我也因此我的问题就是说，这个人的这个学习或者人的这个意识和机器的意识，在除了这些地方之外还有哪些地方是不一样的，要不然我先问问吴老师，对。

我觉得不一样太多了，就是说，因为罗汉说就是可能，信息科学和计算机是傲慢或者是，他搞信息科学，但我不傲慢，就是说忽略了很多那个认知科学，甚至可能文化中的一些东西，就是说因为他们跑来打靶。

就是说benchmark这种，就表去就我做这个做这个做特别好，我好像解决智能问题，不是这样的，其实我们人类社会是特别特别复杂的，我觉得真的这个我们能有太多太多的能力是目前，目前来讲没有实现的。

所以说我觉得真的不同点太多了，我一下子一下子都不好落列，其实大家可以看看一些心理学认知科学的书，你会发现我们人每天干的事情真的是太多了，绝对不是现在那个GPT，他语言回答得很好，但是我们生活中很多事情。

他都没有这方面的能力的，就最基本的一个巨声这个词就没有，是的，是的，这个我其实还有个问题，就是以这个问题来问，就是人类脑子里有什么事情是很长时间来看，AI都无法复制和学习的，就是当然今天几位老师都提到。

就是说在现在可能做的最差的事情是这个，手眼协调，但是也有很多很多人对吧，包括这个顶级的学者，尤其是最近在美国很多顶级的学者出来做的都是，比如说像P。I。

Physical Intelligence这个部分，就是说人类最后的壁垒可能是什么，这个要不然罗老师你回答一下，你的问题是说人脑有什么，机器现在没有了是这意思吗，长期来看人类脑子里的什么东西。

是最难被AI学习和复制的，其实我说话经常非常矛盾，对刚刚批评希基哥有加傲慢，我并不是说，就是我还是，我有的时候在任何一个moment，你可以回头再看二三十年前大家的回答，就比如说以前大家。

刚刚AI出现的时候我记得刚下围棋，你要是去采访很多的这种大咖，他们都会说不行不行，他们不会语言，他们没有情感，然后我那天就很开玩笑的，我当时就问我们家的孩子，他们当时应该上小学，我就问他们同样的问题。

我发现他们的回答是一样的，所以就说，我觉得这个就像一个非常意识下的回答，就是我们会把一些，我们觉得非常主观的东西就认为机器没有，但是现在随着很多很多的发展，你就会发现情感是可以计算的。

其实情感并没有大家想象的那么复杂，虽然我们自己觉得，哇 这个怎么可能机器有情感，情感是可以的，如果你把，我刚才忘了哪位老师讲的这个，内感觉的系统放到这个机器里面去，它其实就是可以解释情感的。

还有包括现在的语言，已经到了这种无以复加，我们以前上课的时候，最喜欢举的第一张PPT就会说，机器语音识别很差呀，加几个人就识别不了了呀，加了噪音识别不了，现在就默默地把那张PPT去掉了，不敢再讲了。

真的不敢再讲，以前真的就是老是用这个例子，然后说我们人脑可以做特别好，宝宝就可以做呀，现在把这张PPT默默去掉，所以我觉得这个，人工智能和信息科学正在攻击人类的这个疆域，这是一定的事情。

然后所以这个问题实在不敢回答，因为回答了就打了一个靶子，比如说下面如果有这个做人工智能的说，好 罗老师说长期不能攻克，我一个月就给你攻克了，我真的不知道，但是我觉得意识是个好的问题。

因为意识就是我刚才讲的，它是集大成者的皇冠问题，可能刚才也有很多老师同学，我们后面聊嘛，就是意识是什么，确实大家不知道，但是大家是不是又同意一点，就是意识不是大家想的那么简单。

它里面有很多很多的这个融合的这个部分，还有包括你刚刚问我这个问题，我觉得就是说，我觉得Daniel Dennett讲的那个蛮有趣的，他讲的就是说，你如何去产生一种思考的工具，我觉得这个工具挺酷的。

就是它不是像GHBT回答一个问题，它是可以把一些无关的东西都变成一个工具，再一次地去问自己，还有就是现在人类说的这种原认知，我感觉也还蛮酷的，就是说好像是，不能完全是自我意识吧。

就是我解决完一个问题以后，我对我自己的一个考量，我对我自己的追问，我觉得这个东西也是感觉是至少，现在还没有被攻克的，不知道明年会不会被攻克，对 这个问题我接下来问一下这个，我觉得是这个学术界里面。

也是比较显著的探鉴，问一下这个刘迦老师，就说，对 其实然后我那个，刚才罗汉老师说到打脸，其实然后我被打脸打得太多次了，然后因为2020年那个5月份，然后那个GPT-3出来，然后6月份当时就开资源大会。

然后我们当时这个论坛特别火，为什么特别火呢，然后就是因为我说那个大模型，那就是搞笑的，对 然后我们当时，我和吴时老师还是比较温和，然后我是比较那个，后来就发现被打脸打得比较厉害，但是我现在这儿想说呢。

然后那个就是，如果假设，如果假设让我非要选一样出来是人类有，而现在AI目前连人影都没看到的，一种功能的话，我觉得这个东西是有的，那么就是我们人类的，死亡意识，死亡意识，为什么这么说呢，其实这个东西那个。

其实是一件很神奇的事情，你可以看到啊就是那个，原来那个动物的进化呢，是自然界的这个压力，对吧 然后你必须要survival，你一旦survival了之后，能够生存下来，你就可以躺平了。

对吧 所以说我们能看到，比如像鳄鱼，它在这个世界上已经存在了两亿多年，两亿年前它是这个样子，然后两亿年之后还是现在这个样子，它不需要再演化了，因为它就可以躺平了，因为我可以生活得很好对吗，那个皮糙肉厚。

然后战斗力也很强，但是人是一个很稀奇古怪的物种，人然后就是，一旦进化成人了之后，人就开始自己跟自己卷了，其实我们人可以已经生活得很好了，但是我们人还是不断地在卷，对吧 然后一定要让生活得更好。

那么已经不再是自然界给我们压力，而是我们自己人在给自己压力，那么在背后的一个，这种进化的动力在哪儿呢，就是我觉得有个很重要的动力就是，死亡意识，因为人是所有动物中间唯一一个，有死亡意识的一个动物。

因为我们小孩，即使他离死还有很多很多年，他也知道自己必将要死，而对于动物来说，只有他当生命最后一刻的时候，高等动物他才知道自己要挂了，然后或者让他去找一个地儿，然后自己来。

其他的可能动物连这种想法都没有，那么我觉得人就是属于，生活在这种，最大的确定性和最大的不确定性之间，就最大的确定性就是你知道你一定会死，最大的不确定性就是，你不知道你什么时候会死。

这么然后一个双重压力之下，人就一直想超越死亡，超越死亡是什么呢，就是卷，对然后你去发明出各种知识出来，你去比如刚才，吴斯然后他去说我想知道楼管的，然后一个核心问领魂三问，这个与你生存有关系吗。

没关系对不对，你把这三个问题搞清楚了，对你能活得多长一点吗，你工资能高一点吗，一点意义都没有，但是，但是，这就是我们想对死亡意识的一个超越，好，那么我们把这个放到AGI，现在AGI的所有进步。

都是人卷出来的结果，而不是AGI自己卷出来的结果，那么我自己坚信，AGI一定会超越我们人类的IQ，这个是我觉得，这个不用说大概率，就是一定会，但是它一旦超越了我们人类之后，我们把。

就像那个baby把它养大成人之后，我们挂了对吧，它能不能再继续进化，如果假设它能再进化，那它的动力是什么，它不会死对不对，CPU烧了换开CPU，然后那个电线断了重新连根电线，它不会然后有一种。

然后向前的一种，发自本能深处的一种恐惧感所带来的，这么一个前进的动力，它没有，对吧，它也不用担心能源不够用，它也不用担心GPU不够用，因为这对它来说，照是一件很简单的事情。

要获取更多能源也是一件很简单的事情，那么将来然后让AGI去前进的，或者进化的动力究竟，它内生的动力究竟是什么，我觉得这是我们人类和AGI到目前为止，就我能看到的，或者至少在几年之内。

然后我觉得没有累来的，我也想不清楚AGI，它有什么样的自己动力，自己去演化自己，把人类灭掉这个很简单，它不需要因为这个动力而进化对吗，因为我们人类自己就会把自己灭掉，对，对我总结一下。

就是刘老师的观点就是，人类的最后壁垒是内卷，对，对，所以，对对对，所以我们这个内卷现在是我们作为人类，非常大的一个优点，对，然后这个我也问一下隋老师和朱老师，因为这个，这个刚刚这个刘老师在讲的时候。

我就在想，这个死亡意识有没有可能会被堆积，能不能通过这个强化学习训练出来，这个死亡意识，以至于让以后的这个AI学会自己内卷，隋老师，这个是不符合这个伦理的，那个，所以这件事情，这件事情在前面被讨论过。

也被设计过，但是可能不会被作为一个优先级很高的，事情来处理，但前面那个问题其实，其实这个我还在想说如果轮到我回答，我回答什么，这个刘老师基本上把我想说的，说完了，这个。

但是我其实是换了另一套这个narrative，就是说我们，我们是有一个，作为一个种群，我们是有一个相对固定的生存周期的，不像刘老师用词那么直接，就在这个相对固定的生存周期，它意味着什么。

意味着说如果这个周期的时间，它降一个数量级，或者升一个数量级，比如我们按现在100年来算，它降一个数量级或者升一个数量级的话，那我们的整个的智能的这些演化等等，我们的社会形态各方方面面会产生区别。

肯定会很不一样，那么别说它，一个这个系统目前它可能没有能够看得到的，一个相对比较固定的生存周期，那这是它和我们的一个，一个非常巨大的一个区别，对，但反正这个说我们是不是可以来，构建一套这个奖励系统。

使得那这套奖励系统，非常，这个真实的去还原，可能人在整个的生存周期的里面的这些，这其实是可以的，这个当然不是说我们现在马上就能够做出来，这要做相应的这些投入，往这条路线去做，但要不要做这个事情。

这可能还是个问题，对 这是我的，周老师你觉得呢，第一是能不能做出来，第二个是该不该做，我觉得不太能做出来，就是我们当然可能可以是吧，在人类的反馈下面，然后来试图对齐这个AI系统。

它对死亡或者其他的一些东西的一个表征，但是这可能又跟我们今天讲的意识有一丢丢的关系，就是这个死亡意识它真的是可以被report的吗，是可以被汇报出来的吗，换句话说用心理学家的话。

它是一个意识上的还是一个意识下的，有很多的死亡意识可能不是我们consciously知道的，但是它会guide我们的行为，所以现在的这个这一套对齐系统，据我肤浅的认知，其实是根据人类主观汇报出来的知识。

然后来进行机器和人类的对齐，它会忽略掉大量的人类意识下的，那些我们自己都未必能够觉察到，或者清楚地说出来的一些主观的体验，包括对死亡的恐惧，所以从这个意义上我觉得，可能不是那么容易实现的一件事情。

至于要不要做，那我觉得这里面还涉及到一系列的问题，AI要不要有死亡，那还要不要有繁衍，那还要不要等等等等，我觉得那是太科幻了，那个可能留给后面吧，对 确实这个，杜老师，这个麦咱们就先放在杜老师那儿。

对对对，那个我觉得刚才刘老师给我一个很好的启发，我可以给你一个可能比较好的答案，就是现在AI肯定没办法实现的，就是那种不具备有loss function，因为AI它无论将来怎么设计，任何怎么设计。

它都需要去，你要做一些，你人为设计带有明确的loss function，对或者不对，好或者不好，就你有很明确，但是很奇怪我们大脑境界当中，有很多东西完全没有loss function，你love 爱。

这个你死亡，然后你情绪的悲伤，你的loss function你该怎么去设计，还有一个，人很容易做一些spontaneously很随机的事，你在路上走，你突发起想，啪，我用脚把这个石头给踢掉。

这种spontaneously的探索，其实非常重要，就是因为我们人类包括学会，用火去烧烤，就是因为看到有这些东西，人总是会spontaneously的去试一下，就是这种spontaneously的行为。

某种意义上来讲，它就是我们人类在进化当中，往往在某一个关键点上，能够跳出local optimal的一种，一个很关键的一个东西，但是这种behavior，就是这种情绪这种反应。

你很难从我目前对AI的了解，你很难用一些明确的loss function，来指导它，你可能会得到一些很随机这种散射的，然后最后把你这个讯息系统会讯得很差，所以这也是我现在想到一个。

就是说对于那些不能明确用loss function，来描述的东西，我觉得现在短时间内，目前这个AI的体系，还是没办法能实现，也许以后可以，但是现在我认为是比较困难的，好 谢谢杜老师。

刚刚其实我们讨论了很多这个，这个AI的能力，然后其实我今天早上还看到了一个视频，里面有Hinton教授提到了一个观点，他说AI意识比人类意识更好的地方呢，就是AI是数字化的，它可以制造非常非常多的副本。

然后每一个副本都可以查看，全互联网上的数据集，并且可以非常高效地共享，但是呢其实人类我们是每一个智能体对吧，我们是一个单独的智能体，我与各位老师的沟通，只能是通过语言 肢体语言，其实人类之间的这个。

共通共享是一个非常低效的，然后所以呢有非常多的人就是在呼吁说，要去找一个这个，要稍微减速或者是暂停这个AI的发展，因为他们认为可能AI是。

better version of AI intelligence，对，然后就这个问题呢我也想问问看各位老师哈，各位老师是这个，加速主义呢还是这个减速主义，对，然后，对超级对齐就是对走哪个路线。

然后怎么看这个AI意识，它其实真的发展起来之后，它的比人的这个能力可能要强很多，因为今天各位老师也反复提到群体意识这个，这个这个概念，这个看看哪位老师愿意先回答，其实我觉得有一条路可能是你没有提到。

就是我们可以借助AI来实现人类有效的对齐，是吧，我们大家都在用GPT，然后某种意义上我们就通过GPT作为一个工具，我们互相之间实现了一个对齐，所以可能从这个意义上。

它not necessary是一件坏事，但，但别的意义上就不好说了，刘老师你觉得这个，这个通过AI来实现人类的对齐这个事情有可能吗，感觉有点变了，怎么变成机器在这个训练我们，强化学习我们。

我觉得然后人类从来就没对齐过，那个就是因为大家的观念是各种各样的，我觉得然后就是让人类对齐，我觉得这件事情我觉得是永远不可能发生的，那个随着这个社会的多元化的进行，这本身是一件好事情，我个人是采用。

我个人的观点啊，我一直是相信的是那个有效加速，为什么呢，因为我觉得这个社会的发展最好还是，就我一直个人的一种观点就是，一边造船一边开船，只要你造船的速度，快于船沉没的速度，That's okay。

就是说你不要等这个船造好了你再去开，其实那时候就已经晚了，我觉得现在然后AGI给我们呈现了，就是说或者是大模型的发展都还不到AGI，给我们呈现了一种，极其极其大的一个opportunity。

这可能对于我们人类整个而言，是然后难以想象的一个opportunity，比如说就像刚才我和罗欢老师在下面开小会，然后我们当时就谈到，比如说然后意识这个问题，然后如果假设我们放在以前去谈它，那我们就是。

置我们的那个学术生育就不要了，然后就是基本上就是有点搞歪理学说，但是现在我觉得它就给了我们一个机会，我们可以正大光明的，而且觉得很有紧迫性的可以去做这件事情，那么这是从小的方向来说。

我觉得更大的方向来说，我觉得然后如果假设人要和机器对齐的话，有没有这种可能啊，但这就纯科幻，能不能把我们人类的，性格，思想，记忆，甚至我们的，独特的自我意识，我们能不能有一天能上传到机器里面去。

这样的话我们摆脱我们的肉体，我们能够从此获得永生，我们就不再被恐惧意识，那个恐惧的死亡意识所困扰对吧，因为你将来到了机器里面，你如果假设算力不够，想不清楚问题对吧，听不懂，比如说然后我们信息专家的。

然后数学公式，我就加块GPU呗，然后一下就懂了，所以说我们算力可以不断地扩大，我们对世界的探索可以更多地来做，所以说我觉得从这点上来讲的话，其实然后把，与其让机器变笨，不如就是刚才我对朱老师的理解。

就是让人变更聪明，变更聪明呢，我觉得让更好的对齐了，就是我们能不能把，我们大脑这些东西把它上传到，AI里面去，上传到机器里面去，所以这个时候研究老科学，我们去探索，大脑究竟是怎么encoding。

怎么decoding的，我觉得可能这就成为，人类的最后一场，科学上的努力，因为我觉得只要完成了剩下所有事情，我们都可以躺平了，我有点听懂了刘老师的这个思路，这个思路一开始呢，这个人类最后的壁垒。

是我们的死亡意识，可能刘老师那个壁垒，说的这个有一点点保守，叫人类最后的阻碍是死亡意识，对吧，人类如果抛掉了死亡意识，就完成了这个进化的最终态，是这样子的，对群体而言呢，死亡是一个最好的结果。

对群体而言，它是我们人类能够拿到的最大的gift，但是对个体而言，死亡是一个最大的悲剧，对吧，我们没有，然后只有让，因为只有死亡，一个社会才能新陈代谢，才能让不断地向前进，对吧，所以对群体而言。

对社会而言，死亡是一个最好的gift，但是呢，对个体而言，死亡一定是一个最大的悲剧，那我在想能不能，然后把这两者合起来呢，我们个体也不要有，经受这个最大的悲剧，而我们整个社会也能向前进步呢，对吧。

这个问题，当然这就是一个，然后纯粹很科幻的，但是我觉得，这也正是让我觉得，我们老科学在此时此刻，变成然后尤其重要的一个关键，而且老科学和人工智能的结合，变成我觉得是现在，就从各种观点，the most。

important scientific question，就没有，然后之一，只有the，对，谢谢刘老师，我问一下吴老师哈，就是吴老师，第一个是怎么看刘老师刚刚的观点，第二个问题我加一个，我加一个。

刘老师刚刚这个，这个发言里面我抓到了一个点，就说这个人类社会是靠死亡来新陈代谢，那么这个AI，它靠什么来实现这个新陈代谢，和进化，所以我刚才一提问大家笑，因为发现我经常观点给大家不一样。

也就是不太一样不太好，说不好意思说出来，就是说，这个死亡意识特别有意思，他们做过这样一个，就simulation的游戏，就是说我就有很多那种，有的sample computer的life games。

你用不同的group，有一个group他们会死亡，有些group他不会死亡，结果发现，作为一个群体的话，有死亡的群体，他会在竞争中胜出的，就像刘家说的有个新陈代谢是吧，但是很有意思的是。

它进化中它产生了这个能力，它怎么就会影响到那个，我们人的那个主观感受呢，去说有种死亡的意识，我这个是想不清楚，这可能就回答我们今天会议的主题，意思是什么的问题，所以说我觉得对那个。

目前人工智能我不是特别，我觉得很多大脑袋担忧什么人类毁灭，我都觉得己人由天你知道吗，因为现在目前的所有的AI，其实都是一个混合智能，都是我们人要参与的，我不为他数据他学什么学，然后你千万记住很厉害。

我不问你问题了，你能干什么呀，你什么都干不了，它实际上它都要我们人去参与利用它，它才能干事情，只有它什么时候有个独立的意识，成为一个个体了，那你真的厉害了，但是这个什么时候出现也不知道，你知道吗。

然后至于刘家最近的永生，其实我自己的观点是，当我真要把那个灵魂三问搞清楚以后，我好像我觉得存不存在不重要了，对真的，有的饶了什么人类的灭亡，我觉得哎，我们搞清楚这一点，我们灭亡无所谓了，但是是这样子的。

我追问一下，这个饶了终极问题，但这个终极问题在你有生之年，比如说你活到一百岁，回答不了，你想不想再活几年，我原来是觉得这个问题是，永远不可能回答出来的，反而是这几年大模型AI的发现。

哎我觉得有可能在我有生之年回答出来，我不是跟你说过吗，我觉得有生之年有可能回答出来了，因为我们相当于，AI的大模型跟我们有个类比了是吧，跟我们人类的智力有个类比了，你发现，比如说我们过去认为。

我们人太独有的东西很神秘，比如说的语言的加工，现在发现你大模型做得很好嘛，那语言的神秘性就被破除了，各种各样的东西，你就在对比的过程中，可能我们还有老科学的发展，我们可能对我们了解的越来越深刻。

有可能加速在有生之年，把这个灵魂三文给回答出来了，好，隋老师你怎么看，就是还是回到最早的那个问题，就是关于我们到底要加速的发展，还是对于它来有一些限制，这里可能有一个是我们意愿的问题。

还有一个是我们的能力的问题，在我们的能力集合里面，其实我们的意愿，可能没有那么大的选择的空间，可能只能沿着现在的差不多的路径，来往前走，但如果抛开能力的这个事情，我们来看意愿的时候。

就是这个有整个在计算机的发展，还有这个AI的发展里面，这个其实哲学家的参与是非常有意思的，早年有一本书，这个叫做What Computers Cannot Do，各位老师可能有印象，这是好几十年前。

那个时候其实computer在，过去的这一百年不到的这个时间里面，相当长的时间里面，其实是扮演着最近的AI的角色，被我们来讨论，所以才有了这个What Computers Cannot Do，对，对吧。

计算机不能做什么，然后呢后面发现计算机能做非常多，就成了这个What Computers Still Cannot Do，计算机还不能做什么，对吧，到今天我们会发现这个事情在越来越收窄，这个我们整个的。

AI领域里面的这个学者传递出来的声音，以及这个我们的政府和这些公共部门，来传递出来的声音都是，AI will take tasks instead of jobs。

或者说AI is taking jobs away，but it's also creating new jobs，但是在这里我们从来不讲数量，我们不讲它的quality和对于人的这些要求，对吧。

到底是创造了一百万个新的岗位，然后消除掉了两百个新的岗位，还是这个事情是反过来的，我们今天都能够看得到整个大的趋势，那么在这个趋势继续发展的情况下，整个我们其实人类社会在前面的漫长的时间里面。

我们迭代出来的一套reward function，我们的这一套价值体系，可能还没有来得及，我们做出很好的调整和反应的时候，就受到了很大的挑战，这其实是我很能够理解一些老先生们。

尤其是早年在推动深度学习发展，但是那个时候大家都不信的这些老先生们，今天反过来能够深感其中的恐惧，这其实是很值得理解的，对 这是我的观点，罗老师呢，对 今天讲了很多对齐，原来知道这个词，今天知道更多。

也学到了死亡意识，对 我是觉得说刚才正好那个又验证了，就是大家说的如果我们把这个AI作为一种工具来对齐人，这是很好的事情，如果perfect对齐就更好，但我想讲的另外一点是。

可能人性这跟刘老师说的死亡意识确实有关，我觉得人性就决定了我们是对不起的，因为每个人都求心求意，要不然为什么大家都进来，今天听这么不着调的symposium，一定是你想去寻求一些什么信息。

无论你是做什么职业的，比如说你是一个媒体人，你希望写出一篇特别好的一个报道，如果你是一个科学家，你特别想找一个点，你是不是内心里还在想，我的这个点最好跟我的同行想的都不一样，所以我觉得对齐是不可能的。

我不知道是为什么，可能是求心求意，但是我觉得刘家老师说的对，可能这个死亡意识，或者像陆沙老师说的，它潜意识里决定了每个人的行为，我们的行为就是我们希望自己，既和别人一样。

但更重要的是我们还跟别人特别不一样，我们要是每个人都是一样的，就像刚才大家都回答了问题，我在想我最简单的办法应该说，我同意各位老师的意见，但是我好像没有办法接受这个部分，我非得说一个别的老师没有说的。

然后我觉得这就是人的本性，就这个本性就导致我们一定会这样做，然后这个做背后的原因，跟刘家老师说的那个死亡意识，可能真的有关，但还有一个原因我觉得可能就是因为，我想当大家都知道那个。

normal distribution，那个是指任何事件是独立的，我们经常认为社会上每个人和每个人是独立的，这种情况下如果互相没有干扰，它会出现一个这种正态分布，但是往往就刚才说内卷也好什么也好。

其实就是说就算资源无限的情况下，大家依然认为资源是有限的，在资源有限的情况下，事情和事件之间就没有办法独立，因为你就需要不一样，然后它就会出现一些，比如说那种hub或者一种东西，对我就是简单补充一下。

好我们还剩一点点时间，因为这个去年好像没有开放观众提问，刚刚好像也有很多这个朋友在举手，有没有现场的观众想，要不那个后面那个穿白衣服的，第一个举手非常积极，再说一遍，首先关于主持人刚刚那个问题。

我有一点想分享，我有相当主意的，就是说拉法拉伊曼，我觉得其中有一个点是，不是来源于我们是否要选择什么，而是来源于，而是来源于它可能是一个囚徒困境，现在就是所有全球范围内的，各个国家的建制派。

它其实面临的是一个囚徒困境，就是没得选，就是我们一定会加速，所以你看到中国对于，Artificial Intelligence Safety，对于AI安全方面的投入是不够的，这是第一点。

就因为我有小伙伴刚刚从牛津回来，然后他是物理系毕业的，牛津的物理系毕业的，然后他其实找了一些，跟Artificial Safety有关的，包括跟暗原AI，包括跟北大的安全组之类的，反正都有聊过。

就发现国内在安全方面的一些投入，首先是不够的，然后有很多的组在分这方面经费，然后你能看到在北美那边，OpenAI刚刚也把他们有关于，Super Love Alignment相关的人员，给裁了很多。

然后也搞掉很多，所以这块大家现在关注的更多的，都是在关注能力方面的东西，都没太关注跟安全相关的东西，这是我的一个补充，一个信息点，对 这些方面，然后我自己更关注的一个东西是，我刚刚跟刘嘉老师也交流过。

跟陆思老师也简单聊了一下，其实我最近更关注的一个点是，有关于Motivation的，对 包括在教育场景下，关于SDT理论的，包括关于爱的，对 然后我提到一个更具体的问题是说，我们从老师们关于认知科学。

关于脑科学的经验出发，对于教育场景下的孩子们而言，是否真的存在一套SOP，是可以帮他们去做自我觉察，然后做自我探索，然后做一种，找到自己的内驱动力，然后进而发现自己的热爱，同时在这个过程中间。

让他们的内驱动力和外驱动力可以有一个，他们的波峰和波谷可以在一定程度上填平，让他们的驱动力处在，让他们去挑战一些困难问题的，这个Motivation能够处在一个，相对稳定的状态下的这样的一个SOP。

我不确定这个东西在质感上是否存在，对 这是我最近很关注的一个点，刚刚罗老师问了个问题，SOP是什么，这种社畜就知道了，SOP就是标准的操作方法，或者说一种范式吧，对，刚刚这个同学的这个问题就是。

有没有什么办法让我们这个标准化的，把人类训练成更优秀的人类，要不罗老师您先回答一下，就不是去训练他，就是让他自己去找，你这个问题特别像教育部长的问题，我会提这个问题的关键，我简单介绍一下我自己的背景。

我是北理工的本科软件工程家车辆工程，然后出去去美国读的航空工程和机械工程，下面的Dynamics and Control，就我其实也是搞控制出身，然后高中是打物理竞赛的。

然后但后来反正做了很多不同的行业以后，现在转过来在做教育，对所以就会特别的关注，就你的问题当然是，我觉得绝对是全社会最关心的问题，我也很关心这个问题，就是所以我说是教育部长回答的问题。

然后那个标准的程序，就是我觉得整个社会就是一个改革嘛，我们其实就在做某种强化学习，我们通过课本通过奖赏标准，我们在训练我们的孩子，希望他们成为最好的孩子，然后我们希望他学习所有所有的东西。

但是现在大家也发现这里面最大的问题就是，如何去培养他的内趋力对吧，这种内趋力是心理学非常非常关心的问题，就每个孩子都有好奇心，那他的内趋力怎么培养，我觉得这里面有很多，其实现在已经越来越多的改革了。

包括大学的一些课程，还有很多的课程，我自己的个人观点就是说，可能要结合吧，一种是通过课程的灌输，但另外一种，就我自己觉得啊，我主要是带研究生的经验，就是还是要通过项目的探索，非常像巨神认知。

就是不能坐在，就不能坐在这个屋子里面听老师讲，还是要通过一个项目，然后得到feedback，然后自己去主动地去学习，补这个知识，再得到feedback，在这个过程中他的内趋力就会非常好的建立起来了。

我只是非常小一个点，谢谢老师，我们再开放一个问题吧，好 那个各位老师好，现场观众好，就是我有一个问题，就是，大家就是都在强调人工智能，就是，其实美国那边也想停下来，然后他是担心中国跟俄罗斯一直停不下来。

然后其实人工智能更多的是应用在军事层面，然后其次比如说像政治，然后经济层面其实倒是其次，因为我本身就是上海江江高科，一家军工企业的负责人，然后就是我的问题就是，人类发展到今天就是。

人的智力水平就是目前最优秀的人，也只是开发了6%左右，我们为什么不把更多的精力去用在，就是去研究我们人类提高我们人类本身，自身的一些，就是开发我们的潜质的一些东西呢，这是我很想知道的一个问题。

因为各位老师都是跟这个有关系的一些，那最后的提请刘老师回答一下，首先来讲啊，我们不是说我们大脑只开发了，然后那个只开发了6%，我们大脑上是100%的都用上了，不然回答你这个问题，我是所有神经元都在放电。

全放起来，全放起来，所以说但是我觉得是这样子的，我觉得我们人类的面临这么一个问题，一百万年之后，我们人类究竟是会比现在聪明很多呢，还是跟现在差不多一样笨，答案非常让人难过。

就是一百万年之后我们人类还会跟现在一样，因为我们大脑大概是3。5斤左右，那么这个大小，它的神经元的多少连接，已经被我们的身体所决定了，我们的心脏 我们的肺，它只能提供这么多营养，支撑这3。5斤。

再多个一斤，我们心脏和肺就不能支持，所以再过一百万年我们的心脏和肺，它一定不会更加地提高，所以如果假设仅仅靠人进化的话，你可以相信，人的IQ是被锁死了，这是一件非常难过的事情，就我们可能会逐渐地上升。

比如说会利用更多的东西，比原始社会的人了解更多，但是你的算力已经被锁死了，被我们的肉体给锁死了，所以这个时候人要进化，就一定不能再靠自己，一定得借助外力，这个外力是什么，一定是AI。

否则人类再过一百万年，还像我们今天一样蠢，还会做一样的蠢事，这是一个特别难过的事情，所以说我觉得我们现在，然后就是发展AI，并不是说我们要在军事上，然后去取得更多的优势，或者在经济上面。

让我们在技术上有更强的能力，我觉得我们现在发展AI，目的是为了人类有一个更好的未来，是为了让我们的文明，能够进入到更高的一个境界，我觉得这是我们做AI的一个唯一的动机，谢谢刘老师。

我刚刚以为您已经不关注，人类这个群体的进化了，听完还是非常的安慰，然后我们时间也到了，正好我就问最后一个问题，就每个老师用一句话回答，去年的问题也差不多，然后我稍微带大家回忆一下。

去年有几位在场的老师的回答，去年那个问题是，你们觉得AGI什么时候到，然后刘迦老师的回答是，去年如果人类是100分，大模型是10分或者20分，然后杜老师的回答是，5年内会有强大的AGI出现。

然后5到10年，这个AGI会像人类一样，然后吴老师的回答是，20年内能取得重大突破，今天这个问题我再问一遍，看看各位老师的答案，有没有什么变化，要不然先从去年没回答的老师，先开始回答 隋老师。

我觉得已经基本上实现了，对 但是出于综合的考虑的话，我们一般来讲我们是用不了的，对 但是已经，是因为超级对齐对吧，就是因为考虑到一个东西，如果它能够非常确定，开放给我们的每一个人，知道我们是谁。

知道我们的能力集合，知道我们的安全线等等，它其实可以把这个能力，再往上有一个协助的一个提升，但是这个事情，现在开放的甚至大家，在这个有些还需要注册一下，有些连注册都不需要了，所以就这个能力上来讲。

从我的认识上来讲，我觉得已经有了，只不过就是说什么时候，能够被更广泛的人所使用，就这个时间表我现在还不确定，罗老师你怎么看，我被吓着了，真的吗，个人观点，那我觉得还是早点开放吧，因为我觉得就跟教育一样。

原来我们说在一个好的大学，学生有更多的资源，但是只有少数人有，那现在随着这个各种各种的平台，然后世界上每一个人，都可以去获得这种知识，所以我觉得如果他已经来了，那只能是学会跟他和谐相处。

把他们作为另外一种思想工具，因为我觉得还是取于这个AGI的定义吧，就是可能在一定的定义下他work，我不知道上升到，我们今天讨论的意识层次，他有没有达到，这个我不大清楚。

我觉得只要把他作为一个立项的课题，然后国家投入大量的钱有可能，大概五年内能解决，在清晰定义的情况下，朱老师，我觉得这取决于你怎么定义AGI，我这是一个比较，比较取巧的回答方法，就像意识领域有所谓的。

难的问题和简单的问题，这个AGI大约也有一个，难的定义和一个简单的定义，那maybe在这个简单定义上的这个AGI，我们就像隋老师说的，我们已经差不多可以拥抱它了，但如果我们给AGI提出一个难的定义。

比如说他有自主学习的能力，他有自我 他有意识，他有自控感，那我想也许，我可能跟吴老师有点像去年说的，我觉得可能还要一个，十年二十年的时间，要不吴老师先说一下，你跟去年的观点还一样吗，我还有四九年。

非常准确，杜老师，我其实有点失望，因为去年我们开那个大会的时候，好像四出来了，然后呢四到四零，我觉得他的逻辑推理能力几乎没有，没有变化，没太增强，所以本来五到十年我倾向于五，现在我倾向于十，对。

也不是九对吧，不是九是十，可以说九吧，九九九 九年九年九年，刘老师，对，那个就是，AGI就是我非常同意，刚才那个就是，罗欢老师和朱璐莎老师那个的观点，就AGI本身没有定义，就这一块，那个就是。

所以说很难，就是说图灵测试已经失效了之后，你一个新的测试还没出来，所以说从科学的定义上来讲呢，它可能就是说还是一个问题，对吧我们怎么去了解它，但是我个人觉得，就是AGI的出现就是一个有生之恋系列。

因为它已经把它所有，挡在它前面的，一些技术上的难题，我觉得已经工程上的难题已经解决了，我觉得剩下只是一个，工程的问题，我觉得现在唯一的一个科学问题，就是我们人，怎么去和，那个AGI去怎么共处。

我觉得这个是然后，唯一的一个科学问题，我觉得工程上不是问题，所以说如果假设你要问多少年，就像我刚才在那个台上这讲的，说不定明年就不用我们来做报告了，直接是AGI来做报告，这也是完全有可能的，对。

因为它已经进入到这么一个高速发展的时候，一旦高速发展它就已经是一个，非线性的，几何级数的这种上升，这个谁也控制不了，对我刚刚故意没有说，刘老师去年的答案是多少年啊，刘老师去年的答案是2030年，对。

对没多久了没多久了，抓紧时间，在我们退休之前，抓紧时间学会和AI相处，谢谢各位老师，谢谢，最后呢，允许我说最后一句话，我们非常感谢主持人，就是李鸿鸣老师，是中理资本的投资人。

去年本来我们是找了一个主持人，一个非常专业的主持人来，结果专业主持人，最后要到上台的时候，说对不起刘老师我要结婚去了，我就来不了了，所以我当时正好和他在聊天，我想投资人主持人会到。

所以我就说你能不能当主持人，所以说去年就来了，而且特别好，而且发现人家出身就是专业的主持人，所以今天我们又把他请过来，他听说有这个会，所以说专门从上海，然后跑到北京来的，所以说我们以热烈的掌声。

感谢一下李鸿鸣老师，谢谢刘老师，谢谢。
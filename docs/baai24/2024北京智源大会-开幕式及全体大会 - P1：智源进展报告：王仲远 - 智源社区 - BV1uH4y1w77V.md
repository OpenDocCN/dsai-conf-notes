# 2024北京智源大会-开幕式及全体大会 - P1：智源进展报告：王仲远 - 智源社区 - BV1uH4y1w77V

尊敬的各位领导，各位来宾，各位专家，各位朋友，大家上午好，再次欢迎大家来参加今天的志愿大会，我是王仲远，非常荣幸能够从黄老师手中接过接力棒啊，在志愿大会上继续向大家报告。

支援过去一年的研究和工作方面的一些进展，智源研究院是2018年11月份成立的，一家人工智能领域的新型研发机构，我们致力于推动人工智能技术的原始创新，智源的含义是智能的源头，我们希望能够成为学术思想。

基础理论，顶尖人才，企业创新以及发展政策的源头，智源智源大厦位于海淀区成府路150号，这里也是海淀区人工智能创新街区，以及海淀区人工智能大模型集聚区的呃，核心区啊。

因此也也非常欢迎大家来智源大厦做一做啊，进行学术的交流，资源是一家非盈利性的科研机构，我们致力于啊人工智能领域前瞻性，战略性原创性的研究和技术突破，我们拥有顶尖的学术顾问委员会。

张宏江博士是我们的顾问委员会主任，那么其余七位委员均来自全球最顶尖的，学术机构的呃院士，在过去5年，智源率先啊遇见了人工智能大模型时代的到来，早在2020年10月份。

我们就已经成立了一支百人的技术攻关团队，开始进行悟道系列大模型的研发，在2021年3月份的时候呢，我们发布了悟道1。0，6月发布了悟道2。0，那么悟道系列大模型的发发布，在当年都创造了中国首个啊。

全球最大这样的一系列的纪录，那么进入到2022年之后，我们的悟道二系列大模型继续向多语言，多模态啊去持续的迭代，在去年的智源大会上，我们也发布了悟道3。0系列的成果，那么应该来说资源呃。

智源研究院与大模型这三个字是紧密的关联啊，甚至大模型就是志源最早提出来的，进入到2023年啊，大模型从研究机构的科研成果开始，向产业界啊逐步的发展，我们也看到在过去的这一年啊，百花齐放。

有越来越多的这个大模型啊，在在过去的这一年啊发布，那么如整个人工智能的发展浪潮啊，过去七八十年的这样的一个发展历程，那么以2023年为界，基本上可以分为两个大的阶段，都属于弱人工智能时代啊。

也就是整个人工智能的这个模型，它是针对特定的场景，特定的任务，那么需要去收集特定的这个数据啊，训练特定啊，训练特定的模型，那么比如说战胜人类世界围棋冠军的阿法狗啊，他能够在围棋上下的非常好。

但是它却无法直接用来解决医疗问题，无法直接用来做自动驾驶，虽然方法可以借鉴，但是针对不同的场景任务都需要去做啊，这个数据和模型的重新的收集和训练，那么进入到2023年，随着大模型的发展。

人工智能将逐步的进入到通用人工智能的时代，那通用人工智能呢最大的一个特点呢，就是它的规模非常的大啊，出现模型具备涌现性，同时它能够跨领域的通用性，那么在过去的这一年。

scaling law是被反复讨讨论的一个啊一个名词，它的一个基本的含义呢，就是说随着模型的参数啊，以及训练数据量和计算量的持续的增大，模型的性能也持续的提升，但是如果我们回看过去七八十年。

人工智能的发展历程，尤其是神经网络的发展历程，实际上skin low并不是一个新鲜的事物，那么这张图的左边的部分，实际上是我2018年做的一张PPT，那么我们可以看到。

事实上在人工智能过去的三次发展的浪潮，每一次新的人工智能技术的突破，都是伴随着模型参数训练数据量，计算量的一个持续的攀升啊，所带来的人工智能的领域的一个突破，那么进入到大模型的时代。

我们看到大模型的参数是在以量级啊，每年都以量级的提升一个量级的速度在发展，在18年时候啊，BT的模型基本上还是E级的参数，到2021年，GPT3就已经是1750亿的参数，到去年的GPT4啊。

业内普遍认为是1。8万亿的参数，可以看到啊，它与人类大脑的参数啊，科学家们普遍认为，人类大脑的参数在一呃，100万亿到1000万亿之间，那么整个大模型与人类大脑的参数呢，其实从过去几年。

从相差100万倍到1000倍到去年100倍，那么如果按照大模型的这个速度继续发展哦，我我们会认为在未来几年，大模型的参数很可能就会改善，或者超过人类大脑的参数，这也是我们认为AGI时代。

有可能会在未来几年啊，到来的一个很重要的一个原因，那么如果ADI时代会到来，它可能的一个技术演化的路径会是怎样的呢，我们知道在过去几年啊，绝大部分的这个科研的关注度。

包括咱们产业的关注度都在大语言模型的突破，但大语言模型依然是一种单模态的模型，那么在这个世界上，除了文本这个数据以外，还存在大量的图像，视频，音频等等这样的多模态的数据。

而这些数据量呢可能是文本数据的十倍，百倍乃至千倍的规模，因此呢在这两年开始，这些年开始也开始有呃，多模态大模型这方面的一些研究啊，但基本上呢产业界里面还是呃针对不同的模态，跨模态就有各自的模型。

同时呢理解和生成也是分开的，那么我们认为从技术发展的路径来看啊，最终会形成一种统一的多模态大模型，它能将理解和生成统一，它能将不同的模态数据进行统一，那么当多模态大模型能够理解和感知决策。

这个世界的时候啊，那它就会有可能进入到我们的物理世界，那么如果进入到宏观的世界跟硬件结合，那么这个可这就是巨生大模型的发展方向，如果它进入到了微观世界，去理解和生成生命分子。

那么这就是AI for science，那么无论是聚生模型还是AI for science，亦或是多模态模型，都会促进整个世界模型的发展，最终推动人工智能技术向ATI方向发展。

那么基于这样的一些技术判断啊，资源研究院在呃多模态大模型，聚生大模型以及生物计算大模型上，将在未来几年持续的投入研发，那么今天也非常高兴啊，借着智源大会的这样一个场合呃，向各位朋友介绍一下。

我们智源在大模型上的全家桶，那么今天的这个报告里面会包含五部分的内容，分别是我们在语言大模型，多模态大模型，聚生大模型，生物计算大模型，过去一年的一些研究方面的一些进展。

另外呃一个工作是支撑所有这些大模型，技术迭代的一个基座，也就是是一个算力集群的操作系统好，首先我们来看看智源研究院，过去一年在语言大模型方面的一些进展，我们知道过去这一年啊，其实呃各家公司。

各家企业都训练了大量的这个模型，尤其是大语言模型，那么企业已经做的事情，资源研究院就已经呃，就不会再去再去重复的做啊，对于语言大模型的历史使命呢，在过去几年资源已经为整个技术的推动啊。

整个产业的发展作出了卓越的贡献，因此在大语言模型方面，我们主要要解决产业界的共性的一些痛点，那哪些是产业的共性的痛点呢，比如说算力的缺乏，那么因此呢，我们与中国电信人工智能研究院一起。

联合研发了一种基于生产技术训练的，全球首个第一碳单体稠密万亿语言模型，简单来说，我们就使用了行业里面不到10%的算力，也就112台AA800啊，那这样的一个算例呢。

我们就能够训练出啊这样的一个dance model，万亿参数级别，同时在整个训练的过程啊，基于我们呃量呃超最优的超参预估技术，我们实现了整个训练全过程的零调整，零从试，最为关键的是。

我们不仅会将这个模型开源，我们还会将其中的技术细节，loss曲线啊全部进行开源，那么这也是智源研究院为开源社区，为整个产业界所作出的啊重要的贡献，那么我们整个模型其实依然正在训练过程中。

我们对于自己在生产技术训练的这这个中间的，一个过程的版本，我们也进行了评估，那么评估的结果显示，我们的这个BPP的loss曲线，确实要优于拉马思瑞，那么整个万亿级别的这个dance model。

当我们把它训练完成之后，我们将把它完全的开源，也希望能够为社区训练万亿参数的稠密模型，提供一个优秀的初始参数的版本啊，避免万亿参数模型早期难以收敛的，这样的一些具有挑战性的问题。

同时基于这样的一个基座模型所训练出来的，对话模型，我们也进行了一个初步的评测，结果显示，它能达到GPT480%到90的水平，那么请大家要注意，我们仅仅使用了100余台的A800机器。

来训练这样的一个模型，那么除了算力紧缺的这样的一个问题之外啊，大模型在产业界落地，最重要的另外一个挑战就是他的幻觉问题，那么在这边我也想向大家隆重的再次介绍，我们的呃BGE模型。

那么我相信所有产业界的朋友啊，一定对于这个模型是非常非常的熟悉，那么因为它是啊，全球下载量最高的国产AI模型，也是最普及的开源向量模型，那么我们的研发团队呢啊，基于这种创新性的无监督预训练。

和多阶段的对比学习，以及构建了一个多语言啊，关联文本的数据集CMTP，那么基于这样的一个呃高质量的数据集，以及我们创新的算法，BGE模型，从发布之初起就一直保持国际领先的位置，那么也正是得益于这样的呃。

又好用又轻量级的这样的模型，所以它在开源社区广受欢迎啊，我们可以看到它的下载量是持续的攀升，并且得到了全球主流大模型应用框架的集成，包括hacking fs，那么index啊，lam chain等等。

同时呃各家云服务厂商，像ARILAWS火山引擎，腾讯云，华为云，百度云都集成了BGE的模型，并对外提供商用，我想这就是智源研究院对于开源社区，对于整个产业界的一个重大的一个贡献。

那么以上就简要的介绍我们在啊语言模型方面，解决共性问题的一些研究的一些进展，下面我想给大家报告一下，我们在多模态大模型的，过去一年的一些研究的进展，多模态大模型依然处于一个，持续的迭代和演进啊。

技术路线还没有收敛，那么因此呢智源研究院在过去的一年，持续的在视觉多模态领域，发布了各项领先的研究成果，引领整个开源社区，去年7月份的时候，我们发布了第一代的email啊。

这是一个呃生成式多模态运预训练模型，去年12月份的时候，我们发布了emu two呃，它截至目前依然是开源社区最大，性能领先的深层式多模态大模型，那么今年2月。

我们还发布了EV i clippers8B模型，它是开源社区最大啊，性能领先的180亿参数视觉表征的click模型，它也被用于非常多的呃，多模态大模型中的视觉编码器的部分，那么整个多玛太大模型。

过去这几年以及在未来的几年，我相信都会非常的火热，但是它的发展现状是此动模态非彼多模态，我们知道在行业里面，各种模态的转换已经有了很多优秀的模型，比如说像图像理解和视频理解有g p t four v。

比如说像图片生成有stable diffusion，大力E，比如说像视频生成有solar will，比如说像语音理解有最近发布的啊，G p t four o，那么每一种模态之间都有这样的一个呃。

主流的一些模型啊，他们以多种模型的方式来存在，那么从技术路线上来看啊，到底是使用diffusion model还是使用auto aggressive啊，到底是这种单一的跨模态还是统一的多模态。

那么到底是理解和生成应该分开，还是应该呃结合，那么到底是基于这种组主城式的呃，组装式的这种多模态，还是要原生的多模态，其实存在不同的技术路线的一些一些争论，那么智源研究院呢以终为始。

我们呃基于对于前面的技术路线的发展的判断，我们还是非常坚定的，要走统一原生的多模态的技术路线，我们去挑战整个行业里面最难最呃，最具有挑战性的一个技术路线，那么这个技术路线如果实现突破。

相信对于整个产业界，对于整个社区又将是一次重大的技术贡献，那么这就是我们正在训练中的鹅苗山啊，那它是统一了文字图像视频啊，使用自回归的技术路线，那么实现了图像视频文字的输入和输出啊。

并且实现具备更多模态的可扩展性，那么我们的鹅苗山系统，目前其实依然是正在训练的过程中，很坦然的讲，中间的技术难度和坑还是不少的，那么呃我们呃今天非常高兴的，借智源大会的这样的一个场合。

也跟大家分享我们训练中啊，目前的一些进展，那么整个峨眉山的研发的目标是，原生的多模态世界模型，那么在这里原声指的是，我们从一开始就会将多种的模态进行融合，同时将生成与理解进行融合，能够扩展。

那么并且由于是auto regressi的这样的一个框架，它也能够进行持续的可控的这样的一种交互，这是我们鹅苗山啊中间的一个check point in的模型啊，目前能够具备的能力。

所以这是呃它的图像生成能力，那么可以看到它的图像生成能力，还是非常非常的优秀，那么呃我想强调的一点是，它不是基基于diffusion model，而是基于auto regressive的这样的一个。

智回归网络的呃，鹅苗三，同时同样的这样的一个模型，它也能够进行视频的生成，那么这是我们峨眉山当前一些视频生成的呃，一些中间的一些结果，我们可以看到啊，它还是能够呃去捕捉到整个这个世界啊。

世界模型的一些规律，那么中间依然有不完美的地方啊，但是我们的模型依然在持续的训练的过程中，同样啊这个模型也是基于智回归的网络，是与刚才的图像生成是同一个模型，那么还是同还是同样的这样的一个单一的啊。

统一的多模态模型，它还具备图像和视频的理解能力，比如说在右上角的这个视频，我们问他啊，他有什么感觉，我们的模型能够回答，他感到了一种幸福兴奋的感觉啊，我们问右上角除了这个人在做什么，他能够识别呃。

理解这个是一个失望的男人，正在看手机上的消息，那么左下角的这张图片呢，我们在问说诶，这个最近的这个交通灯是什么颜色，我们应该怎么做，它也能够识别出其中的红灯啊，我们可以看到其红灯的这个信号。

还是非常的微弱啊，那我们的模型也能够理解，那么我们请他描述右下角的这个视频啊，它也能够去识别出这是一个动态的呃，天空上面有非常多的云，那么还是想强调一下，这跟刚才是同一个模型。

而且是基于一个智回归网络的鹅苗山，那么我们的email three模型啊，它依然在持续的训练过程中，当模型训练完成啊，经过安全的评估，我们也会将其逐步的开源啊，如果各位朋友呢等不及也可以先尝试我们的呃。

上上一代的这个鹅苗EMONE和emu two啊，他们已经在社区里面进行开源，如果大家觉得还是不过瘾，也可以试一下，我们一个轻量级的图文多模态模型呃，班里那么bi呢它是一个基于灵活的架构。

能够支持不同的视觉编码器，像刚才提到的EV a clip，然后也能支持不同的这个语言基座的模型，然后能够实现这样的一个图文多模态的，一个轻量级的模型，所有的这个模型的啊。

模型本身数据训练代码我们全部都开源，那么这个就是智源对于整个开源社区，对于咱们产业界的一个贡献，更多关于资源在视觉多模态方面的成果，大家可以访问我们在呃开源社区的一个主页啊，来了解。

那么接下来想给大家介绍的是啊，我们在聚生大模型方面，过去一年的一些工作进展，那么我们刚才也提到，多模态大模型，能够帮助计算机去感知和理解这个世界，那么接下来它就能够演化成一个智能体agent。

那么我们也看到了，最近其实像MICROSOFT口拍了apple intelligence intelligence，那他们呃确实能够去控制这样的机器，开始使得AI手机AIPC啊开始成为可能。

那么我们也在过去的这一年，研发了一个通用计算机控制的系统，叫CREDLE啊，它能够像人类一样看着屏幕，通过鼠标键盘完成计算机的所有的任务，反思过去，总结未来啊，总结现在，规划未来。

那么这样一个在数字世界的agent，如果又进入到了物理世界，那么会发生什么呢，我们可以一起来看一个短片，你好，Being in，帮我打印费树里的文件，对当数次世界的android进入到了物理世界。

那么这就是聚生智能，基于我们对于聚生智能作为整个大模型，技术路线发展上的这样的一个重要的一个判断，因此在过去一年，资源研究院也非常坚定的在聚生智能，这个方向上持续的投入，我们在机器人的末端操作。

在聚生大小脑在导航啊，在这个自研的硬件上都有呃，都有一系列突破性的一些成果，下面我也给大家简单的介绍，那么机器人的抓取呢，是整个机器人最最重要的啊，一个一个最基本的一个操作。

那么过往呢这种通用泛化的抓取呢，面对这种反光的物体，面对透明的物体应啊经常会失败，那么我们通过构建了一个大规模，高质量的在仿真系统中，构建了千万量级的场景，以及超过10亿的抓取的这样的呃数据。

训练了一个通用抓取的模型，然后实现了simple real的这样的一个抓取技术，的显著的提升，我们在工业级的真机上，能够实现超过95%的抓取的成功率啊，创造了世界的纪录，我们今天也将这样的一个机器呢。

其实带到了这个智源大会的现场啊，一会也欢迎大家能够去啊我们现场的展厅啊，展台去做体验，那么除了这样抓取的技术以外啊，巨神智能最最让人感觉到兴奋的呢，是他的这种思考的能力啊，这就是大模型。

给巨生机器人可能带来的一种新的变化，那过去两年啊，过去一年我们也研发了两个啊这样的专模专用，各司其职的这种大模型，那么sage呢是一个能够反思，可随机应变的操作大模型。

我们基于三维视觉的小模型加图文的大模型，能够让机器人啊，在失败的时候能够继续啊去反思，然后去重新规划它的一些啊操作的动作啊，进而去啊实现啊实现再一次的尝试。

那么open six store呢是一个全球首个的开放指令，六自由度的呃取放大模型，我们知道这个呃google发布的RT系列的机器人呢，它能够实现三自由度，但是如果我们要让这个抓取啊能够真正的实用。

我们不仅要考虑物体的位置，还要考虑它的姿态，它到底是立着的还是还是横放着的，那么这些才能够使得这个抓取的技术，真正的有效，那么我们的，我们在呃这个这个这样的一个抓取上，也是最终实现了技术的突破。

那么这一这个技术呢一样的，今天大家可以在现场是可以体验得到的啊，机器机器人还需要行走起来，因此我们在过去的这一年，也研发了一个面向技术终局的，端到端聚生导航大模型啊。

那我们知道过去机器人它是需要依靠离线啊，提前建好的这个地图来实现导航，那但是人类其实并不需要这样啊，人类完全依靠视觉，那么为了让机器人能够啊真正的智能化起来，我们也实现了一个纯视觉。

纯seem to real的这样的一个解决方案，真正的实现了video language in action out，所以右边的这个视频展示的是，我们在智源大厦的内部啊，包括刚才其实是天呃。

就智源大厦的天台，也是今天呃晚宴的一个位置哈，也非常欢迎大家去智源大厦参加我们的晚宴，那这个这是真正的在虚拟的环境里面，我们实现了训练，然后直接就能够在真实的场景中去进行泛化，有这样的一个导航的大模型。

那为了将我们的这些大模型啊，巨生的大模型能够真正的进行落地，我们也与这个北京银河通用机器人公司啊，一起去基于他们呃迭代的这样的一个硬件呃，聚生的一个轮式的机器人，然后来来将我们的这些模型和技术。

进行了场景的落地啊，那这个场景呢包括了像无人药店，包括了像家庭服务，我们可以看到右呃，最右边的这个视频里面，机器人已经能够去啊自动化的这样的清理垃圾，那中间的无人药店呢，能够根据用户下单的这个药品去啊。

去去自动的智能基于视觉的方案啊，能够去啊去拿正确的这样的药品，那么我们的机器人还能够去思考啊，比如说当我说我渴了，我们一起来看下机器人会如何反应，我渴了，好的给您带个土豆，对如果告诉机器人，我饿了。

看看他的反应，我饿了，现在有橘子香蕉，您要两个橘子，谢谢好的，给您拿橘子，可以看到机器人能够根据啊，用户的开放的指令进行思考，还能够与用户进行啊交互，在基于我们前面所提到的，这种泛化的抓取能力啊。

能够真正的去实现这种啊，这种通用的泛化的执行啊，指令执行，我们也将这样的一台机器人，其实带到了支援大会的现场啊，在对面的这个会议中心的展厅中啊，如果大家有兴趣的话，可以去现场的体验一下。

那么除了像无人药店家庭的场景以外，聚生机器人，在医疗场景也会有非常重要的一个落地，那么在过去的一年，实现了全球首创的智能心脏超声机器人，并且在真人上实现了啊自主的超声扫啊扫扫描。

那呃我们将我们的这个机器人的这个呃，这个心脏超声的这个结果呢，医生的这个扫描的结果进行了对比，那么我们发现在准确性，在高效性上与人类的医生是基本持平的，但是它的稳定性呢和舒适性啊。

是显著的高于人类的医生，更为重要的是啊，现在整个全国这样的一个超声机器啊，超声的这个医生是非常缺乏的，我们也知道经常在超声的这个这个这个科室啊，排队也是排的最久的。

那么它对于整个提升我们在呃超声这一块的，整个医疗的普及度和水平啊，都有非常重要的意义，我们也将这样的一个技术呢孵化出了一家公司，那么也非常欢迎大家关注我们的这个公司，那么在未来啊。

整个聚生智能依然有非常多的技术问题，非常多的产业落地的问题是需要被解决的，我们也将联合像清华北大，中科院这样的高校，以及像银河加速净化等等这样的产业，上下游的呃产业链，然后有希望有更多的生态合作伙伴。

跟我们一起来解决，聚生智能中的一些核心关键性的问题，包括像数据要素，包括像模型以及场景应用，那欢迎呃，全国所有对于这个聚生智能感兴趣的高校院所，企业与智源研究院联系，接下来我想给大家介绍的是。

我们在生物计算大模型方面的一些进展啊，刚才提到了深层式人工智能，已经推动了整个人工智能啊，领域的一些重大的突破，那么当它进入到微观的世界，我们是否可以用相似的这样的一个生成式技术。

来解决生命分子的理解与生成的问题呢，这就是智源进行生物计算大模型研发，的一个初步的一个思考，同时它对于整个产业界也有极为重要的意义，我们知道在药物研发领域，从有一个双死双死定律，从新药的研发到它的上市。

通常要耗费10年以上的时间，以及10亿美金以上的投入，那么其中三四十%呢是在啊药物，在药物设计也就在临床前的部分，这也是人工智能最能发挥的呃作用的地方，那么除了像化合物的这种筛选和预测以外。

那么对于大分子的这种结构的建模和预测，也能够推升，像基于RNA这样的大分子的一些呃，新药的设计，那么这也正是人工智能啊，对于医疗领域的一些可能性的一些贡献和突破，那么基于这样的一些思考呢。

我们就设立了open complex的这样的一个项目，他希望能够研发啊统一的生物分子计算模型，打通啊，基础生物分子像蛋白质啊，RADNA小分子之间的这种壁垒，并且能够研究生物分子之间的相互作用的关系。

那么我们构建了一个全原子的生物分子模型，它是一个decoder only的模型，那么我们可以一起来看一个短片的介绍，生成式人工智能技术的发展，正在加速人类对生命奥秘的揭示，了解生命的过程。

必须观察和理解数10亿个生命分子间，的数百万种组合和相互作用关系，这一庞大的数字计算工程，无法用传统的物理方法高效完成，智源研究院开发的open complex，基于生成式人工智能技术。

能在原子层面进行蛋白质RNA，DNA小分子的结构和相互作用关系的预测，精度达到超级计算机的水平，这样的能力使得科学家可以进一步理解，生命的机理，未来我们希望逐步构建一套微观生命，科学的孪生系统。

为人类理解自然本源带来新的可能，Open complex，好我们的open complex在国际权威的蛋白质呃，国际权威的榜单，卡密尔的蛋白质结构预测中，已经连续26个月稳居第一啊。

那么无论是在精度还是宏观结构方面，都优于同期的模型，像包括像alpha four two，那么除了像蛋白质结构预测以外，它还具备其他复合物的预测，包括像RNA呃，DNA以及蛋白质的这样的复合物。

那么我们也展示了我们的预测的结果，与ENT统这样超级计算机的预测结果，那么最终的结果显示呢，open compress已经初步具备了通路预测的能力，那么左边呢在这边的一组实验中。

左边是我们open complex的啊，预测结果，右边是啊ENTON呃，超级计算机它的一个预测，我们不仅结果相似，并且我们没有像ENTLE那样的一些噪音，那么呃这就是生成式人工智能。

所带来的一个技术的突破，我们能够使用非常少量的GPU，就能够实现，原来只有超级计算机才能够做的事情，我们还将这样的技术呢应用在了啊实时新呃，新站的计算建模上，那么实现了全球首个实时完生。

精湛的一个计算啊，通过GPU的这样的加速，能够将心脏的生物秒和计算秒是呃，突破到了一比0。9，真正的实现啊临床应用的可能，我们也正与北大第一医院安贞医院，长庚医院呃，朝阳医院进行合作。

将我们这样的技术应用在临床当中，以上就介绍了智源，围绕整个大模型技术发展路线啊，我们所做的一些研究，那么很多的研究工作依然在进行，也请各位朋友可以关注，我们在未来几个月以及下半年。

持续的对于一些研究成果的发布，那么所有的这些研究成果呢，都要依赖于一个非常强大的一个基座啊，那这就是我们的一个算力集群的一个操作系统，在去年的时候，我们发布了flag open1。0。

它是一个面向异构芯片，支持多种框架的大模型，全站开源的技术基座，经过一年时间的迭代，flag1。0升级到了2。0，整个技术的这个呃自底向上的这个框架，是更加的成熟，也更加的完备。

比如说有我们有这个面向不同芯片的算子库哦，我们有面向异构AI的计算的框架，我们有数据处理的工具，也有这个啊整个各种各样的算法，和我们前面所提到的像email啊，BGE这样的一些非常优秀的模型。

那么这样的一个开源的呃，整个开源的一个系统框架呢啊，能够真正的实现一站式领先的高效应用的，大模型的算法和工具，我们也与全球的主流的一些基金会合作。

像linux foundation i h o e i MB a以及HAGFISH合作，能够希望促进整个开源社区在人工智能，在大模型这个领域的一个快速的发展，那么基于open呃。

flag open中系统软件的部分，以及我们自研的九鼎平台，我们也构建了一个为大模型而生，支持异构芯片的算力集群操作系统，这个操作系统在过去20多个月内，已经稳定的运行。

支持了超过50多个团队来训练大模型，能够支持八种的AI的芯片呃，我们也非常欢迎啊，全全国各地的计算中心，能够适用我们的这样flag o s，接下来可以看一个关于flag o s的短评介绍。

可指定一种算力资源详细配置，开启跨不同AI芯片的异构算力自动迁移功能，平台依据flag puff工具，在不同异构算力上的性能评估，历史数据，将初始算力资源配置，智能映射至等效的其他算力资源。

实现无缝高效的自动化异构资源配置，九鼎平台启动全局算力智能调度，直至调度成功，平台基于TRITTON大模型算子库，实现任务跨AI芯片的自动迁移，集成的flag scale，进行并行策略的动态优化。

充分利用集群的异构资源，提升训练效率，缩短训练周期，降低训练成本，嗯flag open里面有非常多的模块，接下来我简单的介绍以下其中啊，flag os和flag open中一些核心，关键的一些组成部分。

那么其中一个呢是面向大模型的开源传承，算子库啊，在大模型的这个算子库中，我们也统计了下主流的，大概通用的有120多个算子，我们目前已经实现了48%的全覆盖，能够支持六大厂商的多种AI的芯片。

同时针对大模型专用的算子库，我们也有六个呃，Attention，flag attention的算子，那么能够覆盖主流的attention，并且呢呃一并且依靠着智源研究院，在大模型方面的前沿研究。

也能够紧随算法的前沿去打造创新的算子，那么呃flag of scale，是一个多元异构的并行的训练框架，我们也在业内首次实现了不同厂商呃，跨节点RDMA直连，以及多种并行策略的高效混合训练。

那么实现了首个多元异构芯片，scale up加scale out，两阶段高效训练的千亿语言模型，那么基于这样的一个异构芯片计算出来的模型，我们也将其在社区里进行了开源，今天我们还想发布两个呃数据集。

一个是千万级高质量的呃指令微调数据集，我们知道SFT阶段在激发大模型的能力上，是非常的关键啊，目前整个社区里依然非常缺乏，高质量的SFT数据，那么我们将开源千万级的呃，中英文的高质量的一个数据。

这样的一个指令微调数，以及我们的实验显结果显示，它能够让非常多的开源社区的呃基座模型，能够达到或接近GP4的水平，此外我们还将开源全球最大的中英文，多行业的数据集，它覆盖18个行业的种类，总计3。4。

T b，我们在医疗和教育啊领域进行的这个continue training，SFT加加DPO啊，训练结果显示它能够显著的提升啊，通用基座模型在领域里的一个效果。

我们的flag scare大家相信也非常的熟悉，在上个月，我们也发布了我们的资源的榜单和评测的结果，那么也非常欢迎行业里所有的大模型公司，能够使用我们的flag scale啊，Flag e well。

今天也非常高兴的跟大家分享啊，正是基于智源研究院在开源开放这方面的承诺，以及我们对于整个社区持续做啊，创新的这样的一些突破，那么我们呃flag open系列的所有开源的模型，框架工具。

在过去一年的全球首，总下载量超过了4755万次，应该来说在全国内的AI机构中，处于绝对领先的位置，那么这些优秀的成果呢，以及我们在前沿模型上的这些迭代啊，肯定是离不开啊优秀的人才。

那么因此也想借今天智源大会的这个现场啊，也打个小广告啊，欢迎大家截屏或者拿出手机啊拍照啊，那智源研究院提供了非常宽松的科研的氛围，高水平的平台以及全方位的这个福利的关怀啊。

非常希望全球最最顶尖的人工智能人才，能够考虑加入资源研究院，最后我们回到智源大会啊，智源大会在过去的5年已经成功举办了五次，我们邀请了全球30余个国家和地区，超过1000位的顶尖的专家呃。

来资源大会进行分享啊，其中包括11位的图灵奖的获得者，那么在去年的资源大会上，相信大家也是留下了非常深刻的印象，像星INGTONSAN奥特曼呃，Tech mark rusell。

他们都参加了我们的这个志愿大会啊，其中尤其是其中的这个，我们在去年第一次设立的AI，安全与对齐的论坛，我们知道，随着深层式人工智能技术的快速发展啊，通用通用人工智能时代有可能会到来。

那么AI所带来的安全的问题也是不容忽视的，那么智源研究院啊致力于在AI安全上啊，我们进行技术突破和研究，确保人工智能在发展的这个过程中，始终是造福人类安全可控，今年3月份呃。

我们的顾问委员会主任张宏江博士也发起了啊，志愿研究院，举办了首届北京AI安全国际对话，那么也邀请了包括像新INGTONBENJOR呃，RUSELL姚先生啊，傅莹薛兰啊等等全球顶尖的啊30余位的专家。

并且我们共同签署了北京AI安全国际共识，那么在今年的志愿大会上，我们也依然设立了我们的AI安全的论坛，明天一整天依然是大咖云集啊，非常欢迎大家进行关注，在两天未来两天的的日程中。

和我们的资源大会上有20余个的论坛，百场的报告有非常多的啊，这个朋友告诉我啊，看到我们的这个日程之后呃，第一个感觉是自己的分身乏术，那么我想这就是智源大会的魅力所在，那么一样的。

我们今年的智源大会依然是干货满满，我们有来自全球主流的呃这个模型啊，模型的技术负责人，项目负责人来介绍他们的最新技术，也有国内顶尖的啊，各个模大模型呃，技术负责人，同时我们也会对于大家对于呃。

大模型的各种关心的问题进行全面的啊解答，所以非常欢迎啊，大家能够享受未来两天资源大会的日程，那么今天上午的开幕式呢，在我的报告结束之后呃，有会有OpenAI的呃负责人，来介绍。

在多模态大模型方面的一些最新的一些进展，然后我们也会对于通用人工智能，进行一些讨论和对话，那么也请大家能够享受开幕式，接下来的流程，我的报告就到这。


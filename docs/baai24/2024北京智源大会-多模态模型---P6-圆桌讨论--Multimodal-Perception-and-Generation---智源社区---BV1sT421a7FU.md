# 2024北京智源大会-多模态模型 - P6：圆桌讨论- Multimodal Perception and Generation - 智源社区 - BV1sT421a7FU

好大家好呃，对今天很很高兴有这个机会呃，就是精心准备了一个圆桌的环节，就是我们刚刚也听到了很多我们动态，包括视觉语言最新的一些进展，然后呃整个领域的进展也非常快，我们呃也想借这个机会。

然后有呃几位非常资深活跃的这个学者，然后我们讨论一些呃，现在领域内比较核心的一些问题，然后当然也包括技术的，或者包括一些这个high level的问题，然后呃刚刚在座的三位老师，大家刚刚都已经这个呃。

听过他们的精彩的报告了，然后线上我们还有两位呃两位嘉宾，然后呃我不确定已经，还没有呢啊对对对，我先介介介绍一下，对这个是呃家辉，然后家辉呃啊，之前做过很多很多非常非常突破性的工作啊。

包括这个呃这个party啊等等，然后他现在是open i的perception team的负责人，然后今天也是很荣幸有佳辉加入，我们来一起讨论啊一些问题来对，然后呃。

这个待会待会也很期待听听家辉的一些见解，佳慧能听到吗，哎感谢邀请，能听到啊，好的好的，然后另一位还有呃沈春华老师烧水，大家好，大家好，我我我很不好意思啊，我这个笔记本倒了半杯水，这个摄像头坏掉了。

沈沈老师，大家我相信也比较了解，他是国内我就比较资深的学者，也是我自己的这个导师对，然后，好那我们今天就直接开始，然后我呃准备了一些问题，然后呃不一定我能问完，最后希望呃就是给大家一些提问的机会。

然后对我们就直接开始吧，然后呃第一个第一个问题呃，我觉得也是呃开场一个比较好的一个问题是，大家觉得就我们看到的视觉跟语言的这个发展，先是in internet的，这个啊带领了我们很多年的发展到语言。

那呃在现在这个时间点，大家觉得视觉是AGI的核心部分嘛，然后有可能以什么形式贡献，并且能把我们往AJI的路上啊带到哪，然后呃，看哪位老师先只有一个话筒吧，都有都有都有，要要不谢老师呃，我能听到吗。

啊啊呃呃他应该能看出来我我我的回答肯定是，我当时觉得vision会是通往AGI路上的一个呃，一个这个critical path中的，中的中的很重要的一部分啊，至于为什么是这样。

我就我想说可能想问在座的各位，你愿不愿意丢弃你的为人对吧，我觉得呃我我我觉得可能应该大大，大家可能呃并不愿意做到这件事情，我我觉得我觉得是这样，就是呃另外一件事情是HI，我觉得跟很多它它不仅仅是智能。

它对human experience，emotion等等这些非常nuanced的，很难去通过语言capture的东西，也是紧密相连的，然后我觉得vision作为一个我们很重要的一个。

sensory的medium，我觉得是必不可少的啊，但可能之后可以继续讨论一下跟TECHNI个问题，但是至少我这边的观点是，我觉得vision是必不可少。

然后我也觉得大家应该work on vision more，好谢谢老师啊，我呃我的观点也是微信是必不可少的，但可能因为今天在座的几位，都都都都都是做微信perception的。

所以所以我估计可能大家观点都差不多，对我我觉得嗯从一个角角度来说吧，就是那个呃其其实就说分析人的这个认知的话，嗯就就就说有有有一类叫叫叫叫，叫做是explicit这个memory啊，就是显示的记忆啊。

那部分就说你你的那些寄到了一些东西，学到东西是可以用语言来进行描述的啊，这个是explicit memory，然后其实还有很大的一块叫做implicit，这个memory啊。

里面其中有一部分叫做procedure，这个MEMEMORY啊，就是过程记忆，或者就是影视记忆下面的过程记忆，比如说你学会怎么游，怎么游泳，怎么骑自行车，怎么投投投篮，比如说用one motion啊。

一段是投三分啊，我最近在练玩模型，我练了快两年了，最近总总算是练好了，然后结，结果刚打打了一两场学校的教职工篮球赛，结果就受伤了，然后打不了了，就呵对，然后就是这些东西的话。

就是这种on procedure memory为代表的这些东西，其实它不是用语言可以很精确地进行描述的，它是你的一个experience，它是适于要需要，就像刚才谢谢在领导说的这个sensory。

grounding啊，就是它是通过这种方式去进行学习的，所以我anyway，我觉得视觉是非常重要的，我说完了哎，我觉得啊，前面几位老师讲的都已经啊基本都讲到了，然后包括我自己的呃，talk里面我也提到。

就是我我相信呃real world experience是需要vision的，如果我我退一步讲，就是之前之前唯一没有提到的，是一个可以较为哲学的观点是什么呢，就是到我们到底为什么要vision对吧。

生物体为什么要要vision，那么你可以想象就是比如说曾经的哲学家，比如说嗯这个亚里士多德的说啊，我们要要要知道往哪看啊，那这个特别的有点形而上学的感觉，但是你要如果想从进化的角度来说。

那就是纯从达尔文的角度来看，那我们为什么要vision呢，哇你要繁衍生息对吧，就是make babies that，Can make babies。

That can make babies forever，嗯但是这个好像也不是很就是特别的呃，令人满足，这个这个答案，我觉得很多时候是一个一个不只是一个这种，这种竞争的关系，或者生物体之间的竞争关系。

还有一个就是一种从真实世界中，学习和和交互的一个过程，然后我觉得从这个角度来看，a vision应该是在智能形成的过程中必不可少的，家辉有什么补充吗，呃我很同意大家的观点啊，就是说我觉得啊。

东莫泰是这个AGI的必不可少的部分，然后当然就说理由也跟那个上面说的很定，有点像了，就说我们怎么来看HI对吧，定义是什么，那有一种定义，就是说AGI是希望能够就说完成大量，人类能完成的。

具有经济价值的合法的一些任务啊，那那我们可以想象这个事情，就是说假设明天一起来，我们就是不看任何东西啊，你可能本来一天能完成20个任务，你看看就说我们还能完成多少个任务对吗，就是呃所以这个是呃。

就是说非常显然的一个答案，当然就说就说大家大家都说这个呃，这个是需要的，就是说我觉得有一种情况下有可能是不需要的，但是这个也跟那个AJI的定义有关，就说我们今天讲AGI呀。

我们还是希望它能够benefit human，就是啊并不是简单的一个智能体，在那里就说自己跟自己，我觉得有一种情况下可以想象，就说如果世界上都是这个硅基的智能，就说没有没有人类的话啊。

有有可能他是不需要一些感知，或者说视觉，或者说某种这个啊传感器，但那个就是说跟我们今天所定义的，AGIS不一样，所以回过来就说AGI是要服务人类的，那他是需要这个啊感知啊，需要这个多模态啊，这些好。

谢佳慧稍稍时能听到吗，呃能听懂能懂，对那个我非常同意刚才家辉家辉的观点啊，就是这这个额视觉肯定是AI的一个必不可少的，一个component，但但是不是A加A，那这个就完全取决于你怎么定义A加I了对吧。

那我想我们在做都是做视觉的，那这个它的重要性这个就不用再debate了，是吧啊，对对对，是的对，我们先建立了这个共识，然后这个对，而下一个，我觉得也是现在大家相信都非常感兴趣的，一个问题。

就是我们看动态的任务，包括我们这个panel的topic叫mari model，perception and generation呃，我们可以把任务呃。

简单的分成generation和perception，那在现在这个时间点，就是大家觉得呃生成跟感知的关系是什么，然后动态的生成跟感知应该统一嘛，然后这个对，我就相信这这大家可能会有不同的一个看法。

然后佳慧要不你先来来得谈谈你的观点，因为你可能是这个最最接近的这个嗯，对我是研究过程中，是特别想把两个事情在一起做啊，然后我相信对我们在场所有的研究员来说，几乎就说这个答案是肯定。

就是说我们希望能把这个事情更尽可能简化，尽可能去unify啊，所以我觉得就是那有可能对工程来说，不一定是啊一个同样的这种这种这种希望啊，就对研究研究员来说是大家都喜闻乐见的事情。

那那这个问题我觉得关键还是在于说，我们有这个初衷，我们喜闻乐见这个感呃，就说合在一起，但是能能不能做到对吧，今天的有没有足够多的啊，证据说这条路应该是the way to go啊。

这个我我觉得今天就说一个领域共识定共识，可能还是还没有到那一步，就说还没有到，说我们只往这个UNIFI的方向上走，其他的跟ENLIF不相关的啊，直接就丢弃啊，这个我觉得今天来讲还也还是不对的啊。

所以所以如果今天来看，这个是不是应该unify，我觉得应该unify，但是就是还是evidence driven，就是说不能说我们要一条路摸到黑，就是对整个研究领域来说不能一条路摸到黑啊。

因为今天他就说以不盈利，fire的方法也能带带来很多任务上的这种突破啊，给大家带来很多帮助吧，好谢谢家伙，听起来就是还是有很多的这个研究的问题，我们待会也可以讨论到，然后特特对我。

我其实跟家辉的观点呃是完全一致的，就是现在我们作为这个研究的本身，肯定是希望他们他们能够成为一个主体，但但是呢现在主要是涉及到，我觉得工程上的问题，嗯暂时来言是是没有看到这个这个点的啊。

但有可能比如说是因为我们的这个嗯怎么说呢，learning objective不对，或者是我们我们什么地方还没有做做清楚嗯，这个还不好说呃，但是退一步讲，如果我我觉得，所以这是一个非常值得研究的问题。

但是如果退一步讲，比如说如果嗯我们是是否是因为现在的呃，比如说现在的呃paradigm有局限性，或者说它没有成为一个，比如说真正所谓的general intelligence的这样的一种能力。

使得它两种方式不能融合啊，这个也不好说，只能说这是一个非常非常重要的问题，我觉得作为作为研究本身需要解决它，好谢谢特特戴老师啊，我没有什么更新的观点，我完全同意两位的观点，所以我就不说了，好的谢老师呃。

那我给个更这个definitively answer吧，我觉得呃一定会统一，并且我觉得应该需要统一呃，我个人想法是这样的，我觉得当然大家研究这个general classify，已经有很长时间了。

然后并且从BAS的角度来说，你其实这个p s given y p p y given x，这两件事情其实是可以互相转化，所以ITIDTA也聊到对吧。

就是你your diffusion model is a secretly呃，As you shall classified，就这件事情我们已经能够看到一些signal，那从我的角度来说。

或者从representation learning的角度来说，我似乎觉得china mol是一个很不错的，去学习reputation的一个办法，因为呃简单来说就是说。

如果你现在只model like p y given ax，你的public density，其实只是在这个wide space上去compete的，不管这个Y是呃。

One thousand labels，或者是这个这个这个这个fix5CAPRA这个language，它还是一个比较离散的，比较有局限的一个空间。

但是如果你现在要model这个这个p x given y啊，那你的density是要在整个的这个large的这个，VODOM面上去compete的啊，这件事情必须带来的结果是。

我们要对这个image或者video或者整个的view content，会有更deeper的understanding，我们需要知道呃，比如说一只四条腿的猫。

要比一只这个三条腿的猫更likely to happen，然后这件事情我觉得是一个很N吹弱的问题，并且我觉得呃至少我个人而言，我觉得这是一个对understanding来说。

一个一个非常critical的事情，对啊，当然具体的时间上我完全同意前面嘉宾说的，就是我觉得我们不知道该怎么做，我其实对对谢老师，谢老师有个问题，就是我觉得这个在理论上是是很有意思的。

那你觉得这里面比如说呃在probability上面的modeling，它到底是应该是一个什么样子，laden space去model这样的probability。

比如说在general model的角度来说，它很多时候是pixel space，那这个的space它可能不是一个最好的，比如说laden space去去学习这样，比如说四条腿猫。

三条腿的猫这个概念对吧，right对呃，这就回到一样的观点对吧，他说we we should not work on general models。

Because we don't care about this，Kind like very deep construction。

we care about some real representation in some some form and latent space啊，但我觉得这些都是open question。

但是again maybe嗯，嗯这个final summary就是我觉得呃看到so2之后，我觉得其实这条路线是有可能能走得通的啊，然后具体的representation到底应该怎么做。

这些我觉得我们需要更多的research，沈老师在有呃，对这个问题有什么看法吗，喂沈老师，沈老师应该电脑又坏了，呵呵哎好，我们先待会待会沈老师再接进来了，然后我补充一点啊。

就是我们刚才讲到这个生成和这个感知，在视觉这个堵门啊，我觉得有可能我们需要再跳出来看，就是说有可能视觉和，比如说文字和其他的一些signal，就说它们放在一起的时候，也可能帮你做生成，它就能带来感知呃。

然后如果纯视觉，它也能带来一部分感知，但并不是就当我们讲，比如说理解的时候，今天还是再把一些visual的concept map到一个，比如说texture的concept。

比如说我们看到一条狗说这个是golden retriever，但它其实还是一个文字的表达，就是说以文字给它来约定，所以当我们在讲，就说是不是生成和理解要统一起来看的时候，就是啊。

有可能把这个视野再拓宽到其他的一些，signal上啊，有可能这个答案会更肯定一些，就是更更赞同那个赛宁老师的这个观点嗯，嗯嗯是的，对，我们后面还还还诶，沈老师，大家能听到我吗，可以可以哦。

我刚才这个麦克风也出问题了，这个很奇怪啊，哎anyway，呃，对我我我我接我，我补充一点，就是其实这里面有一个呃，就是从某些能力的角度来讲，就只因为你你我我们我们在谈感知嘛，CEPTION嘛。

那以前在视觉里面，几乎所有的CEPTION的任务都是用呃，DISCRETIMODEL在做嘛对吧，从基本上从八九十年代一直到呃，一直到最近这这这这35年前对吧，那么就就所以从我们新人利的角度来讲。

其实这这就是generative，Mogenerative model，Versus，这个discminting model，那以前为什么generative model做不好，这。

这里面当然最最主要的原因就是就是这个，computing power和和这个数据的问题嘛，对吧，这个高性max model就是一个general model对吧，这个这个在在在之前小数据的时候。

这个几乎是这个用处非常非常小，所以呢我我我的我我的一个理解，就是说以前不是说大家没有意识到，general to model的重要性，而是说啊受限于很多这个当时的这个呃限制。

他他没有办法去去把这个去训练，非常大的这个jn general timodel，没有办法把这个jn t model的这个呃，优势给发挥出来，所以不得已而为之去去去用这个discreen model用啊。

早期的support vector mach啊，boosting啊，后面这个用呃，这个CNN去训一个classify等等等等对吧，那么今天就是说从呃从GPT的呃。

这个success到到到现在这这最近这两三年时间，大家看到啊，这个general timodel，很显然是能够更好地利用大数据对吧，他这刚才赛林老师也提到这这这这这很明显嘛。

他他可以把这个dist性给学出来，那肯定直直接比你去去用啊，Discretion of discretion model，直接学一个mapping，他能他能学到更多的信息嘛，所以理论上来说。

你如果能把这个genental model做好的话，那perception的很多问题，可能就自然而然的就就做好了，就不需要呃，用以前的那一套这个discreen model的这种做法。

去去去去解决这个perception的问题，我就我就说这一点嗯，新龙我能我能在泡可以补个很短的简短两句，就是我就非常非常同意沈老师的观点，而且我我我我想在座的很多学生，其实是没有历史包袱的。

就是他是活在这个java i的时代对吧，但回过头去其实可以关注一下，比如说甚至30年前，40年前呃，比如说alan you，然后包括这个我PCD老师的作文。

他们那时候有这个analysis by thesis的学派对吧，就是大家认为对图像的理解，对图像analysis其实是需要对图像这个钉子的，就是生成来做到的。

其实有很多很非常有意思的discussion，并且阿兰佑也呃，最近也给了一些talk，在YOUTUBEYOUTUBE上都能看到，我觉得对我来说是很有启发的，虽然怎么样。

bridge他们这些old school的这些concepts to something呃，Can be can be deployed in in in in the current error。

I think it's another question，但是我觉得呃呃again，故个人而言，我觉得非常有启发，谢谢老师，然后对我我插入一个问题，本来没有准备，就刚刚佳慧也提到的呃。

可能就是大家可以考虑不同的模态，然后就我们想现在想统一的，包括研究上的大，除了生成和感知这两个任务，我们其实对于不同模态到底哪些模态应该统一，我们应该一起考虑，然后哪些模态可能是分开考虑。

大家现在好像没有一个呃比较成熟的共识，比如说我们是图片和文字视频，还是说音频，这个甚至更多的包括robotics的信号，这个大家呃怎么看待，这个只在呃更统一的多模态的语境下，不同的应该用哪些模态。

然后哪些模态可能带来更强的呃，这种这个SCALABLE的能力，然后他应该是有机融合的，这个对大可以分享一点，看如就是自由选择，可以有什么可以所有模态，所有模态，所有模态，比如说比如说视频，音频手势呃。

触觉呃，听觉呃，包括呃所谓的呃情感啊，这样所有的东西应该都在一起，因为很难去想象，就是呃我至少可能是因为我我们的自身的限制，就是我们学习的过程，永远都是所有的模态在一块的，而且很有意思的是。

其实东莫泰这个点主要在过去呃几十年里，很多时候是media study，是学communication的人在在用的一个词，其实不是在AI里面，是是这最近才才开始出来的，对吧，所以这就是回到了一个。

就是一个学习和沟通的一个过程，比如说嗯我用一个非常平和的语气跟你说话，和我用一个非常呃aggressive的语气跟你说话，这个我所表达的信息是是不一样的，然后这个信息其实对于呃文化而言。

呃是也是不一样的，比如说在在呃这里的文化也，同样的手势，可以在另一个文化里面，代表一个完全不同的意义，嗯这就说明呃我我猜测就是它不是一个嗯，他是一个怎么说呢，是跟学习是一个互相交互的过程。

你不能说我先学好了以后，我再去做多模态，而是我觉得你要从头就开始，从所有的模态一起开始学习，因为我觉得这是一个是一个非常，comprehensive的过程，好谢谢特特佳慧，有什么补充吗。

刚刚我也我也补充一点好了，就是说呃我觉得动作太本，本质呢它就是在某一个时间点有不同的信号，它在同步发生啊，那你为了就是说决定下一个时间点做什么事情，有什么事情会发生。

那就是说你必须得融合当前这个时间点的，所有的信号，所以这个在我看来就是说更加确定一点，就说比这个是不是应该生成，和这个理解应该统一，我会更加确信，就是说啊多个模态之间应该是要统一起来。

然后统一起来会发生，就是会能做更多的事情，好谢谢佳辉，沈老师或者对我说两句，就是说从research的角度来讲，从从我们在academia做做做research的角度来讲，那呃理论上来说。

你肯定你可以把所有的模态，只要你有数据对吧，可以把所有模态的数据都都都用起来，去训一个这个嗯transformer的模型，这这里面其实呃很重要的一点。

就是说因为因为现在现在就是放在transformer，或或者以前这个应该说是sequence to sequence，learning这个框架里对吧，这个这个现在几乎所有的模态。

你经过一个token ize之后，把它把把把这个input做成一个sequence，那你就很自然的就fit到这个transform，这个框架里，所以现在现在这个框架来处理啊。

不管什么样的模态都都非常方便，那在以前是做不到的，对不对，在在在在在LT在sequence to sequence learning，这个出来之前，在transform出来之前。

你不像是两维的视频是三维的，然后这个audio是一维的等等，你都要去啊，用用非常复杂的这个feature extract or去去做，做一个呃可以认为是呃pre processing，所以非常复杂。

OK那那现在非常方便，那那理论从从这个算法的角度来讲，你不管什么样的模态的数据，你你算法几乎不需要做改变嘛，所以所以很方便，就从从从从这个嗯从这个research的角度来讲。

那从application的角度来讲，那这个这个就取决于你到底想想，build什么样一个系统啊，对吧呃呃你如果做robotics的话，是不是需要把刚才特特说了，所有的这个这个有呃。

就是能采集到的数据都加进来，也许吧，但是anyway，这个这个可能这就从工程的角度来讲，可能会牵涉到一些什么data imbalance啊，等等这方面的一些问题了，好谢谢尚老师，我我稍微补补一句吧。

对我我就说，反正就是说这个肯肯定又刚才大家说了，就是多模态这个事情，从科研的追求来来来说，或者从长远的目标来说，这肯定是一个非常有吸引力的事情，当然说我我自私自己，我们肯定也是在努力在追求。

但是呢反正就实际做的时候，你真的要scanner up啊，然后做一个性能非常强的，一个多模态的大模型的系统，比如吃进去全互联网的数据，这种级别的来说，它中间还是会有非常多的现阶段的一些挑战的。

嗯来来自于不同的方面，对就说首首先我们观察到的，我们的感觉是觉得模态往上加的时候，它的有时候训练的复杂度带来的是几何层数的，在网上面在增长，如果你真的要训一个原生的多模态的话。

当然就说这就是训练方法上的问题，然后以及所谓的原生多模态呃，如果真真的要做做，做到说是在同一时刻，然后几件事情同时发生的话，对你的数据的采集，然后呃什么的，就因为现在这一代的算算法。

它其实对数据的利用效率并不是那么高的啊，就是成本这些会带来非常多的现实的挑战，所以我个人的观点，我会觉得原生多模态啊，就说从头开始训所有模态加进来，同一时刻什么的，这种训呃。

我觉得会是一个非常美好的长远的追求，但在现在的时刻，我觉得有很多的现实的问题需要去解解决，然后以及有些事其实会促使我们去反思，这一带的这个AI的这个训练算法等等，中间存在一些本质的问题啊。

比如说有灾难性遗忘啊等等等，带来各种各样的问题是吧，好谢谢戴老师，我可以说两句吗，可以可以可以呃，对我我我完全同意呃，Like all modalities，嗯matter。

But they are not equal，我只想说一件事，就是也是回到之前的talk，就我觉得language这个东西，可能要考虑单独拿出来看一看，就是呃就是就第一是它太强了啊。

会导致会影响其他MODITY的学习，第二是这个东西真的是人类特有的东西，然后呃至少对我个人而言，我还是比较希望能够看到某种意义上的animal。

intelligence或者cat intelligence，before a g i的啊，当然我觉得like this is a long term research，刚开始出来一点。

就是当我说到就所有模态的时候，可能还是比较就是赞同呃，塞宁的观点，就是所有的国泰应该在一块，但是我们不想要看到的是一个模态，去dominate其他的所有的模态对，尤其是当这个language。

比如说赛前在top里面也提到了，就是language上，你非常容易就像有一种cheating的感觉，因为它是一个所谓的人类特有的，至少我们认为是人类特有的东西，当它有的时候。

你可能很快的把它跟跟intelligence连到一块去，那那这时就会发现，就是我们在evaluate一个一个系统，它到底有没有INTELION的时候。

可能会有bias towards language啊，那这会是一个问题，但你说我们比如说做做一套系统，一个human computer interaction，他也必要有language。

他一定要有language，不然我没有办法跟他沟通，对，可以没有language吗，我觉得是是呃wow，我觉得在一个理想的世界里面是可以没有language的，因为比如说假设我们人不存在。

那我们啊就假设另一个智能体吧，那把它们丢到地球上，那它不见得一定要有language，他可能只要有一些简单的这种沟通方式，甚至甚至假设如果他们都有什么，我们从科幻的角度来说。

他们有这个可以用无线电信号去互相沟通，那他把他的这个hidden state发给你就好了，其实没有必要，没有必要用用language去跟你沟通的对吧，language是一个人特有的东西。

它是一个非常compact的东西，是因为我在这说话的速度，我不可能就跟你用这个呃，呃wireless signal这个速度去跟你跟你沟通，所以这个是我觉得是一个现实逼出来的，一个一个东西。

而不是他说是一是不是一定要一个intelligence，必要有的东西，非常希尔特非常棒的这个观点，我们播放到下一个下一个问题，然后呃呃就是我们刚也讨论到了，有不同模态的这个呃任务。

然后包括也有生成感知啊，理解的这些任务，呃，但是呢我们目前好像还没看到一个类似CHEGP，这样大家所有人都能感知到的这种呃突破，当然大家可能有不同的这个看法，就是我想问一下在座的各位呃。

老师就是大家认为呃对于多模态的，不管视觉语言或者是其他模态的深沉和感知呃，的理解的这些任务，什么时候或者达到什么程度，算实现了对应的CHANGP的moment，然后或者说我们现在已经有了吗。

还是说呃还需要一呃更长的时间来让大，让大家都能感触到的这种啊多么high的，真正的类似CHEERP的这种moment，我要不我先来回答一下啊对啊，其实我我这这今天的PPT里面有有提到。

就我我我我的个人观点是那样的，就从生产力发展的角角度上来说，就是文本这个模态模态的chat g p m moon的，我认为它具有特点是亮的，首先第一点它在一些重要的任务上，它的性能足够好。

然后第二点的话，它是能够低边际成本的，泛化到这个开放的任务上啊，就就说你一个chi g b t挂在网上了，你可以呃服务上亿人的，千奇百怪的各种各样的请求，而你服务每一个请求，它的后后面只有计算的成本。

你并不需要研究员，很贵的研究员对吧，比如说在在线的很贵的家辉对吧，这样的研究员为你每一个模型去进行一个，每一个绘画，进进行一个特调，对我觉得就是呃作为一个产品，它到了这样的一个时刻。

我觉得它才具有这种爆发，或者说就是让大大大大大改，就是切实的改变这个现实，这种生产方式的能力对，所以同理，我觉得多多多模态其距离moment也是一样的，就说反正在一些重要任务上，具有非常强的这种性能。

同时呢它应该要具有就低成本，低边际成本的泛化到开放的这样一些，请求和任务的能力，这我的我我的观点，谢谢戴老师教会线上非常贵的研究员，有没有什么补充，对对对，这个问题来本身来讲。

我觉得有一点我是不太同意的，就是说呃听上去好像这个语言的发展非常快，然后视觉啊多模态啊，就是说发展比较靠后啊，我觉得其实不是这样，就说你也可以讲，就是当年比如说CN出来的时候对吧。

比如说minister在recognize的时候，我觉得这个也是chergifty moment，因为大家这个寄邮件啊，什么你不需要人去摘抄这个邮编对吧，这个其实也是服务上千万用户啊。

然后包括你可以说啊就是RESONNET出来的时候啊，最早也是在一个视觉上啊，所以我觉得这个下集bt moment可能更多的是，就是说每个领域的这个my stone大家大都有多少。

然后是不是在持续的推进这个max on啊，就是说对于这个问题本身呢，我觉得没有特别赞同这个问题本身吗，哈哈好的，谢谢焦辉，对哦，我我稍微说一句话，就是我觉得这里面还有个BASSN的问题。

就是CHAGBT之所以好用，是因为他能写出来这些东西我是真写不了啊，他能讲的这些英文我是真讲不了对，但是一个多模态的模型，很多时候这些回答尤其它比较vision centric，或者说啊像戴老师说出来。

比如VILM里面我们能support，比如说process mation detection setation，一个三岁四岁的小孩就能做到，所以我们对他的这个expectation会更高。

呃我觉得我觉得这件事情可能是一个怎么讲呢，我觉得我觉得既是一个挑战，也是一个机会吧，就是我们一定会对这些多模态的，尤其是vision centric的task会有更高的expectation。

会对他的错误更不能容忍啊，Which means，我这些系统得要有更好的reliability呃和robustness，我觉得他才能够真正能够能够，真正被我们日常生活利用起来吧，好谢谢老师，没有补充。

有补充吗，没什么补充，OK那我们来到下一个问题，就是呃对就是对于现在的很多视觉原任务，包括我们最近两年看到的突破，可以看到是有两条技术线在推进的啊，一条是这个，比如说以GBT为代表的这种。

AUTOGRASSIVE的这种model，然后我们通过预测下一个token呃，去去在语言上面大规模预训练，而另一种像呃diffusion model这条线，包括最近的SARA。

然后呃相当于dominant的两条线的这个发展，然后呃那这个问题就是说这两条路线呃，就是分别的优势是什么，然后哪一条路路径潜力更大，我相信这也是大家很多人呃关注的一个问题。

然后看在座的几位对有什么各自的看法，教会好像你也是最接近的对，对于这个问题来来说，对我我觉得就说首先呢两两种方法，本质上都是把一个比较复杂的问题给拆开来啊，拆成多步。

然后用大量的计算在每一步上面大量的计算，然后你再多步合合起来就是auto gressive mo，有可能比如我们以前有个很有意思的事情，是当我们做这个图像生成的时候。

能发现拆成1000步左右是比较好的一个渠道服，然后我们去看DEFASION的mod，发现他也是1000步在训练的时候啊，所以本质上是啊我觉得很像的做法，但是有一些有一些区别是这样子。

就是当我们比如说应该让更多的精力在，每一个这个方法的时候啊，首先呢就是肯定我还是持有，这个就是说要open money的一些，不能说一条路走到死啊，然后其次呢，就是当我们在真实在评估这两个方法的时候。

我觉得如果说diffusion这样这一类的方法啊，想要成为比如说一个一个universal的一个solution的时候，呃，可能更多的是要去看，比如说他对文字的文字的这个处理，能不能达到像这个啊。

auto regressive model的这种效果啊，那那我们反过来再看，就是说to auto regressive model啊，我们今天有人做，比如说图像生成，有人做这个视频生成啊，相相相对来说。

我觉得离这个diffusion的结果更近一些啊，所以比如说两个方法要啊，就说要防止它压住的时候啊，我觉得这个auto gressive，在我心里会分量会更重一些啊。

然后diffusion就是说不容小觑对吧，不要就是不要这个封封死封死对，好谢谢佳辉沈老师，线上有先生有什么补充吗，呃我我我补充一点，就是说因为你刚才提到免费信做个生成嘛，那我我我我我提供一个。

就是我我从另外一个，从从这个图像的representation learning的角度来来比较，这这这几个方法对吧，其实到现在是没有一个定论的，就是说你呃你如果是把它做成AAR模型。

那那就这个呃戴老师最近的in intervl，你今年那篇CPI的PAPERI，已经做了很多downstream的这种task，就说这个呃，呃放在多模态里面训练出来的这样一个V额。

这个image encoder，他的能力非常这个这个能力非常强对吧，可以去做，可以去做很多detection啊，segmentation等等都能做的不错，那也就是说类似于这这个这个A2。

这样的一个训练方式，可以训练到一个非常好的一个image encoder，Image representation，那那从另外一个角度来讲，因为刚才刚才是森林老师也提到clip是吧，就你clip的话。

那其实他就是在训一个分类器嘛对吧，然后他用的是他他他用的信息其实都是一样的，都是配好的image加上text description对吧，跟李迅呃这个动模态是一样的。

然后defence model其实也是一样的，对不对，defence model你你你训的时候也是用的，用到的监督信号都是配好的，image加text，那么现在呃我们我们我们最近做了。

做了一个简单的实验，就是把这个defi model，就stable AI那个讯预训好的defi model unit拿出来，就作为一个相当于额initialization。

然后去做很多下游的这种segmentation啊，等等这些任务，这个效果也非常好，那么我我想说的是，你看啊这这这几种不同的训练的方式，如果我从呃representation learning。

Image，representation learning的角度来看的话，其实效果都不错，但是呢到目前为止也没有一个，我没有看到一个公平的一个对比，说到底哪一种方式啊，训出来的这样一个encoder。

这样一个representation呃，更更powerful，其实我没有看到嗯，Anyway，回到这个，你原来的问题就到底是哪一种方式更好，我我觉得这取决于你到底想干什么对吧。

如果说如果说是从从考虑这个呃，representation learning的角度来讲的话，呃我我我现在没有一个答案，我没有看到一个答案，到底哪一种方式更好，也许最后结论是差不多的是吧。

在在这个相同的呃呃训练数据，相同的训练信号的这个条件下面，那我我就说这一点好，谢谢沈老师，然后我们下一个问唉，还有补充吗，还说我们呃都行，有时间吗，有时间还有半小时哦，诶哈哈啊，对我弄我。

我可能简单补充一下，我觉我觉得可能这个问题，最后也it doesn't matter，就是我就还是相信the beer lesson，可能最后真正刀妹的东西。

还是说你的computer在那之后可能大家都行，那这里面会有一个inductive bias的问题，就是我个人觉得auto regress model呃，对language来说还是比较自然的。

或者disctized tokens啊，diffusion model对view data也是比较自然，比如它会有cost f，会有这种这种这种啊，这种moi skill的概念在里面啊。

或者说但这两件事情反过来，比如说我非要去assume一个Rest can order，然后去从左到右，从上到下到下的去扫我的一张图，做order aggressive，对我来说似乎不是一个很自然的。

这个这个not advice呃，但again我觉得可能computer上去呃，那不一定不一定会有太大区别啊，但是也许在某些场景下面，这些inductive bias可能会变变得比较关键。

所以我会我会倾向于从这方面考虑考虑吧，谢谢，啊看到我对我其实我很赞同这样的观点，因为呃之前的话，其实大家呃像我之前做的一些工作，比如说在在看这个CN和VIT之间的区别。

到后来其实就zoom out的一点点发现啊，到最后可能呃还是呃就是compute，或者说是data，就是在实际的意义上来看呃更重要，那么在这些呃model architecture啊。

到最后就像是提供了一些啊，下游task in搭载bias，然后呢还有就是在实际意义上的选择，比如说嗯VIT它确实或者说是transformers，它更确实非常容易去model各种各样的data啊。

而不是说就是它，而且它是SCALABLE的architecture，那么这两点加起来，可能是更多人选择选择它的原因呃，我觉得可能整个领域在在过去有一些变化，就是大家zoom out以后。

可能看到的更多的是OK我在同样的数据，同样的computer下面，达到的效果是不是差不多的啊，现在看起来好像是差不多的，但是还是没有完全的定论，可能还是the blesson是吧。

好我们啊下一个问题可能是一个具体一点的，就是我们讨论到呃刚刚视觉语言呃，主要是视觉或者视频这个更多模态的时候，一个呃很难避开的就是这个encoder的问题，就是或者叫COGNIZER也好。

encoder也好，我们怎么把这个呃这个这个模态的数据给它，编码成呃某一种表征送送到后面的模型，然后呃这里包括我刚刚呃报告里面，其实也分享了一点观点，就是现在好像有一个不可能三角。

就我们对图像或视频的token izer，很难兼顾这个compact lossless和离散，就是紧凑无损和离散的这个啊三个方面，可能现在最多有呃有两个方面，然后而这个问题。

可能对于我们未来想要做更统一的动态，可能也是一个核心的呃呃研究的问题，然后也想看呃，在座的包括线上的呃几位老师有什么看法，家辉好像这个也跟你最相关，啊对不可能三角就是说确确实我觉得是不可能。

因为文章说呃好像解决了这个不可能三角，比如说它既是这个离散的，然后呢他又能表达的很好，然后他跑一个，比如说像这种ms coco caption task，那其实当你看这个caption task的时候。

大量的这个当你看这个excel的时候，它其实还是这个文字的style，决定了你这个ELELE的高低，并不是说因为它里面可能就有一只狗对吧，他说一只狗在跑好，那我现在换一个问题问我说这张图片。

比如说这个从左到右，第五个pixel，从上到下第十个pixel，那基本上是没法做的，所以我觉得这个不可能三角是不可能，那更有可能的反而是说针对某一个点，比如说针对lost ace。

我们在什么样的task上，希望它是lost st啊，然后或者说针对于这个DISGRATIZATION啊，我们是不是真的需要DISGRATIZATION，DISCRATIZATION有什么好处啊。

就是我觉得可能从每一个点去就说，或者找一个点去突破啊，反而能打破这个不可能三角啊，比如说我举个例子，能看到一些领域里面的一些工作，比如说这个就不通过这个disk ties，然后来做一些生成。

然后同时他也能把理解做，能做成为他这个带宽还是比较宽嘛，就是那个传过来，或者说这个loss is这一块啊，有可能就是我就放弃这个，我要seek这个pixel value的这个task。

我就是比如说做一些robotics的task啊，有可能能出来一个很好的token anizer，它又是discrete啊，从这个pixel的意义上，它也是loss seed。

但是他能啊lost list完成这个robotics的share task啊，对这我谈我的观点吧，好谢谢教会我完全同意贾辉的观点，我觉得从就是从你冯培教育的角度嗯，你呃如果要你不知道在下游。

task是什么的情况下，呃，这个你是不可能去很难去做业，几乎不可能做压缩，因为我完全可以去构造一个一个task，使得你你被压，被压到的地方是是我要问的一切，是我要问的问题，那那这个你是做不出来的啊。

嗯我觉得到最后而言，就像佳慧说的是找到一个balance在什么task上去，需要一个什么样子的指标，我觉得可能呃lost less是一个如果是我的话，我会是为我一个先会放弃的地方。

是因为没有任何的就是生物体是真的，Lost eless，因为如果劳斯莱斯的话，说明我们要存exactly，这个光子打到我们的视网膜上的每一个刺激，That's impossible，对吧。

嗯而且呃所以这些对呃，执行大多数的task是是没有意义的，哦我就说一句，我觉得这个token izer，the toizer是一个fancy name。

但我觉得我们讨论这些东西其实是originally，我啊south surprise learning，我stand up for，就是一开始大家要做SSL，目的就是为了去学习一个更compact。

更maybe a better alignment，Aligned with the semantics，Um uh，不不用说lost eless，但是比较adaptive，或者说比较flexible。

能够去soft1些task的一些东西，所以我觉得其实至少在我看来，我觉得这一部分之前的SUBSURPRISE，Surprise，sin approach肯定是没有达到我们的预期的，但我觉得之后呃。

这也是一个很好的发展的方向吧，好谢谢老师，大老师或者陈老师有补充吗，说我没有补充好的好的，那我们对跳到下一个下一个问题，就是呃呃对这个这个问题，可能大家自己可以选择回答。

就是我们现在大家经常会讨论这个啊，语言里面skin law，然后那对于呃视觉呃，视频就是包括图像视频或者多么high的里面，他的我们现在已经看到了明显的skin law嘛，然后他如果没有的话。

他可能是呃什么样的，怼大可以要不肖老师，其实我我自己也不知道，我我只能我只能说可能在VN里面，我觉得我个人觉得我们还没有看到skin all。

至少没有看到这种language的g p t moon这种counterpart，呃，然后我觉得呃这里面还有一个重要的问题是，这个benchmark到底是什么的问题，然后我觉得对别人来说呃。

想要看到scaling law，或者我们叫做scaling observation吧，也需要依托于一个比较成熟，比较reliable的一个benchmark。

或者说至少是一个evaluation的protocol，我觉得这一部分我们也得要想一想该怎么办，线上的两位老师有有什么补充吗，嗯我觉得如果拆开来看的话，对于这个生成来说。

spring law还是相对来说比较好做啊，对于理解来说，因为这个理解的任务，很多时候它是跟这个文字连接在一起，导致就是说当你看这个SCENO的时候，就在看这个文字的SCRN动呢。

还是在看这个比较的scrning NO对吧，就是那这个会没有那么清楚啊，当然有一种做法，就是说诶我通过这个刚刚才讲到的对吧，就是说通过生成来做理解，那我觉得这里面可能会出来一些SCT0动。

并且这个SCL0动呢可能跟下游的一些，你所care的任务有一些相关联，这个会是很有意思的研究课题，好谢家辉好，我再补充一点啊，还是再补充一点，就说森乐当还见到过一个我觉得是比较PHILLIAS。

就是说呃当当一些vision的这个研究员，看到这个这个文字的这个模型越来越大对吧，从这个几百兆到一个币，然后淘到100币啊，到一个圈能啊，然后就是也有点心痒痒对吧。

然后也去这个still这个vision encoder啊，上来，比如说一个币，然后五个币，20个币，100个币对吧啊这个我觉得是盲目skill呃，不是一个好的，不是一个好的风气吧，就是嗯好谢谢佳辉对。

我其实想就再补充简单补充一下，就是指盲目scale，因为这个让我想到了，就是因为我自己是aviation爱好者啊，所以如果我我看到，比如说过去这个航空发展的历史的话啊，有一个阶段是从啊啊，比如说更快。

就是从从莱特兄弟以后对吧，这个有现代的呃航空航空学，然后再到一个阶段，就是大家永远都要造大飞机，为了造更大的飞机而造更大的飞机，而造更大的飞机，所以比如说这个747应该是没记错的话。

是是60年代的呃产品产物呃，70年代可能已经开始开始使用了，但是你看现在的话，比如说呃747也好，或者或者呃380也好，其实已经不太产了对吧，反而与此这个取代的是可能没有那么大的飞机。

可能是嗯350或者七呃，呃787这样的更更加呃呃优化的，优化的呃产品，所以我觉得就像盲目scale，到最后他要有一个就是我为什么要去scale，可以做出更更省油，更经济呃，更更先进的飞机。

那么我为什么一定要要用这个就要造的更大，更重更耗油呢，这是这是一个很好很有意思的问题，非常形象的一个对比，我很想说一句，就是有时候也不一定真的是盲目skill。

比如现在你你你们做这个Eva clip的这些model对吧，有时候你要问我，说这个model到比如说180个变量或者怎么样，到底普通的应该怎么，我其实不知道，所以而且我自己也做不了。

所以我看到这些结果之后，虽然可能说没有想呃，像我们想象的那种skin law，对，对我来说还是一个很有价值的一个一个data points，所以或者说只有有一些人做了这些事情。

我们才能够不去盲目skill，我觉得里面还是有些research in inside的好，然后我们下一个问题就刚呃可能也提到的，就是呃数据可能是现在大家都知道最关键的，然后最重要的一个部分。

然后特别是呃，因为语言数据可能相对来说形式简单一点，那当我们想要讨论到呃更多模态的时候，呃，它就是我们现有的数据的数据量以及数据形式，数据质量呃，是不是满足我们未来期待的动态的能力的。

就该包括刚畅想的动能力的这个要求，然后呃未来的形势呃可能是什么样的，然后它可能是来自哪里的，就这里我们可以看到，之前包括呃，图文对这种数据在clip各种呃的成功，那未来呃我们应该期待什么样更新的形式。

呃这里也想看各位老师有什么自己的这个看法，对我如果self serving一点的话，我会继续说，就是real real or data，因为就像我的talk里面提过的，有有几点。

一个是internet data，永远总会有一天会用完啊，这是一个，第二个是internet data和real data，还是有有懂main gap啊，这是这是第二点。

所以呃我觉得all over evidence pleads to，就是大家要更关心的去在rewards，里面如何去去采集数据，或者是利用这样的环境去去学习，嗯对我我说说一下我的观点。

对首首首先第一点呢我完全赞同特特说的，就是我会觉得就是说动模态模型，未来它的最重要的应用场景，还是说是能够主动式的去跟现实世界打交道啊，就说那个呃机器人啊什么，这样就跟现实世界进行主动的环境的交互。

就是说他不只是观察，被动的等着人来喂喂，给他网上数据，说他主动的在环境中间去看，去交互去听，我觉得这个会是创造最大生产力的地方，然后第二点呢，就是我，我觉我会觉得其实这个会引申出来一个问题。

就是说其实就说我觉得现在的学学习的算法啊，就是说他的那个效率什么，可能还需要进一步的提升，尤其你跟现实世界去打交道，这些数据其实都会更加贵，然后更加稀缺那样的啊，然后就说以及你看像小小猫。

小狗或者人类的孩子，其实他并不需要那么多的语言的监督，他就能够学得非常好啊，小猫小狗跟根根本就没有语言的监督，但别人照样会很好的跟环境去打去打交道，对就就就说我觉得呃其实这会引申出一个问题。

就说反正我觉得现在这代学学习算法，其实还有需要非常多的改进的地方，对，呃对呃对我，我可能稍微有点悲观，是我觉得这个数据可能如果尤其是SKAL，数据只能被discover，但没办法真正去CLUCT。

就像我们做power，我完当然完全统一，这个real world的distribution是非常非常重要的，但我觉得有时候一些数据，可能要依托于下一代的某种硬件平台等等。

我们才能够去discover这些数据，我现在看起来一个比较promising的数据，或者说在中间的状态可能还是internet skill的video吧，啊但他主要的问题向导师也说。

这个不是一个interactive environment，但也许我们可以通过像呃用用上general model，用用用现在的各种three d呃，reputation learning的技术。

可以让他somehow能够bridge the gap between like real，and synthetic enrolments啊，然后再去develop新的算法吧，对这是我的一个Hope。

好谢谢谢老师，线上家辉或者沈浩时有有补充吗，我我我我我说一点，就是除了N6P以外，其实现在就是NLP cf super learning非常成功嘛，但是现在在别的模态里面点3D点云也好，图像也好。

视频也好，我我们现在根本就没有看到，就是一个能够啊工作的非常好的一个，self server learning的一个方法对吧，就是现在你东步态还是在就是就用用用用text呃。

就配好的text和图像在在做监督嘛，那如就是如果还是以这种方式的话，没有在self修法learning这一块没有突破的话，那我们去去去收集这个数据，你连收应该收集什么样的数据，你都不知道对吧。

你只是去collect那些在这recorded video也好，image也好，那你这个标注成本会非常高啊，如果还是还是以目前这种学习的方式的话，所以anyway我我想说的是，这里面可能还是有啊。

非常非常多的这个工作需要去做，嗯是的，谢谢沈老师，佳慧呢啊我也是一样的观点啊，就是说啊可能重复一下，就是说一个是呃，我觉得数据量不是问题啊，可能关键在于怎么学，然后学习的算法是什么啊。

比如说能不能有self superfice的企业这些事情啊，本质上这个世界时间只要再往前挪动的话，他这个动态的，动态的数据就会往前往前去增加嗯，但是能不能把这些数据用起来。

然后能不能把它用到自己感兴趣的一，些任务上啊，这个可能是需要更多研究的地方，好的谢谢，当然还还有一点，就是还有一点，就是说就是因为问题里面，还有说这个数据有可能从从哪里来对吧。

今天那个莉莉娅在赶飞机没来，就说我同事就是呃图像生成，我觉得也是一个很好的数据，是有可能可以用起来啊，然后有可能跟新的学新的那个学习的方法啊，如果能有一些共同的突破的话。

会有些会有一些很有意思的东西出来，好谢谢家辉，然后呃我们留几个问题给现场的这个观众，然后看大家呃有想提问的可以举手，然后我们工作人员可以递麦过去，那那那那里，哦我想问一下。

那个森林老师讲的第一篇工作里面呃，就是我记得当时是把呃clip换成了加，加上了一个dino v two，然后当时第一部分在找那个返利的时候，说的是找了两张图片，然后他们的呃cliff的距离非常近。

但是dio v to距离非常远，然后这样来说明说这个cliff可能嗯，visual grounding不够好，那比如说我把那个cliff直接换成dino v two，然后我找一个DINO距离很近。

但是cliff距离很远的，那这样的话会不会他也可以找到一些返利呃，对需要澄清一点，是我们没有在做某种意义上，adversal training或whatever，其实这些这些呃。

embedding space上，discussion都只是帮助human annotator去去帮忙label，所以human alt还是在中间一环，需要去控制这个流程的啊。

所以所以我后来也受了这个results，其实啊我我们可能没有是你说的这件事情，但是至少比如说这件事可以去把dal way to，换成其他的soft spice learning model，呃。

这个conclusion也是成立的对哦，那你有没有试过就是再加入一些其他的feature，就比如说把那个self supervised learning model也多加几个进去，这样会变得更好吗。

呃欢迎关注我们之后可能会release的一个陪伴，我们会讨论一些相关的问题呃，呃short answer是可能没有那么直接，不是越多越好对哦，所以就是这个self supervise跟cliff。

之间还是是有区别的，是的是的是的，谢谢谢谢，好我们可以看下一个问题，这边，嗯老师你好，我想问一下，就是这种视觉模型需要增强它的可解释性吗，就是可解释性对这个视觉重要吗，问问哪一位老师都可以。

看是形容你应该回答一下，你总对吧，你这问题问在座的回答吧，对您回答一下，12时12时有什么，我我觉得不重要，能work就行，不不是不是一定要有科技就行，有有当然好，没有也不妨碍我们去用嘛，是的是的是的。

但是如果是用于呃医疗的话，他可能是需要有很精确，他他是怎么得出这个结论来的，如果把这种影像和和这种文本用在医疗上的话，他是不是需要可解释性，然后怎么样去发展这样的一个模型，我觉得这个也有点绝对。

其实很多就是就是很很早很早以前不是google，google写了一篇paper，然后呃忘了是做哪一次，是skin cancer吗，还是什么，我忘了哦，不是skin cancer，是REINAREINA。

就是那个眼睛的这个这叫什么，Anyway，就就就就好发啊，发了一篇nature science嘛对吧，去去用用这个用这个RINAGAIMAGE，去去训练个风来器去啊，Detect diabetes。

他的他的这个训练集，这个数据集它是每张图片找了七个端，七个这个specialist，七个医生去标的这个啊做的这个标注对吧，完了之后就是嗯majority voting嘛对吧。

那那这个七个里面如果有四个同意，那那就那就用用用这个观点对吧，那我我想说明什么呢，你看这个医生去标七个医生去标这张图片，大部分情况下都标出不同的结果，来这个这个训这个这个训练，训训练好的这个医生。

他他能解释吗，他也不能解释啊，那那你到医院去，不就是在这样的医生在帮你看病吗，你你不也接受这样的结果吗，所以这个还是kiss by kiss吧，我觉得对不对，对对是的，我我我那个行啊，对焦辉嗯。

我斗胆那个提一个呃跟陈老师不一样的观点，我觉得很重要，就是一方面呢是解释性能带来一些新的insights，然后啊其实就keep learning呃，他能到今天我觉得还是非常magical。

就是好像突然一个时间点是为给你这个技术，然后这结束能到今天的这个结果呃，然后在在可解释性上的研究，有可能能带来一些deep learning，对deep learning的理解啊。

然后其他下一下就说下一个突破啊，尤其是就是说，如果你今天是研究这个课题的事情呃，我是非常鼓励你继续研究下去啊，不要说这个改topic啊，我都听，因为有可能就是说继续研究下去。

有可能是下一个这个比如说skin skin law，这个Impact level的研究吧，嗯相信相信自己就是后续可解释性，对我我简单就是echo一下佳慧刚才说的我。

我我理解的INTERPRETABILITY有有好几种，一种是工程上和使用上的INTERPRETABILITY，比如说OK我这个系统在医疗上用了以后，我怎么知道它是通过什么样子的逻辑来来做了，这个预测。

那这是一个实用性上的呃，可解释性，但是另一个可解释性就像佳慧说到的，可解释性是OK我，我能够指导我们以后的研究的方向，能够值得指导我们给我们提供这个deep learning。

这个过程中的insights，我觉得在这样的可解释性的基础上，它会OK那我们假设吧以后知道往哪去scale，用什么样子的数据，那是不是我们就啊，能够更好的把这个领域往前往前推下去啊。

更快的去去把model啊带到下一个level，而不是说我们所有的东西都要试一遍，那所以我觉得在这个角度上的话，我觉得是是必要的，但是如果是在实用性的角度上来说的话，就像大家已经讨论过的。

这个是在有些时候是需要的，有些时候是不需要的，要不我们啊对那边有个男生一直举着，直接说吧，呃我想请问一下各位老师，那个呃随着我们在这种视觉语言模型当中，加入了更多的视觉的训练数据之后。

在纯语言的性呃性能上面，比如说reasoning相关的能力上面，呃我们有看到一些呃比较大的提升吗，呃以及呃在可见的未来当中，大家怎么看这件事情啊，谢谢嗯，这也是一个对很好的问题。

我只我看到g p t four v的tech report的时候，看起来没有特别大的提升，所以我们就要去问一下家辉了，家辉哈哈，研究中不方便透露，看来，我觉得这个问题本质是这样的啊，就是说当一一。

而且跟这之前问的问题有点像，就说我们几个模台是不是要合在一起做啊，那这里面本质上问题是在于，就是说互相之间有没有这种positive transfer，就是你做的这个问题。

能不能transfer到另外一个问题，然后嗯，然后甚至有没有可能就说有negative transfer，Negative transfer，我觉得还是一个可解的问题。

因为positive transfer，这个就说只能说god god bless deep learning吧，就是啊希望是能有一些这个POITI的TRANSER啊，那有些情况下。

我觉得还是很容易能看到一些positive transp，尤其是从比如说语言语言对这个多模态，就说语言上，比如说啊很简单的例子，就是说你的这个语言的输出更加的标准化啊。

会导致在比如说这个当你图文问答的时候，也会更加标准化，就是更加符合你的预期，更加让你读起来通顺，那就是说图片这个事情能不能对，因为你的问题是，图片能不能对这个语言，reasoning带来一定的提高嘛。

呃我觉得这个是有可能的，然后这个是研究中的，好的好的，还得我们可能都得还得研究一下，我能补充一句吧，呃就我觉得还有一个EVOLUE什么benchmark的问题，我一定能找到一些task。

没有vision你的language什么的，Completely fail，我也可以找到更多的task，没有vision呃，压根不许就是这个PERLANGUAGE，Performance。

没有任何的影响，就是所以还是取决于我们，我们到底应该怎么去define这个problem，但我相信比如说如果回到刚才所说的，如果我们care real world这些这些task的时候。

我相信有很多很多的差词，是没有为人是不行的哦，好戴老师或者生老师有补充吗，嗯对就回回到你刚才那个问题的话，就是现在的情况是嗯，至少我们这边观察到的情况是就说是呃，你的问题。

刚才是说是那个对于语言任务来讲对吧，然后图文的这个多模态的训练，是否对纯语言任务有帮助对，然后现在观察下，我们观察现象是没有帮助，甚至可能会有一些坏处，但就说确确实这件事情如刚才各位所说说的。

反正是呃是有各种各样的空间，以及现实中间很多任务，就是说他其实是就说反正越往现实世界走啊，那就视觉这些东西的重要性会越来越多，对所以所以这个是我们的呃，到benchmark的问题。

还是说这一代算法有局限性，很好的追问，不是你不能criticize说本体Mark有问题，那存远任务的本期Mark，别别人就定义的挺挺挺挺好的，对我我觉得还还是就说是现现在的算呃。

现在的算法的问题或也也不一定，你说这一代算法的问题，我觉得可能是也许是一些工工程设，设计上面的问题什么的，对，好然后那我们还最后还有一分钟，要不最后一个问题呃，呃那位那位那位同学举得最高举的嗯，你好。

我有我实际上有两个问题啊，一个一个一个鞋码，一个我问一个问题是这样的，就是呃我有一个疑问是说，因为现在token的话，实际上是呃就是一张图在token呃，就是encoder的时候会token成。

比如说呃一个就是比如说有101024个，那个什么呢，就是token嘛，就是图片token以后，那么的话如果每一张图，如果它的分辨率都是1024，那么的话它token化以后，它是这些token的一个组合。

那么这个组合它代表的意义是什么呢，它是一个呃它是一个排列组合吗，还是到底它有更深层的含义，对就是关于对这些token的理解，对就是它呃虽然都是102，比如说都是1024剖面率，可是它最后的我们就是。

比如那个token的那个密码本，实际上都是1024的，那么它实际上都是这些的组合，我不知道它的那个内部的含义到底是什么，就是说就像一个文章一样，我们的话token完了以后是一些，我不知道他是最后。

我我是把它类比类类比成一个，就是说像是一种token写的一篇文章一样，我不知道是不是这样能理解，这个问题我可以稍微说一下，就说我几年前看过这个hot book里面的这个code，就其它做法也很简单。

就是说你把整个这个英拉斯的token，都要翻译成同一个code，然后你把decode一下，你看看你出来的是什么东西啊，然后我们观看到，基本上还是一些很基础的颜色啊，然后有一些这种啊边边角角啊。

一些pattern啊，所以我可能更倾向于说，在这些排列组合的情况下，加上你的这个decoder，它才能把整个这个视觉的信息给decode出来啊，那回过台就是跟刚才那个问题很像，比如说要不要可解释性。

我的我的我的回答是需要的，就是说我们可能需要有一些可解释性的东西，来看一下这里面到底在干什么啊，是不是人能理解，然后是不是能理解之后能把这个事情做得更好，谢谢好，那，OK没有补充吗。

OK那我们今天正好时间到了，然后今天也很感谢这个大家在这边，这个一起参与我们这个panel，然后也感谢各位线上线下的这个嘉宾，让我们有更多问题可以这个下面再讨论，然后也感谢大家参与今天的这个动态论坛。

然后下午应该这大会还有一些其他论坛，也欢迎大家关注。
# 2024北京智源大会-视觉大模型 - P6：圆桌论坛：视觉重回第一赛道？-主持人：颜水成-嘉宾：鲍 凡-申琛惠-李俊男-程明明 - 智源社区 - BV13x4y1t7sb

今天的话虽然是我们是视觉的大模型，但是我们也有AMP也有多摩钛的浚缆在这个地方，但是在开始之前的话，我们请每一位panelist做一个简单的介绍，比如说不只是局限于你现在做的工作。

比如说你自己的整体来说的兴趣爱好是什么，好吧，好，那么从抱环开始吧，大家好，我是神术科技的抱环，然后目前我主要经历是在关于这种视频大模型上面，然后关于它做一些偏一线的优化吧。

然后在后期其实我也有自己比较感兴趣的方向，比方说这种和3D结合的一些世界模型，然后以及说那种，其实所有做多摩钛人的一个愿景吧，就是那种通用的理解生成，在输入输出端都能做到这种统一化的大模型，好的，申辉。

你拍一下看，你拍一下看是不是开着的，大家好，我是申辰慧，目前在木城科技是OpenSORA这个开源团队中的一员，然后我博士是在新加坡国立大学，然后其实我博士期间做的研究主要是偏向自然语言生成的。

然后我在接触这个视频生成这个时间其实还是比较短，然后非常荣幸今天有机会可以在这边和行业内业界的各位专家，进行交流学习，非常不错，时间那么短，但是效果已经非常不错了，谢谢，好，麦俊男，大家好，我是俊男。

然后我博士也是毕业于新加坡国立大学，然后我博士期间主要从事的就是计算机视觉相关的研究，然后之后我去了这个Salesforce在新加坡成立的一个AI研究院，然后在那里工作了大概5年的时间。

主要最开始还是做一些视觉的这种自监督学习，然后后来就转到了这个多么态这种视觉跟语言的这个领域的研究上面，然后我个人目前的兴趣还是对这个多么态大模型是非常感兴趣的，尤其是像ACGP4V4O的这种模型。

我们怎么能够自己打造出来一个类似的模型，这个是我的一个目标，好，李铭，好，谢谢，我是程明明，我目前在这个南开大学工作，因为可能跟其他的几位有所不同，可能在企业界。

所以我们其实跟刚才那个报告之后的那个问题也一样，其实我们我这个可能更自由散漫一些，就是我们可能会觉得在学术界，我们会比较关注可能业界这些比较好玩的比较有趣的事情，然后我们看了之后，慢工出细活。

我们看了之后，我们希望能够在一些关键的一些点上有一些自己的想法，然后把这些想法去验证出来，然后把它开源出来，然后给大家提供一些炮弹，然后可能我们比较幕后一些，好，谢谢，所以你是清华毕业的，对。

所以今天我们四位panelist的话，应该是两位NUS，两位清华，都是新加坡和这个中国的话，两个最棒的大学，在AI领域里最棒的这个大学了，好吧，好，那么我们直接进入问题，对。

就是今年SORA以及就是说原生多模态大模型，像GPT-4O，还有Google的那个Astro项目的话，他们的这个成功的话，意味着就是说这个视觉的这个成分的话，就变得越来越重要。

那么这些项目的这些成功的话，是否意味着计算机视觉正在取代自己的语言的话，成为AI或者AGI的这个最主流和主导的方向，那么我们方向反过来，先从陈彬彬老师那边开始，好吧，这个取代这个事儿。

我个人一般不太倾向于说什么东西会取代什么东西，就是当然这个视觉里边最近的这样一些进展呢，确实给大家一个非常大的一个鼓舞，可能之前我们可能更多的在，或者过去年或者前年吧。

我们更多的在关注这个自然语言的这些东西，然后确实跟我们传统上的印象可能会，早期我们一般都是自然语言的人看我们，现在变成我们去看他们之后呢，这个心里还有点落差，但是这个，落差还是不服。

这个可能还是有点不服，然后呢我觉得这个SORA出来之后的话呢，这个真是确实给大家很多的这个震撼，然后呢我个人感觉就是自然语言呢，其实从生存的这个角度来讲，自然语言能率先取得突破呢还是有道理的。

是因为自然语言整体来讲的话呢，它的这个信息密度更高一点，它原则上来讲，我个人感觉它应该是训练的过程中可能需求会相对低一些，视频呢我们要真的投降视频，我们要真的婉转到这个自然语言的那个高度。

可能未来对这个计算量呀，对这个复杂度呀等等的这个需求，应该是本质上应该是要比自然语言要大很多的，这次SORAMOS好像用的这个GPU的数量的话好像，没有想象的那么大，包括昨天比如说像快手的话。

发布他们的那个可灵的那个系统的话，感觉就是说跟Train那个GPT4，GPT5的话所需要的资源好像是更少一些的感觉，是的是的是的确实是，当然可能跟那个最早的那个GPT比，当然第一版我是这么理解啊。

就是说很多模型它第一个出来的时候呢，它更多的是展示说我能干这件事情，它干的这个过程呢不一定是最优化的，它甚至可能本质上需要的这个，我刚才说的是本质上需要的这个资源呢，它可能不一定那么大。

但是呢它为了尽快地把这些事情做成，告诉大家这些事情可行，所以呢它消耗了很多的资源，甚至比如说大语言模型，最开始插的GPT用了那么多的卡，其实现在要想浮现一个那样的一个模型，同样能力的模型。

其实最新的方法也不需要那么多的这样一个算力，然后另外一个就是说从这个，我们现在这个视频生成确实很惊艳啊，但是我们也会看到有很多的这个问题，比如说刚才咱们看到那个视频生成里边那个车。

那个车轮其实并不一定跟着那个，车的那个速度在转，其实我们有很多的这样一些，就是我们至少说我们先展示出来有这样的一个能力，当然未来可能真要像我刚才也说的过程中也，特意地提到了说。

婉转到那个自然语言的那样一个灵活性，我觉得本质上它的复杂度还是蛮高的，真的要是，说刚才也有人提到了说这个骨骼呀这些东西的一个提取，我个人感觉它可能我们现在能做到的，可能还是比较泛娱乐化的。

就是这个事好玩有趣，我们大概能做这件事情，真要到说这个骨骼非常精确，精确到能给病人治病，或者说这个轮子也，转的速度也很精确，很多东西能做很深入的一些，很严肃的一些事情的时候。

目前的这样一些可能还有一些差距，所以我个人感觉可能未来我们这个，图像视频这块我们可能，可以拓展或者可以玩的空间可能会，非常的大或者更大一些吧，所以我觉得，还是对我们这个领域还觉得挺好的一个事，好 谢谢。

这个其实是有一个有趣的事情啊，就是说，在NRP领域的话，貌似就是第一个做出来的和第二个做出来的，其实它的资源的消耗差距不是那么大，但是做计算机视觉的话相当于说。

好像一个特点是说第一个做出来的和第二个做出来的话，它们的资源消耗的这个量的话，往往是非常非常的这个巨大的，对，比如说这次的Solar的话，据说它们应该都是Luma。

可能应该是超过就是在1万块到10万块K，不就，就是H100的这个基础上称出来的，对，但是现在明显的话就是包括中国这种复现的话，可能大概就是在大几千块卡的这种量吧，所以就是说其实。

它至少有个几十倍的这种差距，对，所以这个是蛮有意思的一个现象，好，那我们那个郑楠，对，我觉得首先作为这个视觉和多媒体研究者，非常感谢这个自然语言这个领域率先发现了这个Scaling Law。

我觉得NLP能率先发现Scaling Law是有一些它内在的原因，就是首先是它这个我们人类的语料在网上是非常好，相对于视觉来讲是更容易处理的，包括它数据的信息密度，刚刚程教授说，包括它占据的内存。

包括它计算所需的资源来讲，所以从Scaling Law这个角度出发，我个人觉得我们视觉刚刚开始发现这个东西。

可能自然语言它已经到了一个已经开始从Exponential Curve到Sigmoid Curve这样一个阶段，但是从计算机视觉来讲。

Solar刚刚是从生成这个角度证明了大量的这种视频和大量的计算资源是能够带来Scaling Law的这种效果的，但是另外一方面从这种视觉理解的角度来讲。

我们目前还没有看到特别明显的通过大量的数据能够提升，能够得到一个真正的对任何场景都理解的非常好的这样一个视觉模型，目前还是没有出现，所以我觉得从这个角度来讲。

做视觉研究是现在是非常exciting的时候，因为很多东西都是要被探索的，包括Infra怎么样像自然语言这种有非常成熟的Infra的support去并行地处理这种大量的视觉的数据。

把Scaling Law的潜力发挥出来，我觉得从各个方面来讲，视觉现在是刚刚Scaling Law的一个起步的阶段，未来还是有很多空间去继续发展，另外一个维度的话就是。

比如说我们产生出来的内容要让人去消费的话，那么在激活人的多巴胺的这个角度来说的话，明显视觉的话要比纯粹文字的输出要强很多，所以可能从产品娱乐的角度来说的话，其实视觉的话可能会大有可为吧，对，好，春慧。

好，就是我这边的话，其实我觉得如果说取代，你原来是AMP，现在变成了视觉，是的，其实我觉得如果说取代的话，可能现在还是比较言之过早吧，因为其实我之前分享的时候也说，就是我们觉得目前视频生成这一块。

还是处于非常早期的阶段，然后就是说我们在生成过程中，也会遇到各种各样的问题，就比如说即使我生成相当于那种自然场景，其实是比较容易生成的，但是如果我去生成一个人脸，这样子，然后一个是说训练数据的问题。

还有就是说即使生成了，那可能在这个模型，它那个训练欠缺的这个程度上，可能有的时候你会发现，比如说这个人他这个眨眼睛是不是怪怪的，然后也包括就比如说可能之前，大家分享就比如说我们给他针到针的这个变化。

就是因为大家对人脸也是非常的敏感，所以稍微有对这个容错率也是比较低，稍微有一点错误，大家就能非常明显的感觉到，然后另一个角度的话，我觉得就是更多的从实际的应用场景来说，就是我们做这个OpenSORA。

目前是比如说通过这个文字，作为一个媒介来进行控制它这个生成内容，当然我们也可以比如说通过一些图片对它进行控制，那可能因为我自己之前是做这个自然语言的背景，就是我觉得文字的话，因为目前它这个大语言模型。

已经达到一个相对成熟的这个状态了，所以说我们如果是通过文字可以在这个阶段，就是取得更快的对它这个可控制性的提升，然后也是觉得在短期内可以在这个方向看到，比较令人激动的结果吧。

比如说你现在在做视频生成的时候的话，你觉得除了文字的这个控制信号之外，还有其他的一些就比较自然的一些控制信号，有可能引入吗，我觉得这个肯定是有可能可以引入的。

但是就是说我们引入这个东西的成本是怎么样子的，或者是不是本身就是available是吧，然后就是它这个数据我们要去获取它，我们要就是会成本是怎么样子。

然后因为现在文本其实是一个相对于比较廉价的一个数据源头，因为加上我们有很多已经开源的对于图片来生成文字这样子的方法，然后这个的话其实使大家自己的私有数据集。

就可以很快地给它对标上就是那种相对应的文字信息，来更快地让模型去理解这个控制程度，好的好的，那个鲍凡的话他们这些公司比较特别。

就是说他们的导师的话朱军老师是一个非常非常theoretical的一个researcher，所以他从一个pure一个theoretical researcher的话，走到前台去做成这个产品的话。

这确实是让人觉得特别的这个振奋，因为说实在在中国的话就是能专注在这个基础研究的人的话，已经非常非常的少了相当于是，但是要把两者结合起来的话就是少是更少，鲍凡你的观点是什么。

确实就是我也是从做纯理论然后过来的，然后确实感觉到从这个最底层理论然后到这个产业落地之间，它这种这么一条最短路径是怎么样的，所以就也觉得挺有趣的这段经历，然后我也回应一下这个问题吧。

就是我可以大致发表一下我自己感受，就是为什么这个大语言模型就在文本这个模态上，它会比较早地得到这么一些关于skill and role的结论，但是视觉这些模态会比较滞后。

因为我感觉就是机器学习的问题就无非分为三类，第一类就关于数据的表示问题，然后第二类就是关于这数据要有了表示之后要怎么去理解，第三类就是有这些表示要怎么去生成，然后在文本的模态里面它其实这个表示的问题。

已经被很好的解决了，就是用那种比较朴素的tokenizer，就可能说可以把这问题解决80%到90%，那所以它后面做生成做理解，其实都已经没有什么表示上阻碍了，但是在图像上在3D上它不一样。

就它的表示其实也是一个非常本质非常困难的问题，到现在为止这个图像表示其实都没有一个定论，现在我们可以看到就是光图像表示，学术界就有非常多的争论，比方说这个纯pixel space的表示。

然后基于这种场的表示，就是implicit这种neural representation，然后比如说那种VAE压缩那种影空间的表示，然后甚至那种把它压缩成理想化token的表示。

就每一个表示然后它都延伸出来非常多的工作，然后可能这些工作就是在表示没有得到一个定论的前提下，然后你要去再得到后面关于scale and load的定论，它其实就会相对来说研究会比较发散一些。

所以我觉得像这个图像的，它就是可以预期到它会比这个文本要滞后一些，然后关于3D的话那就更加了，因为现在3D几乎所有的工作都集中在它的这个表示上，3D表示就比图像要多更多了，所以我感觉3D的数据也是更少。

是的，然后包括这个数据上的这种知识的密度，其实也很显而易见的，就是这个文本上它这个知识密度更高，你随便找一些文本，它就是有非常有效的知识，但是对于图像来说，目前可能代表知识的这种数据就只有视频。

对于3D好像就，目前我感觉没有看到过什么有知识的数据，所以其实我感觉还是，就是为什么图像它这种，Scale and Row的雏形会比较滞后一些，我觉得本质上还是，它这个数据表示的难度和这个。

数据本身高知识数据的获取上，它天然的会比文本要更难一些，好的，那我们进到第二个问题，现在的话就是说，大家都在讲通用模型嘛，或者说大模型，那么就是说我们肯定很希望得到一个。

计算机视觉的一个Generist，那么我们的问题是说，这个计算机视觉大模型，或者说Generist视觉模型的话它，到底应该怎么样的方式，train出来是比较合适的，是说像比如说像。

单模态的这种视觉的大模型，比如说大家知道的可能，伯克利有一个Large Vision Model，然后也包括那个应该是，SAM的话应该也是算这样的一个模型，所以可能主要是从这个，图像本身出发。

但是另外的话就是，跨模态的话就比如说像Text-to-Video，GPT-4，那么这样的话其实它是一个，就是多模态的话融合在一起，来这个就是去train这样的一个大模型，那么就是说。

一个问题是说如果离开文本的这个，视觉，离开文本去研究视觉大模型，有可能能train出一个所谓的，Generist出来吗，对，那我们这样吧，我们把这个顺序稍微调一下，从俊男开始好吧。

我觉得这里面可能有两个问题，一个是这个监督信号的问题，一个是人跟这个模型交互方式的问题，首先监督信号的问题就是，刚刚范华也说了，我们现在的这种视觉数据，是缺少有效的监督信号的。

当然有很多这种自监督学习的工作，他会比如说预测这个图片的某一部分，应该是什么样的，通过这种Risk Reconstruction Loss，但是这种，去学出来的这种表征，一般都是比较low level。

他可能学到一些这种，呃，不同concept的这样一些，呃，剧类的知识，但是他很难真正的抽象化这个，每一个物体，它的一些属性之类的东西，如果在没有语言帮助的情况下，所以我觉得第一个问题就是说。

我们怎么在没有语言信号的情况下，找到一个非常有效的监督信号，去真正的学出一个比较通用的这种，那像视频这样的next frame prediction，觉得有可能能成立，对。

我觉得这个可能就是一个非常值得探索的一个空间，就是如果他真的能非常好的预测，后面的事情，那他是不是对于这个视觉场景，就有一个很好的理解，呃，我觉得这个是是非常值得探索的，包括伯克利那个论文。

他也用了其他很多监督信号，比如说用一些这种深度图，用一些这种，呃，segmentation，呃，等等去共同监督，呃，这个在语言之外的一些信号，我觉得这个也是非常值得探索的，呃。

但是这个里面还是涉及到可能数据的获取的一个问题，呃，所以这个是监督信号的问题，呃，另外一个问题就是我们怎么跟这个模型交互，呃，因为现在包括GPC4V，呃，这些模型它的交互方式大部分是用这种语言去交互的。

所以我们离开了语言的话，呃，怎么交互呢，当然传统那种检测或者自动驾驶里面，机器人里面它是有一些其他的交互方式，但是我们一个对于人类来讲最通用的交互方式，如果说还是语言的话，呃，那我觉得可能在这方面来讲。

呃，把语言引入这个视觉模型还是比较重要的一个事情，嗯，对，呃，我这边的话也是同意，嗯，俊阳老师刚才讲的就是说我们实际在应用场景下面，如果真的要完全的将语言去进行一个剥离的话。

这个其实也是一个非常难的事情，就相当于嗯，就比如说可能可能视频中确实有非常大量的信息，但是如果完全去除到语言就有点类似于那种，呃，默剧的那种感觉了，其实感觉，嗯，这种可能应用上面也是会受到比较大的限制。

然后呃，因为呃，我在视频这方面其实经验也不是很多，然后呃，如果是从这个自然语言方向看的话，其实我们现在两大模型就是那个训练的两个方法，一个就比如说auto encoding，就是这个呃，自编码模型。

编码肯定是单模态，对，然后还有就是auto regressive，就是自回归模型这两种，嗯，这可能会就是有点像就比如说我们视频训练当中，就是说我基于一个frame，我进行，嗯。

这个后面那个多个帧数进行下一步的生成，或者说我去给这个模型看到我其中一些不同位置的这个模块，mask，然后让它进行这种不同的这个生成，我觉得这些，嗯，都是有可能就是进行推进的方向，但是，嗯。

应该还是需要进一步的探索，然后融合其他的模态来看，怎么样去更好的控制这个效果，好的，好，那宝凡，就是关于这视觉大模型，最终形态问题的话就是，首先这个融合语言的我觉得肯定是一个方案，但是可能。

比方说一个可能就是大家也会想就是，单一视觉就单个模态，是否能够做成那种非常通用的大模型，然后我感觉这个问题可以从这个，一个存在性的方面去考虑，另外一方面是从这个构造性的方面去考虑。

就从存在性的方面考虑的话，我觉得是能够存在这么一个，呃 纯视觉的一个通用大模型，因为比方说，其实这个例子已经被构造出来，就是我们所生活的世界，其实我觉得它就是这么一个纯视觉模态的大模型。

就给定这个世界当前的状态，然后这里面的这个写字文本，都是属于我们所见到的东西的一部分，然后它是可以去predict下一个状态，对就它存在性我觉得是有的，就我们当前的世界，是这么一个视觉大模型。

然后关于这个构造，构造性的问题说，就我们要怎么构造出这么一个视觉大模型，我觉得这个东西，可能是一个比较曲折的过程，就它可能没法通过这种，单纯算法或模型的角度去完成它，我们可以举个例子。

就说NLP的发展它其实，很大一部分是来源于互联网的发展，就互联网的存在，让它能够呈现大量可用的数据，我觉得可能对于视觉来说是类似的，可能它需要有一些新的装置新的设备，然后针对这些装置设备。

它可以比较方便快捷地，构造出这种大量的，有实际信息支持的这种数据，然后可能基于这上面，才能有这种，有这些数据之后才可能在，上面去训练出这种纯视觉的这种技术大模型，我的想法是这样子，就是一个存在性。

我觉得它存在，然后构造怎么构造，可能得要一些曲折的过程，就不仅仅是人工智能本身的努力，对 明白，好 宁贝老师，刚才几位已经论述的比较多，补充一些我的想法，我个人更看好多模态的。

我个人觉得这个事情是这样的，我们需要有一个多模态的大模型，去探索更多的可能，就是说这些不同的模态之间怎么交互呀，它能做到的上限是什么样的，去探索这样一些更多的可能，但另一方面呢在很多实际的应用场景里边。

你不可能说是我们家买一个小摄像头，你都要具备这个多模态大语言模型的能力，这个你可能，压根不需要那么大的能力，那可能会根据，在具体的行业里边我感觉，最终呢可能会有一个特别超级的。

就是有个多模态大模型算是一个超级的人工智能，然后呢 从过这个超级的人工智能的帮助下，然后呢根据不同的应用会产生很多一些小的，垂直领域的或者说，像您提到的单模态的这样一个。

有些情况下它可能是个单模态的这样一个人工智能的模型，那个大模型呢一方面呢能够给这个小模型，让小模型知道说我做得最好可能能做到什么程度，或者说我离那个可能的那个最好能做到什么程度。

但另一方面呢就是从应用的角度来讲，像这个就跟我们人一样，我觉得人就是属于一个，干什么事都干得还不错，然后呢但是你真的说要效率做到极致，你跑步你是跑不过汽车的，然后你像这个鸟飞行也是飞不过飞机的。

就是说这，真把某个方向要做到效率的极致，这个可能最终还是单模态的，一些东西有可能还会在很多领域里边发挥重要作用，但是说我们用多模态，所以单模态可能就是说在做处理某一个任务的时候的话，可能还是会比那个。

Generalist可能更强，更有效率，对，就会效果更好一些，对对对，OK，好 谢谢，那下面我们进入到一个，选择性回答，大家感兴趣就可以回答，就是说，意思就是说在现在这个，算力受限的这种情况下。

比如说现在好多的模型的话，你们都需要，就是需要大量的这个算力资源，才可能把这个模型给train出来，无论是单模态还是多模态的，那么在这种情况下的话，学术界肯定是说算力资源的话，不是那么充足。

肯定没有那么充足，一般一个Lab的话有个几十张卡，就已经算非常非常不错了，而且卡的话还经常可能是，4090啊或者说是，比较低端的一些卡，那么在这种情况下的话，就是要想推动。

但是学术界其实还是有一个非常重要的价值，就是说，它要为这个工业界不断地去培养人才，那么在这种情况下的话，就是说学术界和，工业界的话应该怎么样去分工，特别是在这种情况下，学术界如何去发挥它自己的价值，对。

我觉得要不先从敏敏老师开始吧，好 谢谢，那个，这个问题确实是很多学术界的老师，特别困扰的一个问题吧，一般大家一开会，就是包括李飞飞也在抱怨，就是说，很多人一开会就在抱怨说，哎呀这个我们都没个。

我们连个卡都没有是吧，您刚才说4090其实您高估了，我们很多时候现在还有，2080Ti的和3090的还在跑，我们大量的还其实，我们最主要的可能还是这些卡，所以确实从这个，算力的资源上来讲。

其实跟企业界还是差距还是蛮大的，我个人觉得就是我们高校的话呢，大概可以从两个方面去尝试去，做一些事情，第一个事情呢就是说，我们，反正我个人吧，从来不尝试去做全流程的事情，我觉得太累了，一方面觉得太累了。

另一方面呢就是，确实资源也不够，我们可以去，尝试去做整个排库内里边的一些，我们觉得比较自己感兴趣吧，我也不敢说关键啊，至少说自己感兴趣还挺，蛮有用的一些step，那这个step的话呢，它可能用到的资源。

就明显要比整个系统要小很多，在这个情况下呢，我们去找一个还不错的一个系统，作为我们的baseline，然后呢我们尝试去对某些step，做一些改进，这样的一些工作呢，我个人感觉，不论是对学术界的同行来讲。

还是对工业界来讲，还都是蛮有意义的，然后就是我们不尝试去做整个这个，汽车，我们尝试去做几个螺丝钉，然后呢我们扮演好，我们这个做螺丝钉的这个角色，我觉得也蛮幸福的，就是就是你感兴趣什么。

你做什么还蛮自由的，另一方面呢就是说，当我们有一些这样的一些工作的时候呢，我们希望展现出来这些工作的这些，用处吧或者说可能性吧，我们也在确实会很紧密地，在跟一些企业去合作，然后当我们有一些还不错的。

一些初始的结果之后呢，我们经常会联系一些企业，自己没自己没卡吧，可以借别人的卡用，大概我们是这么处理的，好谢谢，而且的话其实学术界的话，也是开源的这一部分的话，非常重要的这个贡献力量，对。

我们后面统一来好吧，对，好的，那你们三位的话，因为是在工业界，你有没有兴趣分享分享，对我个人的感觉就是，我觉得为什么现在会出现这个问题，是因为对于工业界来讲，大模型是一个非常有潜力的。

商业化的这样一个前景，所以工业界会给特别大的投入，是看中了它的这个商业的潜力，从这个角度来讲，我觉得是不是可以考虑一下，有没有之前的一些科研的这种领域，当它被工业界挖掘出来，有非常大的商业前景的时候。

学术界是怎么处理的，比如说在物理生物，我觉得一定发生过这样的事情，就是比如说像通讯领域，对，就那个应该是在上个世纪的时候的话，非常非常的火爆，工业界马上可以用，后来的话就有很多的学生就去那边，以后的话。

老师的话也去那边，但后来慢慢慢慢的，那个领域的话就变得就是，成绩了相当是，因为就是像这个问题的话，已经解决到一定程度了，其实历史的那个教训来看，其实不是特别的乐观，对，那这个我觉得可能从这个角度。

我会觉得，那学术界能不能考虑，做一些工业界做不到的事情，就是更前沿的一些探索，或者是，就是不是说去直接的竞争，而是说去在自己的这个更擅长的地方，去做一些尝试，比如说。

比如说我觉得从这个Diffusion角度来讲，这个Diffusion的模型就有很多理论上的，可以提升的空间，我觉得就是，那从可能工业界它会选择一个更保险的方案，更被验证过的方案。

那学术界能不能有一些创新性的，当然它可能，不一定用，有这个资源用Scaling Lodge去验证，但是可以通过合作的办法，去做更多的这种创新的探索吧，我觉得，好，说得挺具备，就是。

确实就是我自己也是体会非常深切的，就是说很多时候，就是大家想要做那种大规模的，模型的训练的研究是，受到了这个硬性资源的限制，所以这个限制还不只是说学校，其实就是，就是早期的创业公司也同样的。

就是那种中小型的企业也是会因为，彩利的原因，就是没有办法做这方面的研究，那么，但是我觉得就是现在，我还是比较乐观的一个就是说，我们会有越来越多的开源的模型，就比如说像自然语言处理这个领域LP。

它会就是拉满进行了，拉满1拉满2这些开源，然后后面也，引发了就是一系列Follow up的工作，然后像在，视频方向呢其实我们自己的，这个OpenSource的模型也是用到了大量的，开源模型。

然后在这个基础上，进行推进，然后还有一点就是说，我觉得一些，加速的工作，也是非常有价值的，就包括就是之前，老师这边分享的一些，就是通过这个，只recover它这个被mask掉的那个部分。

这样子的一些方法，然后像我们路程的话用的这个，Colossal AI的这个加速系统呢，也是之前是可以比如说在，把这个VIT的架构只在单卡这个3090上面，进行非常，就是一个性能的这个加速和提升。

然后大家感兴趣的话也可以去看我们这个，官网的这个公开的数据，然后在此之外就是如果说讲到，比较细的就是研究的话呢，就是我自己目前其实我看到，也是有非常多就是那种出色的工作，包括我们用到的。

这个VAE就是说，一开始大家就是说我们先训练一个VAE，然后把它freeze住然后再，从头可能开始训练这个，Definition Transformer 但是就是说。

Pixar Sigma它的发现就是说，虽然就是我这个VAE我在，给它训练以后把它freeze住但是，就是我仍然可以就是非常快捷地，拿它来，就是放到我们这个新的，这个Transformer架构上面。

再让Transformer很快去适应这个freeze住的这个，VAE的这个架构，然后也包括就比如说我们新的，这个版本用到了一个，Rectified Flow Loss，这个就是我们。

它的那个论文就是作者一开始，也没有进行非常大规模的实验，他只是就是发现说他这个把，这个noise再到这个mapping，他这个会跟，比如说我的那个training还有validation loss。

跟我最后这个模型的表现，是有比较强的相关性，然后之后也是被，有更多资源的公司拿去进行验证，然后确实发现了这么一回事，然后我们就把它应用到了这个我们最新的版本中，所以我觉得其实。

学术界的很多科研的这个成果呢，对这个业界就是也是有非常大的贡献的，然后因为现在也是一个早期，大家都是摸着石头过河探索的阶段，所以我觉得更多也是一个相辅相成的一个过程，挺好挺好，其实就是有做数学的人。

因为我经常也跟一些做数学的教授交流，他们认为其实我们做机器学习的话，其实只有三个问题，第一个问题就是说网络结构是什么意思，就是说我有一个idea的function。

我也只能在一个hypothesis space里面去拟合，那么这个hypothesis space的这个，创立的话其实就是minimize这个error，第二个就是说你要得到这个。

得到这个解但是你只能用一些具体的数据，那么这样的话你就必须要定一个loss，那么这个loss怎么定义的话就决定了你，根据这个数据的话，它能够拟合到什么程度，那么第三个就是说。

因为你虽然说在这里面有这么一个好的解，但这个解的话只能从一个任意的解开始，所以它就有一个optimization，所以就是optimization是这样的，其实如果是说回归到这个数学的本源，这三块的话。

我是觉得其实学术界的话还是有很多东西可以做的，对，好 那博凡这边，我可以补充一下，就是对于刚才那个数学界的老师的看法，我觉得他可能想得有点薄，就其实我觉得在这个，人工智能里面可能最重要的是。

如何定义数据的分布，就这个data distribution要怎么定义，因为data distribution这个东西，其实取决于你这个智能它是怎么样的，其实它第二步有两个。

一个是叫data一个叫loss，其实data好像也考虑到了，对 其实在现阶段我反而觉得后面这个loss，就你有了数据分布之后，你要怎么去建模它，要怎么去优化它，这些问题都已经被解决大差不差了。

优化有A跟W，然后loss那自回归loss，然后diffusion loss，这些都发展得非常迅速，那其实感觉反而这个研究最少的是这个，data distribution要怎么定义，所以我觉得就是。

在学界一个非常好的一个topic，就是关于数据的工作，你要怎么去把这个数据分布给它定义出来，其实数据分布，这是一个你觉得是一个工业界的，是一个工程的问题，还是一个理论研究的问题呢，我觉得它可能都有。

对 就是你数据分布，首先就数据分布它是那个，取决于你这个智能的上限对吧，其实程慧的话在那边也讲了，你们其实对于数据这块的话，对整理的话也是非常关键的，其实我，就我觉得不仅仅是数据清洗吧。

数据清洗它这事情本身可能是，会偏一些engineering，但比方说你，比方有一些比较有趣的topic吧，就是你手头上有一堆，比较差的分布，你可以通过一些统计学的方式，比方说这种。

mature sampling或者说那个，importance weight sampling的方式，去提升数据质量，我觉得也是有非常多这种，理论的层面上可以做的，但我觉得其实相比这些更重要的还是说。

我觉得可能无论是工业界和学界，都需要思考问题就是，怎样的数据分布能够带来强大智能，我觉得这个东西就是，所有人都可以思考这个事情，OK great，好，那我们接下来可能用很短的时间，回答一个问题，就是说。

按照今年这个，发展的这个趋势的话，大家预估在这个接下来这一年里面的话，视觉大模型，有可能会有哪一些新的breakthrough可能发生，简单地说一下就可以了，我们从邦凡这边开始吧，对。

对其实我思考问题还是比较习惯性地，从这三个维度加数据去思考，第一个是这个，数据分布怎么构造，第二个是数据要怎么表示，第三个是那个数据的理解，第四个数据的生成，然后，比方说在数据的分布上，其实我觉得这个。

这个东西的话我觉得可能还是会比较，中规中矩的一些更加好的数据清洗方案，或者说一些更加巧妙的数据构造方式会被提出来，然后也会让这个智能提升一定的水平吧，然后在这个数据表示上，其实我最近关注到就大家。

对数据表示热情越来越高了，就之前你可能看到在图像上，就大家就几乎不太去care它的一些压缩工作，但是发现最近就是有好多人开始做这种，这种图像的VAE，思考怎么把这图像的压缩力给它降起来。

我觉得这会是一个，非常大的突破，就因为当你这个图像的表示压到足够，足够稀疏的 足够稠密的时候，那它在后面去做这种生成和理解，所需要的训练开销，所需要的这种复杂度应该都会进一步的降低。

然后从而你可能后面要花，十倍的算力去做生成和理解，现在可能只需要一倍，那就意味着可能这种skilling role，它的这个门槛就变低了，所以我觉得可能从数据的表示的维度上，今年会有一些比较大的进展。

然后从而去推动这个数据理解和生成这样的，所以数据表示，那么如果压缩的足够狠的话，那么就相当于说后面去train的话，它所需要的这个成本就大幅的降低了，对 这肯定是一个重点。

好 那么接下来每个人可能用大概30秒 好吧，我先讲一下就是首先从数据的角度的话，就是说我们有大量的数据，然后可以其实，或者说哪一个领域吧，或者说哪一个问题的领域，可能会产生新的breakthrough。

OK 就是如果只是从这个视觉来看的话，肯定就是说视觉的这个质量，可以会有非常大提升，然后这个长度生成的长度，以及它的稳定性来讲，也是，然后我觉得我们可以期待，视频生成是吧。

这个视频对会生成更多不同的场景，然后从可控制性来讲也是，因为随着这个视频这个标注，它这个也是在不断进步的，然后视频生成的quality，和这个视频生成过程的可控性，会有大幅的这个，会有新的创新出来。

对 我觉得这个是可以期待，短期内是可以得到非常快速的提升，OK great，我觉得这可能是业界非常期望得到的，好 俊男，我提一个叫那个评测吧，因为我觉得现在这个视频，不管理解和生成的评测，都非常欠缺。

有点空白的状态，对 这个就不是breakthrough，而是说从可能没有到有的一个过程，我觉得有一个大家都公认的，这样一个类似于言模型里面这种评测，我觉得是非常必要的，可能有更多的系统出来之后的话。

可能这个评测会更好做一些，因为现在开源的系统还太少，对，好 明明了，我特别看好就是说，现在越来越多的这些，各种各样模态的输入，各种各样的一些多模态，带来的各种各样的可能潜在的可能性吧，我就简单地说这个。

好 谢谢，相当于说，因为有了其他模态的和视觉的结合，有可能会让它的产生内容的过程中的话，就会产生一些新的创新点出来是吧，是的是的，就好像你做那个比如说，就是生成了一个story一样。

diffusion story一样对不对是吧，是的是的 谢谢，好 谢谢各位，好 那么接下来我们大概有，还有四分钟的时间，那么大家的话都是自由提问的时间，以后的话大家最好把问题。

identify到哪一个panelist好吧，好 那一位同学对 后面的，各位老师大家好，我是做AIGC应用的，然后也是视觉，主要是视觉应用，然后想问一下各位老师就是，就是对于视频的这种可控性。

图片或者视频的可控性，就是主要的就是，视频的那个动作的控制相关，目前我们图片生成的，一张图片的这样一个角色啊，这个我觉得都做的还可以，但是你要让它这种动起来的话，这应该是视频你走向更长的一个核心。

所以说我想听听，这个各位老师在这块的一个想法，你指定一位吧，要不集中让陈老师帮我看一下，对 因为他也是那个story那个，然后还有一个点就是，我的问题主要是可控性这块，然后刚刚的这个时长。

我觉得就是动作的控制是比较关键，还有一个就是，就是图片这块的，比如说表情或者是一些手这种细节，我想听一下就是陈老师，其实陈老师那个就是做那个，就是那个，就是photomaker对不对。

其实他也类似于是用，几张图像去control它来生成图像对不对，是的 就是说，所以我其实最开始我一直提一个观点，我觉得现在的这样一些，图像的视频的，特别视频的这样一些生成的这些模型。

我个人感觉它可能最早能够，大规模的被大家可用的应该是在娱乐行，也就是相对来说不是那么严肃，也就是因为，确实是您刚才陈大老师说到的这个问题，它要是做到非常好的高质量的这个可控，理解我们人脑子里边。

所理解的包括像物理公式上物理的规律，包括它的一些其他的一些很精细的一些控制，它确实还是，现在的这样一些，我们靠这个VIT啊，靠这样一些这个特征的表征，其实很难把这样的一些规律给它表征进去。

因此在后续的这个训练过程中，现在大家能做的呢，就是说尽量的搞好多的数据，然后呢希望这个事出现的少一点，也没有一个特别高效的一个手段，能把这些比如说这个轮子转的这个速度，跟这个车的运行速度给它匹配起来。

这个人的动作呢能够跟他的这个骨头，给它对得很好，这些事呢目前来讲还是比较难的，但另一方面呢我们也看到了就是说，可能针对一些具体的问题，比如说刚才我们提到的，杨老师也提到的就是说我们像。

做Photomaker的时候我们，可能那么多的事情不好做，但是呢我们可能抓住其中几个点，比如说像这个人的这个人脸的一些，具有个性化的属性的这些东西，我们想办法给它弄出来。

然后呢去验证说这个事情有没有可能，通过少量的一些数据，其实虽然我们有一个自动的数据组装，但是你看到最终我们实际用到的数据，其实也就十几万张的图像，也不算太大但是呢，可能把人脸的一些关键的属性。

或者至少人特别感觉还是，就是至少说感觉那个，比如说甚至从这个老人到小孩，我们都感觉那个五官眉眼特别相似，就是把这样的一些东西可能，我是感觉可能在未来短期一段时间内，可能大家会在这个领域那个领域。

把各种各样的东西尝试去，更好的做一些表征，然后呢靠这些东西去约束，至于说什么时候能把这些universal的都弄好，这个可能还稍微再长一些时间，好我就回答这样 谢谢，好的 谢谢老师，那这位同学吧，对。

各位老师好，那个我主要想探讨一个问题，就是我们就是统一表征的这个问题，因为我在想说我们对真实世界，就是刚刚包房有提到说我们，真实世界的存在，那我们对真实世界的描述其实，人是怎么沟通。

我们其实通过语言沟通，都不是通过文本沟通的，因为像我的方言，那它可能并没有针对性的文字，所以我就在想这个问题就是说，其实不同的语言是可以描述同一个物品的，例如这个麦克风。

其实有不同的语言都在描述这个麦克风，那包括即使我这个人，在讲这个麦克风，它是普通话，但是我可以很慢地说麦克风，或者很快地说麦克风，但是它还是表示这个物体，所以我就在想说，那是不是这个语言的这个东西。

其实是可以有，比较统一地去这个表征的，因为不论是不同语言，还是说同一种语言的不同人，不同的表达的情绪，它都表征了这么一个物品，它是不变的，像哪一位同学，我可能巨难，对，我觉得这个可能第一个涉及到一个。

这个多语言的语言模型的问题，我觉得目前的一个，学术界可能，也涉及到语音的问题了，对 也涉及到语音的问题，我觉得之前大家会觉得不同语言之间，不同语种之间，是有一个这种distribution的。

这种分布的差异的，但是可能在大模型的这个时代，如果我们就是在我们用GPT的过程中，比如说你会发现它其实对于，不同语言的理解，是可以非常自如地切换的，那这个我就有理由猜测，它其实内部的表征。

是得到了某种程度的统一的，包括语音上面，如果说它真的做出一个，end to end这样一个系统的话，那它这个内部的机制，我觉得也是会慢慢地学到，某种统一的表征的，所以我觉得。

当模型这个skilling-out，越来越成熟的情况下，它确实是会呈现这样一种趋势，好的，针对这个问题，我想再稍微补充一下，就是这个因为涉及到多语言模型，然后其实目前也是有非常多的研究。

就是在做这方面的工作，我觉得，我其实也不是说想回，就是可能大概地提一下，现在遇到的几个难点，就是说比较重大的一个难点，就是说有一些小语种，或者我们把它叫做low resource，对这方面的训练语聊。

它其实是非常的缺乏的，然后可能即使像ChargePT这样的模型，它也是没有办法把它做得很好，然后这其中就比如说，您刚才这个提问说，不同语言都可以描述同一个物体，但其实有的时候这些也是。

语言也是受到这个文化的很大影响，就可能有些文化当中，就没有一个概念，所以这个可能也是一个难度，就是怎么样把它合适地，就是用这个语言去给它统一出来，那么我们现在其实主要就是说用，大量的数据去训练。

然后但是就是可能，也是要看就是未来这个，就是现在我们可能比较大的这个语言，就比如说中文 英文 法语 德语，这些我们有大量的语料，那它可能能力已经非常的不错了。

但其实在其他的low resource language，依然就是一个问题，有可能将来的话这个，translation可能是一个，造数据的话有可能是一种途径去解决这个问题。

因为translation做得还像模像样的话，可能是一个就是，把一个语言的数据的话，transfer到另外一个语言上的一个数据，因为我其实之前也做过一些就是，多语言模型的训练，然后其实我们设计到的。

也是有通过这个，老师您说的这个translation的方法，然后再进行一些数据的清理，然后这个方法其实确实可以提升这个大模型，在这个小语种这个上面的能力，好 那我们最后一个问题，时间不够了 好不好。

我们把机会给另外一个同学，我们最后一个问题 好不好，好 对 好，你好 我问一下就是问一下鲍老师吧，就是我们现在也做一些那个，就是那种图像编辑的一些工作，就是我们用的是Nerf。

我看你们用的是就是生成模型，我想问一下这两种路线，就是它未来的发展会怎么样，就是会哪个比较有潜质，3D的为主是吧，对对 都是3D的，Nerf也是3D 3D重建嘛，我觉得就它们会对应这些不同的交互方式。

比方说3D的你比较自然，你可能是有一个表示界面，然后你可以去比较轻松拖拉拽，或者说扭一扭这个表示，然后有点像那种捏橡皮泥的感觉对吧，你可以把这个表示通过一些方式去，手动搓成另外一个状态。

然后通过生成的话，它就是会有一些对应不同的交互方式，就它自由度可能更大一些，比方说你可以通过这种对话式的，就你提供一些素材，用户提供一些素材，然后它这个系统自动办去，根据用户的需求去做一些合成。

或者说是你可以对一张图像，在一个编辑框里面对它图一图抹一抹，然后它系统帮你自动的做一些增删改，其实我觉得本质上可能还是，回归到产品，会对应着这种交互方式的一些区别，好的 也就是说。

这个3D高深Spriting的话，它可能在这种控制性的维度的话，就是更加的这个，understandable 解释相当于是，好 那我们今天上午就到这，让我们再次用热烈的掌声。

感谢我们四位的panelist，非常精彩的分享，好 那么现在应该，下面就是午餐的时间了，好 大家enjoy your lunch，由 Amara。org 社群提供的字幕。


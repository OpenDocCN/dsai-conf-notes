# 2024北京智源大会-视觉大模型 - P6：圆桌论坛：视觉重回第一赛道？-主持人：颜水成-嘉宾：鲍 凡-申琛惠-李俊男-程明明 - 智源社区 - BV13x4y1t7sb

今天的话虽然是我们是这个视觉的，这个呃大模型，但是我们也有这个AMP，也有多模态的那个俊男在这个地方啊，但是在开始之前的话，我们请每一位这个panelist的话，做一个简短的介绍。

比如说呃不只是局限于你现在做的工作，比如说你自己的呃整体来说的兴趣爱好是什么，好吧好，那么从这个爆款开始吧，呃喂大家好，我是神树科技的爆凡，然后呃目前我主要精力是在关于这种视频，大模型上面对。

然后关于他做一些，其实做一些偏一线的一些优化吧，呃，然后在后期其实我也有自己比较感兴趣的方向，比方说这种呃和3D结合的一些世界模型，然后以及说那种呃，其实所有做多模态人的一个愿景吧。

就是那种通用的呃理解生成，在输入输出端都能做到这种统一化的大模型嗯，好的嗯，生辉嗯，诶你拍一下看你拍一下，看是不是开着的，嗯OK大家好啊，我是申真慧，呃，目前在路程科技嗯。

是open sora这个开源团队中的一员，然后呃我博士是在嗯新加坡国立大学，然后其实我博士期间的嗯，做的研究主要是偏向自然语言生成的，然后呃我在接触这个视频生成，这个时间其实还是比较短，然后非常荣幸。

今天有机会可以在这边和行业内，业界的各位专家嗯进行交流学习，非常不错，时间那么短，但是效果已经非常不错了，请好李俊男，大家好，我是俊男，然后我博士也是毕业于新加坡国立大学，然后我博士期间主要呃。

从事的就是计算机视觉相关的研究呃，然后之后我去了这个sales force，在新加坡成立了一个AI研究院呃，然后在那里工作了大概5年的时间，主要最开始还是做一些视觉的这种自监督学习。

然后后来就转到了这个多模态，这种视觉跟语言呃的这个领域的研究上面，然后我个人目前的兴趣，还是对这个多模态大模型是非常感兴趣的，尤其是像类似于GP4V四O的这种模型。

我们怎么能够呃自己打造出来一个类似的模型，这个是我的一个目标，好李宁好，谢谢嗯我我叫呃，我是这程，明明我目前在这个南开大学工作，因为可能跟其他的几位有所不同，可能在企业界呃，所以我们其实呃。

其实跟刚才那个那个报告之后的，那个问题也一样啊，其实我们我这个可能更自由散漫一些啊，就是呃我们可能会呃觉得在学术界，我们会比较关注可能业界这些比较好玩的，比较有趣的事情，然后看完之后慢工出细活。

哎我们看了之后呢，我们希望能够在一些呃关键的一些点上，有一些自己的想法，然后把这些想法去验证出来，然后把它开源出来，然后给给这个给大家提供一些炮弹，然后呢可能我们比较幕后一些吧，好谢谢嗯。

所以我们呃你是清华毕业，对不对，清华，所以所以今天我们思维PALLIST的话，应该是两位NUS，两位清华都是新加坡和这个中国的话，两个最最最棒的大学，在在AI领域的最棒的这个大学了，好吧好。

那么我们进入直接进入问题对嗯，就是今年sorrow以及就是说原生多模态大模型，像g p d four o啊，还有google的那个extra项目的话，他们的这个成功的话。

意味着就是说这个视觉的这个成分的话，就变得越来越重要，那么这些项目的这些成功的话，是否意味着计算机视觉正在取代自然语言的话，成为AI或者，AGII的这个最主流和主导的方向，那么我们方向反过来。

先从陈明明老师那边开始好吧，呃那个呃这个取代这个事，我呃，反正我我我个人一般不太倾向于说，什么东西会取代什么东西啊，就是呃当然这个嗯，呃视觉里边最近的这样一些进展呢，确实给大家一个非常大的一个鼓舞，呃。

去呃，一可能之前我们可能呃更多的在或者过去，过去年或者前年吧，我们更多的在关注这个自然语言的这些东西，然后确实呃比跟我们传统上的印象，可能会早期我们一般都是自然语言的人。

看我们现在变成我们去看他们之后呢，呃这个心里还有点落差啊，但是这个落差还是不服呃，这个哈哈哈哈可能还是有点不服，然后呢我觉得这个呃SORA出来之后的话呢，呃这个哎真是确实给大家很多的这个震撼。

然后呢呃我个人感觉就是呃自然语言呢，其实呃就是从成生成的这个角度来讲，自然语言能率先取得突破呢，还是有道理的，是因为呃自然语言整体来讲的话呢，它的这个信息密度更高一点，它原则上来讲。

我个人感觉他应该是训练的过程中，可能需求会相对低一些，视频呢我们要针对图像视频，我们要真的婉转到这个自然语言的那个高度呃，可能未来对这个计算量呀，对这个复杂度呀等等的这个需求，应该是。

本质上应该是要比自自然语言要大很多的，从这这次说了，貌似好像用的这个GPU的数量的话，好像没有想象的那么大，包括昨天比如说像快手的话，发布他们的那个可灵的那个系统的话。

感觉就是说跟train那个g p t for这样做，会g b d five的话，所需要的资源好像是更少一些的感觉，有哎是的是的是的确实是呃，当然可能跟那个最早的那个GPT比。

这当然第一版的我我我我是这么理解啊，就是说很多模型呃，他第一个出来的时候呢，他更多的是展示说我能干这件事情，他干的这个过程呢不一定是最优化的呃，他甚至可能本质上需要的这个我我刚才说的是。

本质上需要的这个资源呢，它可能不一定那么大，但是呢他为了尽尽快的把这些事情做成，告诉大家，这事情可行，所以呢它消耗了很多的资源，甚至比如说大语言模型，最最开始差GGPX的GPT用了那么多的卡。

其实现在要想复现一个那样的一个模型，同样能力的模型，其实最最新的方法，也不需要那么多的这样一个算力，然后另外一个就是说从这个呃，我们现在这个视频生成确确实是很惊艳啊，但是我们也会看到有很多的这个问题。

比如刚才咱们看到那个视频生成里边那个车，那个车轮，其实并不一定跟着那个车的那个速度在转，嗯其实我们有很多的这样一些呃，就是我们至少说我们先展示出来，有这样的一个能力呃。

当然未未来可能真要像我刚才也也说的过程中，也特意的提到了，说婉转到那个自然语言的那样一个灵活性，呃，我觉得本质上它的复杂度还是蛮高的，嗯真的要是说刚才提也有人提到了，说这个骨骼呀这些东西的一个提取，呃。

我个人感觉他可能我们现在能做到的，可能还是比较泛娱乐化的，就是这个事好玩有趣，我们大概能做这件事情，可真要到说这个骨骼非常精确，或者说这个轮子也也速度转，转的速度也很精确，很多东西能做很深入的一些。

很严肃的一些事情的时候呃，目前的这样的一些可能还有一些差距呃，所以我个人感觉，可能未来我们这个呃图像视频这块，我们可能可以拓展或者可以玩的空间，可能会非常的大或者更大一些吧。

所以我觉得还是对我们这个领域，还觉得挺好的一个事，好谢谢，那这个其实是有一个有趣的一个事情啊，就是说在NIP领域的话，貌似就是第一个做出来的和第二个做出来的，它其实它的资源的消耗差距不是那么大。

但是做计算机视觉的话，相当于说好像一个特点是说，第一个做出来的和第二个做出来的话，他们的资源消耗的这个量的话，往往是非常非常的这个巨大的对，比如说这次的whole or a solar的话。

据说他们应该都是LMA，可能应该是超过就是在1万块到10万块K啊，不就是H100的这个这个基础上衬出来的对，但是现在明显的话就是包括中国这种复线的话，可能大概就是在大几千块卡这种这种level。

所以就是说其实它至少有个几十倍的这种，差距对，就是这个这个是蛮有蛮有意思的一个现象，好那我那个俊男嗯，对我觉得首先作为这个视觉和多模态研究者，是非常感谢这个自然语言这个领域。

率先发现了这个skin law，呃，我觉得NLP能率先发现scale now，是有一些它内在的原因，就是首先是它这个我们人类的语语料，在网上是非常好，呃，相对于视视觉来讲是更容易处理的。

呃包括它数据的信息密度，刚刚呃程教授说，包括它占占据的内存啊，包括它计算所需的资源来讲，呃所以从skin law这个角度出发，呃，我个人觉得我们视觉刚刚开始发现这个东西。

可能自然语言它已经呃到了一个已经开始呃，从exponential curve到signal id curve这样一个阶段呃，但是从计算机视觉来讲，SA刚刚是从生成这个角度呃，证明了呃。

大量的这种视频和大量的计算资源，是能够带来这个skin law的这种效果的，呃，但是另外一方面从这种视觉理解的角度来讲，呃，我们目前还没有看到特别明显的，通过大量的数据能够提升一个，能够得到一个真正的。

对任何场景都理解的非常好的，这样一个视觉模型，呃，目前还是没有出现，所以我觉得从这个角度来讲，呃，因为呃很多东西都是要被探索的，包括INFA呃。

怎么样像自然语言这种有非常成熟的infred support，去呃并行的呃，处理这种大量的视觉的数据，把这个skin law的潜力发挥出来，呃我觉得从各个方面来讲呃。

视觉现在是刚刚skating out的一个起步的阶段，呃，未来还是有很多空间去继续发展，其实另外一个维度的话，就是就是比如说我们产生出来的内容，然后让这个人去消费的话。

那么在激活人的多巴胺的这个角度来说的话，明显视觉的话要比这个纯粹文字的，这个输出的话要要强很多，所以可以可能从产品啊，去娱乐的角度来说的话，确实视觉的话可能会会大有可为吧，对好陈慧嗯好，就是我这边的话。

其实我觉得如果说你原来是LP，现在就变成了视觉，是的是的，其实我觉得如果说取代的话，可能现在还是比较言之过早吧，因为其实我之前分享的时候也说，就是我们觉得目前视频生成这一块，还是处于非常早期的阶段。

然后就是说我们在生成过程中，也会遇到过那种各种各样的问题，就比如说即使我生成嗯相当于那种自然场景，其实是比较容易生成的，但是如果我去生成一个人脸样子，然后嗯一个是说训练数据的问题。

还有个说是说即使生成了，那可能在这个嗯模型，他那个训练欠缺的这个程度上，可能有的时候你会发现，比如说这个人他这个眨眼睛是不是怪怪的，然后也包括就比如说可能之前嗯大家分享。

就比如说我们给他真到真的这个变化，就是因为大家对人脸也是非常的敏感，所以稍微有一些对这个容错率也是比较低，稍微有一点错误，大家就能非常明显的感觉到，然后嗯然后另一个角度的话。

我觉得就是更多的从实际的应用场景来说嗯，来说就是我们做这个open sora呢，目前是比如说通过这个文字作为一个媒介，来进行控制它这个生成内容，当然我们也可以，比如说通过一些图片对他进行控制。

那可能因为我自己之前是做这个，自然语言的背景，就是我觉得文字的话，因为目前它这个大语言模型已经达到一个，嗯相对成熟的这个状态了，所以说我们如果是通过文字呢，可以嗯在这一个这个阶段就是取得更快的。

对他这个可控制性的提升，然后也是嗯觉得在嗯短期内，可以在这个方向看到嗯比较令人激动的结果吧，比如说你现在在做视频生成的时候的话，你觉得除了文字的这个控制信号之外，还有其他的一些就比较自燃的一些控制信号。

有可能引入吗，我觉得这个肯定是有可能可以引入的，但是就是说我们引入这个东西，的成本是怎么样子的，然后是不是本身就是available是吧，然后就是它这个数据我们要去获取它。

我们要嗯又就是会成本是怎么样子，然后因为现在文本其实是一个，相对于比较廉价的一个数据源头，因为加上我们有很多嗯已经开源的，对于图片来生成文字这样子的方法，然后这个的话其实使大家自己的私有数据集。

就可以很快的给他对标上，就是那种相对应的文字信息，来更快的让模型去理解这个控制程度，好的好的，那个鲍华的话，就他们这公司比较特别，就是说他们的导师的话。

朱军老师是一个非常非常theoretical的一个researcher对，所以他从一个pure一个theoretical researcher的话，走到前台去做成这个产品的话。

这确确实实让人觉得特别的这个振奋对，因为说实话在中国的话，就是能专注在这个基础研究的人的话，已经非常非常的少了，相当于是但是要能把两者结合起来的话，就是就是少之更少，对那包含你的观点是什么。

对确实就是嗯我也是从那个做纯利润，然后过来的，然后确实感觉到从这个最底层的理论，然后到这个产业落地之间，他这种这么一条最短路径是什么样的，对，所以就呃也觉得挺有趣的，这段经历。

然后我也我也说回应一下这个问题吧，呃就是我可以呃大致发表一下我自己感受，就是为什么这个大语言模型，就在文本这个模态上，它会呃比较早的得到这么一些，关于screen roll结论。

但是视觉这些模台会比较滞后呃，因为我感觉就是机器学习的问题，就无非分为三类，第一类就是关于数据的表示问题，然后第二类就是关于这数据要有了表示之后，要怎么去理解，第三类就是有这表示要怎么去生成。

然后在文本的模态里面，它其实这个表示的问题呃已经被很好地解决了，就是用那种比较朴素的token anizer，就可可能说可以把这问题解决，80%到90，那所以他后面做呃深沉做理解。

其实呃都已经没有什么表示上阻碍了，但是在图像上，在3D上它不一样，就他的表示其实也是一个非常本质，非常困难问题，呃到现在为止，这个图像表示其实都没有一个定论，现在我们一看可以看到就是光图像表示呃。

学术界就非常多争论，比方说这个纯pixel space的表示，然后基于这种场的表示，就是呃implicit这种neural representation，然后以及说那种呃VAE压缩那种隐空间表示。

然后甚至那种呃把它压缩成离离散化，token的表示呃，就每一个表示，然后他都会他都延伸出来非常多的工作呃，然后可能这些工作就是在表示，没有得到一个定论的前提下。

然后呃你要去再得到后面关于skilling low的定论，它其实就会相对来说，这个研究会比较发散一些对，所以我觉得像这个图像的呃，它就是可以预期到它会比这个文本要滞后一些，然后关于3D的话，那就更加了。

因为现在3D几乎所有的工作，都集中在他的这个表示上，3D表示就比图像要多更多了，所以我感觉3D的数据也是更少啊，是的是的对，然后包括这个数据上的这种知识的密度，其实呃也很显而易见的。

就是这个文本上它这个知识密度更高，你随便找一些文本，那它就是有非常有效知识，但是对于图像来说呃，目前可能代表知识的这种数据，就一只有视频，但对于3D好像，就目前我感觉没有看到过什么有知识的数据。

所以其实我感觉还是就是，为什么图像，它这种score road的出现会比较滞后一些，我觉得本质上还是他这个数据表示的难度，和这个数据本身高额高知识数据的获取上，它天然的会比文本要更难一些，好的啊。

那我们进入到第二个问题嗯，就现在的话就是说大家都在讲通用模型嘛，或者说大模型，那么就是说我们肯定很希望得到一个，计算机视觉的一个generalist，那么我们的问题是说这个计算机视觉大模型。

或者说generous的视觉模型的话，它到底应该怎么样的方式衬出来是比较合适的，是说像比如说像呃单模态的这种视觉的大模型，比如说大家知道了，可能伯克利有一个large vision model。

对不对是吧，然后呃也包括那个应该是SAM的话，应该也是算这样的一个模型，就纯粹可能主要是从这个图像本身出发，但是另外的话就是跨模态的话，就比如说像text video g b t four o。

那么这样的话其实它是一个就是多模态的话，融合在一起来，这个来来这个就是去train这样的一个大模型，对，那么就是说一个问题说，如果离开文本的这个视觉，而离开文本去研究视觉大模型。

有可能能串出一个所谓的generalist出来吗，对那我们这样吧，我们把这个顺序稍微调一下，从俊男开始好吧，呃我觉得这里面可能有两个问题，一个是这个监督信号的问题，一个是人跟这个模型交互方式的问题。

呃首先监督信号的问题就是呃刚刚爆凡也说了，我们现在的这种视觉数据，是缺少有效的监督信号的，当然有很多这种自监督学习的工作呃，它会比如说预测这个图片的某一部分，应该是是什么样的。

通过这种risk reconstruction loss，但是这种去学出来的这种表征，一般都是比较low level，他可能学到一些这种呃不同concept的这样一些呃，聚类的知识。

但是它很难真正的抽象化这个每一个物体，它的一些属性之类的东西，如果在没有语言帮帮助的情况下呃，所以我觉得第一个问题就是说，我们怎么在没有语言信号的情况下，找到一个非常有效的监督信号呃。

去真正的学出一个比较通用的这种视觉视频，这样的next frame prediction，觉得有可能能成为一种对，我觉得这个可能就是一个，非常值得探索的一个空间，就是如果他真的能非常好的预测后面的事情。

那他是不是对于这个视觉场景，就有一个很好的理解呃，我觉得这个是是非常值得探索的，包括伯克利那个论文，他也用了其他很多监督信号，比如说用一些这种深度图。

用一些这种呃segmentation呃等等去共同监督呃，这个在语言之外的一些信号，我觉得这个也是非常值得探索的，呃，但是这个里面还是涉及到可能数据的获取的一，个问题呃，所以这个是监督信号的问题呃。

另外一个问题就是我们怎么跟这个模型交互呃，因为现在包括GPT4V呃，这些模型，它的交互方式大部分是用这种语言去交互的，所以我们离开了语言的话呃，怎么交互呢，当当然传统的那种检测或者自动驾驶里面。

机器人里面它是有一些其它的交互方式，但是我们一个对于人类来讲，最通用的交互方式啊，如果说还是语言的话，呃那我觉得可能在这方面来讲呃，把语言引入这个视觉模型，还是比较重要的一个事情，对。

嗯我这边的话也是同意嗯，俊楠老师刚才讲的，就是说我们实际在应用场景下面，如果真的要完全的将语言去进行一个剥离的话，这个其实也是一个非常难的事情，就相当于嗯，就比如说，可能可能视频中确实有非常大量的信息。

但是如果完全去除到语言，就有点类似于那种嗯演默剧的那种感觉了，其实感觉嗯，这种可能应用上面也是会受到比较大的限制，然后嗯因为嗯我在视频这方面，其实经验也不是很多，然后嗯如果是从这个自然语言方向看的话。

其实我们现在两大模型，就是那个训练的两个方法，一个就比如说auto encoding，就是这个嗯自编码模型，编码肯定是单模态对，然后还有就是auto regressive，就是自回归模型这两种嗯。

这可能会就是有点像，就比如说我们视频训练当中，就是说我基于一个frame，我进行嗯，这个后面那个多个帧数进行下一步的生成，或者说我去给这个模型，看到我其中一些不同位置的这个模块mask。

然后让它进行这种不同的这个生成，我觉得这些嗯都是有可能就是进行推进的方向，但是嗯应该还是需要进一步的探索，然后融合其他的模态来看，怎么样去更好的控制这个效果，好的好，那抱凡就是关于这视觉大模型。

最终形态问题的话，就是首先这个融合语言的，我觉得肯定是一个方案，但是可能呃比方说一个可能就是大家也会想，就是单一视觉，就单个模态是否能够做成那种，非常通用的大模型，然后我感觉这个问题。

可以从这个一个存在性的方面去考虑，然后另外一方面是从这个构造性的方面去考虑，就从存在性的方面考虑的话，我觉得是能够存在这么一个呃，纯视觉的一个通用大模型，因为比方说啊其实这个例子已经被构造出来了。

就是我们所生活的世界呃，其实我觉得他就是这么一个，纯视觉模态的大模型，就给定这世界当前的状态啊，然后这里面的这个写字文本啊，都是属于就是我们所见到东西的一部分，然后他是可以去predict下个状态对。

就它存在性我觉得是有的，就这个我们当前的世界是这么一个视觉大模型，然后关于这个构造呃，构造性的问，你说就我们要怎么构造出这么一个视觉大模型，我觉得这个东西可能是一个比较曲折的过程。

就他可能没法通过这种单纯算法或模型的角度，去完成它，我们可以举个例子，就说NOP的发展，它其实很大是来源于互联网的发展，就互联网的存在让它变了大量可用的数据，我觉得可能对于视觉来说类似。

可能他需要有一些新的装置，新的设备，然后针对这些装置设备，它可以啊比较方便快捷的构造出这种大量的呃，有实际信息支持这种数据，然后可能基于这上面才能有这种呃，有这些数据之后，才可能在上面去训练出这种。

纯视觉的这种基础大模型，我的想法是这样子，就是一个存在性，我觉得它存在，然后构造怎么构造，可能得要一些曲折的过程，就不仅仅是人工智能本身的努力来明白，好敏敏老师啊，那个呃我刚才几位已经论述的比较多啊。

就是补充一些我的一个想法呃，我个人呢更看好像多模态的，就是就我个人觉得这个事情是这样的，就说我们需要有一个多模态的，这样一个大模型呃，去探索所有的去探索，更多的可能，就说这些不同的模态之间怎么交互呀。

它能够他的他能做到的上限是什么样的，去探索这样一些更多的可能，但另一方面呢，在很多实际的应用场景里边嗯，你不可不可能说是我们家买一个小摄像头，你都要具备这个大多模态，大语言模型的这个能力。

嗯这个你可能可能就压根不需要那么大的能力，那可能会根据在具体的行业里边，我感觉最终呢可能会有一个特别超级的，就是有个有个多模态大模型，算是一个超级的人工智能，然后呢通过这个超级的人工智能的帮助下。

然后呢根据不同的应用，会产生很多一些小的垂直领域的，或者说demo，像您提到的单模态的这样一个，有些情况下它可能是个单模态的，这样一个人工智能的模型，那个大模型呢一方面呢能够给这个小模型。

让小萌新知道说，我做的最好可能能做到什么程度，或者说我离那个可能的那个，最好能做到什么程度，但另一方面呢就是说从应用的角度来讲呢，呃嗯像这个就就跟我们人一样，我觉得人就是属于一个什么呃。

干什么事都干得还不错，然后呢但是你真的说要效率做到极致嗯，你跑步你是跑不过汽车的，然后你像这个鸟飞行也是飞不过飞机的，就说这真把某个方向要做到效率的极致，这个可能最终还是单模态的一些东西。

有可能还会在很多领域里边发挥重要作用，呃，但是说我们所单模态，可能就是说在做处理某一个任务的时候的话，可能还是会比那个generalist可能更强，更有效率，更就会效果更好一些是吧，OK嗯好谢谢。

那下面我们进入到一个选择性回答，大家感兴趣就可以回答，就是说嗯，意思就是说在现在这个算力受限的这种情况下，比如说现在好多的模型的话，你们都需要就是需要就是大量的这个算力资源。

才可能把这个模型给REN出来，无论是单模态还是多模态的，那么在这种情况下的话，学术界肯定是说算力资源的话不是那么充足，肯定没有那么冲突，一般一个lab的话，有个几十张卡就已经算非常非常不错了。

而且卡的话还经常可能是4090啊，或者说是比较比较低端的一些卡，那么在这种情况下的话，就是要想推动，但是但是学其实还去，还还是有一个非常重要的一个价值，就是说他要为这个工业界不断的去培养人才。

那么在这种情况下的话，就是说学术界和工业界的话应该怎么样是分工，特特别是在这种情况下，学术界如何去发挥它自己的价值，对我们呃我觉得要不先从敏敏老师开始吧，好谢谢那个呃，这个问题确实是很多学术界的老师。

特别困扰的一个问题吧，一般大家一开会就是包括李菲菲也在抱怨，就是说很多人一开会就在抱怨，说哎呀这个我们都没个，我连我们连个卡都没有是吧，那您刚才说4090，其实您高估了我们很多时候。

现在还有2080ti和3090的还在跑，那我们大量的还，其实我们最主要的可能还是这些这些卡呃，所以确实从这个呃算力资源上，其实跟企业界还是差距还是蛮大的，呃我个人觉得就是我们高校的话呢。

呃大概可以从两个方面去尝试，去去去去做一些事情，第一个事情呢就是说呃，我们我反正我个人吧，从来不尝试去做全流程的事情，我觉得太累了，一方面觉得太累了，另一方面呢就是呃确实资源也不够。

然后我们可以去尝试去做整个pipeline里边的，一些我们觉得比较自己感兴趣吧，也不我也不敢说，关键啊，至少说自己感觉得感兴趣还挺蛮有用的一些step，那这个step的话呢，它可能用到的资源。

就明显要比整个系统要小很多啊，在这个情况下呢，我们去找一个还不错的一个系统，作为我们的base ine，然后呢我们尝试去对某些step做一些改进，呃这样的一些工作呢，我个人感觉不论是对学术界的同行来讲。

还是对工业界来讲，还都是蛮有意义的，呃然后就是我们不尝试去做整个这个汽车，我们尝试去做几个螺丝钉，然后呢，我们扮演好我们这个做螺丝钉的这个角色，我觉得也蛮幸福的，就是就是你感兴趣什么。

你做什么还还还蛮自由的，呃另一方面呢就是说呃，当我们有一些这样的一些工作的时候呢，呃我们希望展现出来这些工作的这些用处吧，或者说可呃可能性吧，嗯我们也在确实会很紧密的，在跟一些企业去合作。

然后当我们有一些还不错的，一些初始的结果之后呢，我们经常会联系一些企业，唉自己没自己没卡吧，可以借别人的卡用，唉大概我们是这么处理的，好谢谢，而且而且的话其实学术界的话也是开源的。

这一部分的话非常重要的这个贡献力量，对呃呃我们后面统一来好吧，对好的，那你们三位的话应该是在工业界，你有是有没有兴趣分享分享，对我个人的感觉，就是我觉得为什么现在会出现这个问题，是因为呃对于工业界来讲。

大模型是一个呃非常有潜力的商业化的，这样这样一个一一个前景呃，所以工业界会给特别大的投入，是看中了它的这个商业的潜力，呃从这个角度来讲，我觉得是不是可以呃，考虑一下有没有之前的一些科研的这种领域。

当它被工业界挖掘出来，有非常大的商业前景的时候啊，学术界是怎么处理的，比如说在物理生物，我觉得一定发生过这样的事情，就是比如说像通讯领域对，就那个在应该是在上个世纪的时候的话，非常非常的火爆。

工业界马上可以用，后来的话就有很多的学生就去那边，以后的话是的话也去那边，但后来慢慢慢慢慢的那个领域的话，就变得就是成绩了，相当于是因为就是像这个问题的话，已经解决到一定程度了。

其实历史的那个教训来其实不是特别的乐观，哈哈哈哈对，那这个我觉得可能从这个角度，我我会觉得，那学术界能不能考虑，做一些工业界做不到的事情，就是更前沿的一些探索，或者是呃就是不是说去直接的竞争。

而是说去在自己的这个更擅长的地方，去去去做一些尝试，比如说呃，比如说我觉得从这个diffusion角度来讲，这个diffusion的模型就有很多，理论上的可以提升的空间，我觉得就是呃呃。

那从可能工业界他会选择一个更保险的方案呃，更被验证过的方案呃，那学术界能不能有一些创新性的，当然他可能不一定用有这个资源，用skin law去验证，但是可以通过合作的办法呃，去做更多的这种创新的探索吧。

我觉得嗯啊，说几句吧，就是嗯确实就是我自己也是体会非常深切的，就是说很多时候，就是大家想要做那种大规模的模型的训，练的研究，是受到了这个硬性资源的限制，其实这个限制还不只是说学校。

其实就是就是创早期的创业公司，也同样是那种中小型的企业，也是会因为财力的原因，就是没有办法做这方面的研究，那么但是我觉得就是现在嗯我还是比较乐观的，一个就是说我们会有越来越多的开源的模型。

就比如说像自然语言处理这个领域，LP它会就是拉满进行了浪漫，one la two这些开源，然后后面也嗯引发了就是一系列follow up的工作，然后嗯像在视频方向呢。

其实我们自己的这个open sa的模型，也是用到了大量的开源模型，然后在这个基础上进行推进，然后还有一点就是说嗯，我觉得一些加速的工作也是非常有价值的，对就嗯包括就是之前嗯老师嗯这边分享的一些。

就是通过这个嗯只recover，它这个被mask掉那个部分这样子的一些方法，然后嗯像我们路程的话，用的这个cos AI的这个加速系统呢，也是之前是可以，比如说在把这个v it的架构。

只在单卡这个3090上面进行嗯，非常嗯就是一个性能的这一个加速和提升，然后大家感兴趣的话，也可以去看我们这个官网的这个公开的数据嗯，然后在此之外就是如果说讲到比较细的，就是研究的话呢。

就是我自己目前其实我看到嗯也是有非常多，就是那种出色的工作，包括我们用到的这个VAE，就是说嗯，一开始大家就是说我们先训练一个VAE，然后把他freeze住，然后再从头可能开始训练这个defense。

Transformer，但是就是说pixel sigma，他的发现就说嗯虽然就是我这个VIE，我在跟他训练以后把他freeze住，但是就是我仍然可以就是非常快捷的拿它来嗯。

就是放到我们这个新的这个transformer，架构上面，再让transformer很快去适应这个freeze，主的这个VIE的这个架构，然后也包括就比如说我们新的这个版本。

用到了一个reactify flow loss，这个就是我们嗯他的那个论文，就是作者一开始也没有进行非常大规模的实验，他只是就是发现说他这个把嗯这个noise，再到这个mapping，他这个嗯会跟哦。

比如说我的那个training，还有validation loss，跟我最后这个模型的表现是有比较强的相关性，然后之后也是被嗯，有更多资源的公司拿去进行验证，然后确实发现了这么一回事。

然后我们就把它应用到了这个我们最新很重，所以我觉得其实嗯学术界的很多科研的，这个成果呢，嗯对这个业界就是也是有非常大的贡献的，然后因为现在嗯也是一个早期，所以我觉得更多也是相辅相成的一个过程，挺好挺好。

其实就是有做数学的人，因为我经常也跟一些做数学的教授的交流啊，他们认为其实我们做机器学习的话，其实只有三个问题，第一个问题就是说网络结构是什么意思，就是说我有一个idea的function。

我也只能在一个hythesis space里面去拟合，那么这个have shave sc base的那个创立的话，其实就是就是mini maze这个LR，第二个就是说你要得到这个得到这个解。

但是你只能用一些具体的数据，那么这样的话你就必须要定义一个loss，那么这个loss怎么定义的话，就决定了你根据这个数据的话，它能够拟合到什么程度，那么第三个就是说。

因为你虽然说在这个里面有这么一个好的解，但这个解的话只能从一个任意的解开始，所以他就有一个optimization，所以就是optimization是这样的，其实如果是说回归到这个数学的本源。

这三块的话，我是觉得其实学术界的话，还是有很多东西可以做的，对嗯好那包凡你这边可以补充一下，就是对于刚刚那个数学界的那个老师的看法，我觉得他可能想的有点薄，就其实我觉得在这个人工智能里面。

可能最重要的是如何定义数据的分布，就这个data dispution要怎么定义，因为data ption这个东西呃，其实取决于你这个智能它是怎么样的，对其实它第二部有两个，一个是叫data。

一个叫loss，其实data上也考虑到了，对对，其实在现阶段，我反而觉得后面这些loss，就你有了数据分布之后，你要怎么去建模，它，要怎么去优化它，这些问题都已经被解决，大差不差了，优化有ANW。

然后loss那自回归loss，然后diffusion loss那些都发展的非常迅速，那其实感觉反而这个研究最少的是这个data，EXPTION要怎么定义，所以我觉得就是呃在学界。

一个非常好的一个topic，就是关于数据的工作，你要怎么去把这个数据分布给它定义出来，其实数据分布就这是一个，你觉得是一个工业界的呃，是一个工程的问题，还是是一个是一个理论研究的问题呢。

我觉得他可能都有对，就是你数据分布呃，首先就数据分布，它是那个取决于你这个智能的上限对吧，对学生会的话，在那边也讲了，你们其实对数据这块的话，对整理的话也是非常关键的对对。

其实我嗯就我觉得不仅仅是数据清洗吧，数据清洗它这事情本身可能是会偏一些engineering，但比方说你还有一些比较有趣topic吧，就你手头上有一堆比较差的分布，你可以通过一些统计学的方式。

比方说这种你觉得SAMPING或者说那个important sweetest，EMPY的方式去提升数据质量，我觉得也是有非常多这种理论的层面上，可以做的，但我觉得其实相比这些更重要的，还是说。

我觉得可能无论是工业界和学界，都需要思考问题，就是怎样的数据分布能够带来强大智能，呃，我觉得这个东西就是所有人都可以思考，这个事情，Okay，great好，那我们接下来可能用很短的时间回答一个问题。

就是说按照今年这个发展这个趋势的话，大家预估在这个接下来这一年里面的话，视觉大模型有可能会有哪一些新的breakthrough，可能发生，简单的说一下就可以了，我们从爆反这边开始吧，对，对。

其实我思考问题还是比较习惯性的，从这三个维度加数据去思考，第一个是这个数据分布怎么构造，第二个是数据要怎么表示，第三个是那个数据的理解，第四个数据的生成，然后呃比方说在数据的分布上啊，其实我觉得这个。

这个这个东西的话，我觉得还可能还是会比较中规中矩的，一些更加好的数据清洗方案，或者说一些更加巧妙的数据构造方式，会被提出来，然后也会让这个智能提升一定的水平吧，然后在这个数据表示上呃，其实我最近关注到。

就大家对数据表示热情越来越高了，呃就之前你可能看到的，在图像上，就大家就几乎不太去care它的这些压缩工作，呃，当时发现最近就是有好多人开始做这种呃，这种图像的VAE呃。

思考怎么把这图像的压缩率给它降下来，我觉得这会是一个呃非常大的突破，就因为当你这个图像的表示压到足够呃，足够稀疏的哦，足够稠密的时候，那他在后面去做这种生成和理解所需要的训练，开销。

所需要的这种呃复杂度应该都会进一步的降低，然后从而你可能后面要花十倍的算力去做，生成和理解，你现在现在可能只需要一倍，那就意味着可能这种skding role对吧，他的这个门槛就变低了对。

所以我觉得可能从数据的表述的维度上呃，今年会有一些比较大的进展，然后从而去推动这个数据的理解和生成，这样对于数据表示，那么如果压缩得足够很的话，那么就相当于是后面去train的话。

它所需要的这个成本就大幅的降低了，对这肯定是一个重点好，那么接下来每个人可能用三大概30秒，好吧哦，我先讲一下，就是首先从数据的角度的话，就是说我们有大量的数据，然后可以嗯其实或者说哪一个领域吧。

或者说哪就是哪一个哪一个问题的领域，可能会产生新的breakthrough，对哦OK就是如果只是从这个视觉来看的话，肯定就是说视觉的这个质量，可以会有非常大的提升。

然后这个长度生成的长度以及它的稳定性来讲，嗯也是，然后我们可我觉得我们可以期待我们视频，这个视频对会生成更多不同的场景，然后从可控制性来讲，也是因为嗯随着这个视频这个标注，他这个也是在不断进步的。

然后更好的quit，和这个视频生成过程的可控性会有大幅的，这个会有新的创新出来，对我觉得这个是可以期待短期内饰可以的，非常快速的提升，great我觉得这可能是业界非常期望得到的，郝俊男呃。

我提一个叫那个评测吧，因为我觉得现在这个视频，不管理解和生成的评测都非常欠缺点，空白的状态，对对对，这个就不是breakthrough，而是说从可能没有到有的一个过程呃。

我觉得有一个大家都公认的这样一个类似，语言模型里面，这种评测我觉得是非常必要嗯，可能有更多的系统出来之后的话，可能这个评测会更容更好做一些，因为现在开源的系统还太少，对好命名了啊，我特别看好，就是说呃。

现在越来越多的这些各种各样模态的输入，输，各种各样的一些呃，多模态带来的各种各样的可能潜在的可能性吧，我我就简单的说这个好，谢谢，就相当于说因为有了其他模态的和这个视觉的，这个结合。

有可能会让它的这个产生内容的过程中的话，就会产生一些新的这种创新点出来是吧，是的是的对，就好像你做那个，比如说那个就是呃生成了一个story一样，diffusion story一样，对不对是吧。

是的是的，谢谢好，谢谢各位好，那么接下来我们大概有还有4分钟的时间，那么呃大家的话都是自由提问的时间以后的话，大家最好把问题identify到哪一个panelist，好吧好，那位同学对。

后面的诶各位老师嗯，大家好，我是做AIGC应用的，然后也是视觉主，主要是视觉应用，然后我想问一下各位老师，就是就是对于视频的这种可控性，图片或者视频的可控性，嗯就是主要的就是视频的那个动作的控制相关。

目前我们图片生成的一张图片的这样一个呃，角色啊，这个我觉得都做的还可以，但是你要让他这种动起来的话，这应该是视频你走向更长的一个核心，所以说我想听听这个各位呃，老师在这块的一个想法，指定一位吧。

嗯呃要要不集中让陈老师帮我看一下对，因为他也是那个呃story那个，然后还有一个点就是就我主要我的问题，主要是可控性这块，然后刚刚的这个时长，我觉得就是动作的控制是比较关键，还有一个就是就是图片这块的。

比如说表情或者是一些手这种细节，我想听一下，就是陈老师，其实陈老师那个就是做那个啊，就是那个呃图就是那photo maker，对不对，其实它也类似于是用几张图像，是control它来生成图像，对不对。

是的就是说呃，所以所以我其实最开始我一直提一个观点啊，我觉得现在的这样一些呃头像的视频的，特别视频的这样一些生成的这些模型，我个人感觉啊，他可能最早能够大规模被大家可用的，应该是在娱乐行业。

就是相对来说不是那么严，也就是因为呃确实是您刚才存在的说的，说到的这个问题，他要是做到非常好的高质量的这个可控呃，理解我们人脑子里边嗯，所理解的包括像物理公式上物理的规律呀。

呃包括它的一些其他的一些很精细的一些控制，它确实还是现在的这样一些呃，我们靠这个VIT啊，靠这样一些呃这个特征的表征，其实很难把这样的一些规律给它表征进去，呃因此呢在后续的这个训练过程中。

现在呃大家能做的呢，就是说尽量的搞好多的数据，然后呢希望这个事出现的少一点，嗯也没有一个特别高效的一个手段，能把这些比如说哎这个轮子转的这个速度，跟这个车的运行速度给它匹配起来。

这个人的动作呢能够跟他的这个骨头，给他对得很好啊，这些事呢目前来讲还是比较难的，但另一方面呢我们也看到了，就是说可能针对一些具体的问题，比如说刚才我们提到的呃，杨老师也提到的。

就说我们像做to photo maker的时候，我们呃可能那么多的事情不好做，但是呢我们可能抓住其中几个点，比如说呃，比如说像这个人的这个人脸的一些，具有个性化的属性的这些东西。

我们把它给想办法给它弄出来，然后呢去验证说这个事情，有没有可能通过少量的一些数据，其实虽然我们有一个自动的数据组装内存，但是你看到最终我们实际用到的数据，其实也就十几万张的图像嗯，也不算太大。

但是呢可能把人脸的一些关键的属性，或者至少人特别感觉，还是就是至少说感觉，那个比如说甚至从这个老人到小孩，我们都感觉那个那个五官眉眼特别相似啊，就是把这样的一些东西。

可能呃我是感觉可能在未来短期一段时间内，可能大家会在这个领域，那个领域把各种各样的东西尝试去呃，更好的做一些表征，然后呢靠这些东西去约束呃，至于说在什么时候能把这些universe的都都弄好。

这个可能还稍微再长一些时间好，我就回答这样啊，谢谢好的，谢谢老师，那呃这位同学吧，对，呃各位老师好，那个我主要想探讨一个问题，就是呃我们就是统一表中的这个问题，因为我在想说我们对真实世界。

就是刚刚包凡也提到说我们真实世界的存在，那我们对真实世界的描述，其实人是怎么沟通，我们其实通过语言沟通，都不是通过文本沟通的，因为像我的方言，那他可能并没有针对性的文字，所以我就在想这个问题，就是说。

其实不同的语言是可以描述同一个物品的，例如这个麦克风，其实有不同的语言都在描述这个麦克风，那包括即使我这个人在讲这个麦克风，它是普通话，但是我可以很慢的说麦克风，或者很快的说麦克风。

但是他还是表示这个物体，所以我就在想说，那是不是这个语言的这个东西，其实是可以有比较统一的去这个表征了，因为不论是呃不同语言，还是说同一种语言的不同人啊，不同的啊表表达的情绪，他都表征了这么一个物品。

它是不变的，像哪位同学啊，我可能俊男哦，对，我觉得这个可能第一个涉及到一个这个，多语言的语言，语言模型的问题，呃，我觉得目前的一个呃学术界，可能也涉及到了语音的问题了啊，对也涉及到语音的问题。

我觉得呃之前大家会觉得不同语言之间，不同语种之间是有一个这种distribution的，这种分布的差差异的呃，但是可能在大模型的这个时代呃，如果我们就是在我们用GPT的过程中。

比如说你会发现它其实对于不同语言的理解，是可以非常自如的切换的，那这个我就有理由猜测，它其实内部的表征是得得得到了某种程度的，统一的，呃，包括语音上面，如果说他真的做出一个end to。

end的这样一个系统的话，呃那它这个内部的机制，我觉得也是会慢慢的学到某种统一的表征的，呃，所以我觉得呃，当模型这个skin到越来越成熟的情况下，它确实是会呈现这样一种趋势，对好的，针对这个问题。

我想再稍微补充一下，就是嗯这个因为涉及到多元模型，然后就是其实目前也是有非常多的研究，就是在做这方面的工作，我觉得我我其实也不是说想回，就是可能大概的提一下现在遇到的几个难点吧。

就是说嗯比较严比较重大的一个难点，就是说有一些嗯小语种，或者我们把它叫做low resource，对这方训练语料它其实是非常的缺乏的，然后可能即使像charge bt这样的模型。

它也是哦没有办法把它做的很好，然后这其中就比如说嗯嗯您刚才这个提问说嗯，不同的语言都可以描述同一个物体，但其实有的时候这些也是语言，也是受到这个文化的很大影响，就很多可能有些文化当中就没有一个概念。

所以这个可能也是一个难度，就怎么样把它合适的，就是用这个语言去给它统一出来，那么我们现在其实主要，就是说用大量的数据去训练，然后嗯但是就是可能也也是要看，就是未来，这个就是现在我们可能比较大的这个语言。

就比如说中文，英文，法语，德语这些我们有大量的语料，那它可能能力已经非常的不错了，但其实嗯在其他的low resource language，依然就是一个问题，有可能将来的话。

这个translation可能是一个照数据的话，可有可能是一种途径去去解决这个问题，因为translation如果做的还像模像样的话，可能是一个就是把一个语言的数据的话。

transform到另外一个语言上的那个数据对，因为我其实之前也做过一些，就是多语言模型的训练，然后其实我们涉及到的也是有，通过这个老师您说的这个translation的方法，然后再进行一些数据的清理。

然后这个方法其实确实可以提升这个大模型，在这呃，在这个小语种这个上面的能力，好的好，那我们最后一个问题，呃时间不够了，好不好的，我们把机会给另外一个同学，我们最后一个问题好不好，对好，哎你好，我问一下。

就是问一下鲍老师吧，就是就是我们我们现在也做一些那个那个声，就是那种图像编辑的一些一些工作，就是我我们用的是NERF，我看你们用的是嗯SD就是生成模型，我想问一下这两两种路线。

就是它未来的发展会会会怎么样，就是会拿到3D3D的维度是吧，对对，都是3D的NF也是3D3D重建吗，我觉得就他们会对应着一些不同的交互方式，比方说3D的你比较自然，你可能是有个呃一个表示界面。

然后你可以去比较轻松拖拉拽，或者说扭一扭这个表示，然后有点像那种捏向平移的感觉对吧，你可以把这个表示，通过一些方式去手动搓成另外一个状态，然后通过生成的话，它就是呃会有一些对应不同的交互方式。

就它自由度可能更大一些呃，比方说你可以通过这种对话式的，就你提供一些素材，用户提供一些素材，然后它这个系统自动办，去根据用户的需求去做一些合成呃，或者说是你可以对一张图像呃。

在一个编辑框里面对它这个涂一涂抹一抹，然后它呃系统帮你自动的做一些增删改，其实我觉得本质上可能还是回归到产品啊，会对应着这种交互方式的一些区别，好的也就是说这个three d高en spring的话。

它可能在这种是控制性的维度的话，就是更加的这个understandable，就解释相当于是对好，那我们今天上午就到这，让我们再次用热烈的掌声，感谢我们四位的这个panelist，非常精彩的分享好。

那么现在应该下面就是午餐的时间了。
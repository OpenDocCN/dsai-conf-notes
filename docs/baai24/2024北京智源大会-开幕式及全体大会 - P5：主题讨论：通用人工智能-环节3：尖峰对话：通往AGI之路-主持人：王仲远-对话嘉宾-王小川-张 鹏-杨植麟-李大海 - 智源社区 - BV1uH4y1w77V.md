# 2024北京智源大会-开幕式及全体大会 - P5：主题讨论：通用人工智能-环节3：尖峰对话：通往AGI之路-主持人：王仲远-对话嘉宾-王小川-张 鹏-杨植麟-李大海 - 智源社区 - BV1uH4y1w77V

再次欢迎指令小川，张鹏大海来到我们今天志愿大会的现场，我们这个环节是尖峰对话环节，我们想要讨论的是通往AGI之路，各位都是国内头部大模型公司的CEO。

我也想请教一下各位是否相信大模型是通往AGI之路的一个基石，抑或是大家在实际的训练大模型的过程中发现，它可能依然只是一个数据的压缩，可能对于产业界是非常有价值的，但并不一定能够通往AGI。

我想听听各位的看法，我们比较相信大模型还是这里面的第一心原理，就是通过不断的去提升模型的规模，就像钟远刚刚说的，它确实本质上是一个压缩，但这个压缩它确实是可以产生智能，所以你随着不断的去规模化模型。

不断做更好的压缩，它能产生越来越多的智能，当然肯定在这个过程中也会有很多挑战，比如说可能最大的挑战就是，有一些数据可能它并不一定有那么多，对吧 那在数据没有那么多的领域。

或者说假设你最后要做出来一个可能比人类更好的AI，那你可能就根本不存在这样的数据，因为你现在所有的数据可能都是人产生的，所以我觉得可能最大的问题是，怎么去解决这些比较稀缺。

或者说甚至可能有一些不存在的数据，但是我觉得规模化定律或者说大模型本身，可能是没有太本质上的这个问题，我刚刚注意到的提议就是说大模型，这个通向AGI是否是基石，我用基石这个词是没有问题的。

今天大家已经看到了这个，这个scaling law它带来的这样一个提升，但是我想说的话呢 它只是在逼近AGI，但是光靠scaling law我理解是不够的，所以在这里面的话 如果从第一性上讲。

其实刚才这个亚琴也在提到这个事情，觉得需要有范式的一个改变，所以我是认为确实是这样，今天大家看到了scaling law的第一件事，今天的话我们还有一件事情大家不要忽略的。

其实是把语言放到大模型的体系里面，把语言变成了数学，我们将来往前走，语言其实把这个符号的这么一个主义，跟连接主义之间产生了一个突破，所以除了这个规模以外的话呢，符号跟这种连接的融合。

我觉得这是中间的一件事情，那么再往前走，还会有更多东西必须有范式改变的，比如说这个，今天大模型是靠数据驱动一种学习系统，能做压缩，但是反而像之前，类似像AlphaGo那种能够自我去，我称叫思考性的系统。

它也会有这样一个作用，所以我的结论来讲的话是，一个是我们到了AGI的时代，这个时代里面我们是能够，有足够多的科学家进来，够多的资源进来，能够走向AGI，但是光是以现在我们公开。

大家看到了Skinning这个事情，是做不到AGI的，张鹏 张仲，其实要说大模型它是不是说一个基石，首先同意小川说的，它肯定是基石之一，那是不是之一，这是另外一个问题，所以这个问题其实也涉及到说。

你怎么来定义AGI，其实刚才两位台上，开复和雅琴也聊到AGI到底怎么定义，其实也跟定义有关，但是站在我们现在看到的角度来说，其实我是觉得做人工智能的这拨人，还是挺实用主义的，所谓的实用主义就是说。

咱不看广告 看疗效，这东西它能不能解决问题，是不是，能不能真的像我们心中所谓，每个人心中定义的AGI那个路径上，能够帮我们推进一步，所以大模型到目前为止，还是很有效的在推进这件事情。

而且就像刚才小川说的一样，其实我们这个scanning law，还是在有效，还是在往前前进，至于说它是不是能够帮助我们，推到顶峰上去，我们现在也找不到很确切的一个答案，但至少我们相信说它在这个阶段。

还是有效的，所以我认为它肯定是基石之一，这个没问题，好 谢谢 谢谢张鹏，大海，我个人是数学专业毕业的，所以我可能会比较严谨地去表达，就是我认为大模型，一定是通往AGI这个方向上。

当前所有技术里面能走得最远的，它能不能够直接到达，我觉得现在还有很多未知的因素，包括刚才提到的定义是什么，但我想提一个，可能大家没有提到的点，我觉得现在的大模型，作为知识压缩。

主要是在处理人的大脑的系统一的工作，我认为这种慢思考的系统二的，去做各种各样的推理，搜索空间里面去做搜索组合，来完成一个任务，这样的能力，我觉得是未来大模型，可能要通过H&R技术外部化。

或者把它内化为自己的能力，这个是行业里面，我觉得大家需要去探索的，好 谢谢，其实确实有一个非常有意思的问题，我们总在讨论AGI，但似乎好像连AGI的定义，大家都没有广泛的共识，然后我不知道在各位的心里。

这个AGI到底什么样叫AGI，志琳，对 我觉得，首先我觉得AGI的定义是重要的，但是它不一定需要在现在，被非常精确的有量化的定义，它可能是一个定性的感性的东西，或者，我觉得因为它最重要的一个作用。

我觉得是能让这个社会，或者说所有人吧，能够对于说接下来要发生什么事情，有一个准备，因为就是可能，也许这个技术的节奏会非常快，那我们如果能够知道AGI它是什么样的，能够某种程度上去定义它。

我觉得其实是可以更好的去，准备这个事情，不管你是每个人的职业，还是说就是这个行业，接下来可能会怎么发展，我觉得首先这个是重要的，然后，可能第二个就是说，也有一定程度上就是说，你在短期内。

我觉得可能是需要一些量化，因为如果你没有，完全没有量化的话，你可能就没有办法去衡量，你这个AGI的开发的这个进度是什么样的，所以可能从短期的角度来说，这个evaluation本身也会是个很难的问题。

而且可能也是个很大的挑战，所以志琳觉得比如说，我们需不需要有新的图灵测试，因为我们知道如果，按照传统的图灵测试，应该已经被大模型给攻克了，对 传统图灵测试，可能在现在已经不完全适用了。

因为即使说它现在通过了图灵测试，但是它可能还有很多事情，是人可以做得非常好，但是AI基本没法做的，就是现在其实还有很多，大量这样的事情，所以我觉得这个不是一个很容易的问题，就是你可能需要去。

对这里面评估的维度，去做很多拆分，比如说你可能会有，不同的这个能力，比如说知识能力和推理能力，和创造的能力，它可能就是完全不一样，评估的方式会完全不一样，对 所以这个也是现在。

可能大家很多人在关注的问题，我觉得是非常重要的，对，好 谢谢 谢谢志琳，那个小张，咱们上次在央视对话栏目里面，其实您也提到去年是智能纪元的元年，所以这智能纪元是AGI的纪元吗。

又或是您对AGI这块怎么理解，上次提到我刚刚提到，今天是个元年，是因为我们掌握了这个skilling law，同时我们掌握了把语言变成数学，这是重大的一个起点，当这个机器掌握语言。

我觉得这是翻天覆地的一个变化，因为大家以前都在讲这个，图片识别很厉害，无人驾驶也很厉害，对吧 我可能调侃就是说狗都会，这狗也可以自己导航，狗也会看图片，但是狗是不会语言的，语言代表我们认知世界的。

一个大的一种范式，我特别喜欢刚才你这个问题啊，就是什么是AGI的这个定义，对吧 确实在全球里面，很难有完整的一个这种共识，刚才大学说学数学的，我相信我们得通过变换，把它从一个空间换到另一个空间。

来做一个这个判断，换成另一种事物来判断，就跟咱们讲的保新变换一样的，那么在我看的话呢，我会用一个这个，大家可以评测的这个指标来看，在我心中是接近等价的，是什么呢 是能不能够去造医生，能不能造医生。

为什么图这么一个奇怪的一个题目，之前我们在谈AGI的时候的话呢，一种理解把它当成工具在看，我认为这次AGI的这个，首先第一个变化，它是能够开始有这种思考能力，学习能力 沟通能力 共情的能力。

甚至有多么态的这种，这种图片处理的这样的能力，从它的学习范式的能力要求里面，我反而觉得我们是在，就是像看人一样在看它的，所以一种做法是说，跟人是差异化看，但我从我的这个，整个这个从我们今天。

所谓大家共识的评价指标，或者学习范式里面，就是在向人学习，它数据来自于人类社会产生的数据，所以一直在评价里面，我是拿人的一个职业，来跟它做这样一个比较，医生在这个所有职业里面，相对而言是一个叫智力密度。

相对最高的这么一个行业，既需要多么态，也需要少幻觉，也需要既看你七十万字的，这么一个病例，也有推理的能力，也有这样查文献的能力等等的，对吧 所以，我把医生跟AGI做比较时候的话呢，其实我就会说呢。

做到AGI 做到医生，是否就算做到AGI了，然后我发现肯定有很多种声音的，比如大家 哎呀 这个医生，只是一个vertical，是个垂直，那其实医生比这个低，那但是我说那能造医生吗，他说 哎呦 太难了。

这里面有太多太多的这样的一个，这个幻觉问题，有太多的这么一个，一个咱们讲到的这种，这种他的推理能力 对吧，这种不可靠，那如果我们认为医生是比AGI低的，医生都造不了，我就就咱们就别谈这AGI这事。

但是如果你觉得医生比AGI高，但是我们又讲这个医生只是这个，这么一个叫做，造人的各个种类中的一种，所以在我的这个逻辑里面，医生跟AGI讲，我是可以基本就画个等号的，那数学上有一个题目，刚刚大海强调。

就是自然数和偶数哪个多，我们第一反应是偶数比自然数少，对吧 偶数是自然数的一个子集嘛，对吧 每两个数只有一个偶数，但数学上应该知道它们是一样多的，因为每一个自然数乘以二就是一个偶数，它们是可以映射的。

所以把自然数和偶数能做映射，今天我是把大模型，咱们今天行业上能共识的能力，都可以映射到对于这个医生的一个要求里去，因此拿这个作为一个标准，能造医生就是个AGI，好 谢谢小川，大海你被cue到了。

那个数学家作为，你对这个AGI怎么去理解，我会尝试从经济学的角度来去定义AGI，我觉得从经济学的角度讲，如果我们去执行任何一个任务，它的边际成本都为零，这就是我们理想中的AGI了。

但是这个就回到我刚刚说的，为什么我认为大模型能够走得最远，就是我相信大模型能够把这个边际成本，一直往下降 可能会逼近于零，但这个过程中就像指令刚刚讲的，很多时候需要我们在各行各业的数据。

产生一个飞轮 逐步地让模型持续训练 持续学习，然后让整体的成本降下去，其实我们去年看到行业里面，大家去做大模型的落地的时候，很多的场景都还需要做微调，这个边际成本就很高，我们相信随着模型能力的提升。

慢慢地从微调，逐步地只需要做Prompt Engineering，慢慢地连Prompt Engineering都不需要做，模型直接就问你，说你到底有什么需求，如果你讲不清楚我来问你 对吧。

通过这种方式我相信，未来的门槛会越来越低 成本会越来越低，低到接近于零的时候，我觉得AGI基本上就到来了，另外一方面呢 我们就是，我可能额外还想补充一个观点，就是我们现在大家都在讲怎么把模型做大。

其实刚才小团提到一个关键词叫智能密度，其实我们觉得大模型的智能密度，也是个非常重要的事情，就当有一天我们达到AGI的时候，我们还要做一件事情是大模型的小型化，就是我如果用一个10万亿的参数的模型。

能做到AGI，我能不能把这个10万亿的参数，把它降到1万亿 把它降到1000亿，这也是一个我觉得持续要去突破的事情，对 其实面壁智能以及像智普跟智源，都有非常深厚的渊源。

其实当年面壁的刘老师 刘志源老师，以及像咱们智普的谭杰老师，都是跟智源一起，就开始做我们的悟道系列大模型，所以也想请教一下张鹏张总，最开始咱们做悟道系列，再到后来咱们整个智普系列这些大模型。

最开始有考虑到它可能实现AGI吗，您对这个AGI是怎么去理解的，对 其实在我们看来，看待这件事情 AGI这件事，其实你要说它是一个，有一个很严格的定义的一个定义，还是另外的什么东西，其实我更愿意相信它。

可能是我们的一种信念 是一个符号，它的内涵外延是在不断地变化的，其实刚才提到了早期的定义AI的时候，我们说怎么来检测这个系统，是否是一个AI系统 图灵测试，但现在大家已经觉得这个已经过时了。

就是因为随着我们对技术的不断地演进，对这些事情的认知越来越多，然后越来越深，然后其实本是在同样的三个字母，所代表的含义实际上是不断地在变化，在这个动态的过程，所以刚才这里也讲。

就是说其实它是一个balance的事情，就是如果你把一件事情，能够把它说得非常的量化，非常的清晰，内涵是什么 外延是什么，那这件事情that's it，也就那样了，估计天花板在哪儿大家都能看得到了。

那现在的问题就在于是说，其实没有人能够把这件事说清楚，那反过头来讲是一个好事，就是说这个事情还有很多的空间，很未知的空间等待我们去探索，所以AGI对我们来说，你可以把它定义成我们的一个目标。

那对这件事情我们一直相信是说，当前我们的目的，我们的目标是说以人为参照，让机器像人一样去思考，这就是我们的愿景，那这是第一步，当然刚才也提到说，机器的能力远不止人的这个水平。

那我们期待它可以出现超越人的这种能力，所以AGI里边我们会提到说有这个，叫Super Intelligence 下一步，它是否能产生超过人的这样的智能的水平，那就是我们会不断地去更新。

迭代AGI的内涵和外延，好 谢谢，其实直龄也跟智源是有非常深厚的渊源，当年也是我们悟道系列的核心的技术骨干，然后也是我们智源的青年学者，然后我们今天其实早晨在反护，大家都提到的一个词。

Scaling Low，我不知道直龄你对Scaling Low，还是特别的坚信吗，就是它会继续在未来的这些年会起作用吗，对 就像我们刚刚说到，我觉得这个Scaling Low没有本质的问题，对 就是。

而且我觉得接下来可能比如说三到四个数量级，我觉得是非常确定的一个事情，就是可能我觉得这里面更重要的问题是说，你怎么能够很高效的去Scale，然后你应该Scale什么东西，就比如说如果你只是。

还是像现在就搞一堆WebText，搞一堆网页的文本，然后再去Scale，我觉得可能就不一定是一个对的方向，因为这里面可能就会遇到很多的挑战，比如说我们刚说的这些推理能力，它不一定能够在这个过程中解决。

所以我觉得这里面其实本质上是，就是怎么定义Scaling Low，就是说Scaling Low是什么，对 如果你是说，我就沿着当前现在的方法，然后我去做Next Token Prediction。

然后我再去Scale很多个数量级，然后用跟现在完全一样的数据分布，我觉得它的上限是很明显的，对 但是Scaling Low本身，它其实并不受这个东西的限制，就是本质上它讲的是说，我只要有更多的算力。

然后我更多的数据模型参数变大，那我持续能产生更多的智能，但这里面它其实并没有定义你的模型是什么样的，比如说它要多少个模态，它中间的数据是什么样的，它数据是你生成出来的。

还是说我是可能还是用这个Web Text，所以也没有规定你的这个Loss Function是什么样的，就是你不一定是Next Token Prediction，你可能是别的Loss Function。

所以我觉得Scaling Low是，是会持续演进的一个还是First Principle，我觉得是这样，然后只是说在这个过程中，你要Scale的方法可能会发生很大的变化，对 包括现在比如说。

像Yann LeCun一直在讲的这个世界模型，我觉得其实本质上现在的大语言模型，它是世界模型的一个特例，对 所以你只是说先把里面就是一部分给做了，但是你还能把可能更多的持续的去，扩充这个训练的这个方式。

对 所以我觉得Scaling是会持续，只是Scale的方法会变化，好 谢谢，小川你对Scaling Low，还是未来几年会持续发挥作用怎么看，Scaling Low，对 Scaling Low。

您觉得是会在未来几年持续的发挥作用，对 我觉得Scaling Low它一定会，到目前没有看到边界的持续的发挥，所以看到美国在Elon Musk对吧，号称要买30万片B100 B200来做。

所以在这种情况里面的话，美国确实在这方面的认真程度，甚至包括投入程度是会远高于中国的，因此在我看起来的话，我们在Scaling Low之外，一定要去寻找这个范式上的新的一种转化。

咱们就能讲数据 算法 算力在里面，所以我觉得Scaling Low，它们在里面是很明确，就是在美国后面跟进的这样一个维度，不管从我们的战略上讲，还是从我们信仰上，我认为在Scaling Low之外。

都还有范式的这样一个变化，就不只是简单的去，Prediction Token变成压缩这样一个模式，会走出这样一个体系，才有机会走向AGI，才有机会能跟最前沿的这代技术里面，产生这种较量的能力。

江鹏您对Scaling Low呢，其实我刚才在讲AGI这个定义的时候，其实已经表达了相当的观点，就是说Scaling Low这个事情，它本身这个定律，我觉得到目前为止，人类认识的所有的规律也好。

这些物理定律也好 什么也好，其实都有可能有推翻的一天，只是看它的有效期是多长，所以刚才也同意的，就是前面加一个定语的话，就是到目前为止，我们还没有看到Scaling Low，会失效的这样的一个预兆。

未来的相当一段时间之内，它仍然会有效，当然这个所谓的会有效，也是一个动态的概念，在于是说它本身所包含的，这样的一些事情会内涵，它会不断的去演进，就像刚才小川说的，Scaling Low早期关注的。

其实就是简单的模型的参数量 规模，现在已经慢慢的大家扩展到什么呢，参数量很重要 对吧，你的数据量也很重要，数据质量也很重要，计算量就变成了一种计算量，所以你看它的内涵其实也在慢慢的变化。

其实是随着大家对这个规律的认知，越来越深，规律的本质越来越结实，所以你掌握这个本质，你就能掌握说通往未来的这个钥匙，所以基于现在大家对这个本质的认识的深浅，我觉得至少在我们这看来，它仍然还会起效。

还会是未来我们主力，想要推进的这样一个方向，我想追问一个问题，其实我们现在也看到像GPT-5，之前传过几次说要发布，但一直都在似乎在推辞，在推辞，那么所以张鹏 张总，您觉得这个Scaling Load。

包括咱们自己因为也都在训练大模型，就是如果我们从追逐GPT-4，到我们要突破GPT-4，再往GPT-5的这样的方向去发展，现在Scaling Load是有出现边界效应吗，我不知道你们怎么看这个问题。

我觉得这个因素可能有很多种，包括刚才说的传说的所谓的4。5，还有5什么时候发布，为什么一直大家传了好几次都没有发布，我觉得这个可能里面的因素会非常非常多，就拿我们自己来说这个事情的话。

其实我们自己也在选择一个道路，不断地去追寻Scaling Load，往前前进，大家就举个例子吧，其实在我们最开始，您也记得我们开始做这个，误导的时候就讨论过一个方案，就是说我们是否去做一个稠密的。

一个单体模型，还是去做一个MOE的，一个稀疏的一个多体的模型，其实这就是当时我们认为说，如何去满足Scaling Load，或者去追寻Scaling Load不同的路径，但是到发展到今天这个地步的时候。

你会发现其实这里面，维度已经非常非常多，你可以在很多方面去做这样的一个事情，所以但同样反过来看这个问题，你会发现其实这个难度又，复杂度又上升了，不是简单地说追求参数量上去就行的，难度也变大了。

所以我理解想要实现，比如说GPT-5或者在下一代，我们自己想要实现下一代的模型，这里边的技术的可能性，要探索的这个东西还是非常多的，也是一样的，就正反两方面，好 谢谢，大海咱们面壁其实主要是关注在。

端测的大模型，所以我不知道在轻量级的这种大模型上，您认为Scaling Load也是有效的吗，我认为Scaling Load是非常重要的，对，但是我也非常认同张鹏的意见。

我们觉得Scaling Load其实是一个经验公式，是整个行业对于大模型，这样一个复杂系统的观察以后的一个经验总结，这个经验总结会随着我们对于，模型训练过程中做的实验越来越多，认知越来越清晰。

会有更加细的颗粒度的认知，比如说我们自己就会发现，除了前面说的这些维度之外，在模型训练中的训练方法，本身对于Scaling Load对于智能的影响，也是比较显著的，这个显著的影响在我们固定住。

参数规模以后其实就会变得非常重要，因为现在大家觉得参数规模是能够不断的往上scale，它是低垂的果实，只要阔就可以，所以就觉得没关系我们先去做，先往上放大，但是一旦我们固定说我们要让端测的芯片。

能够去支撑这个规模的模型，能够去做到足够好的智能，那么数据的质量训练的方法，这些都变得非常重要，对 然后大海我们最近其实也关注到一个非常热门的新闻，就是关于开源社区的一件事情。

像Stanford他们的这个团队，然后确实抄袭了咱们的mini CPM，我不知道您对这个事件是怎么看的，对 最近这个事情在国内引起了非常大的反响，我们也完全没有想到我们的工作会以这种方式出圈。

这个挺惶恐的，在这里我想也想澄清一下，我们自己认为这其实是海外的个别学生，组成的一个小团队做的个人行为，它不代表任何更大的比如像Stanford这样的学校，因为事件发生了以后。

像Stanford的系主任他们也，还有就是整个西方的一些同行，其实也都表达了非常价值观非常正的一些观点，然后另外我们因为这个事件，我们会更加坚定地相信开源的力量，其实像这样一个事件。

它的发现也是靠我们开源的热心的参与者发现的，并不是我们自己发现的，我们是5月20号把这个模型开源出来，然后到了29号的时候，这几个本科生小朋友，他们就做了一些非常简单的工作。

在我们的模型上做了一个高丝叠加，就叠加一些高丝噪声，然后就号称是自己的模型，然后呢 当然它这个模型一下子变得很受欢迎，主要原因是因为他们宣称这个模型的多模态能力。

是跟GPD 4V和Gemini Pro完全对标，但是参数只有后者的1%，并且还只需要500美金就可以训练出来，那前两项是真的，就我们的模型真的是有这样的能力受欢迎，但是500美金是训练不出来的。

还是要花很多的钱，在这个就是5月29号发生这个事情以后，其实一天之后，就我们社区里的热心的参与者就发现了这个事实，然后去把这个事情曝光出来，让我们能够尽快地知道去纠正了这样的行为。

所以我们看到开源的力量是很强大的，这里面是多层次的，不光是有做原创工作的人，还有很多的参与者，他们会在里面贡献需求 贡献反馈，这些也都是对开源这个生态非常重要的一个组成部分。

让我们觉得持续地做开源的贡献，能够给公司带来正向的收益，是 志愿也是非常坚信开源的力量，所以其实在今天的这个报告里面，我们也向各位报告我们过去一年，在开源社区发布的各种的模型。

其实我们的下载量也还是非常大，其实百川也把自己的百川一百川二，其实都对外开源了，我不知道当时咱们百川想把自己的，也花了不少钱训练的大模型，对外开源的一个考量是啥，当时开源的话。

我觉得是在市场上第一个是有这样的一个需求，有需求 因为在当时在去年，我们大概是在九月份就开了第二版，六月份开了第一版，那么在去年的时候，这个应该叫中国是快速入场做大模型。

但事实上的话不仅币源跟美国是落后的，欧盘顶在里面我们大家都没做到，开源上的话当时拉马也开源了，所以在美国其实既有大的币源生态，也有开源的这样一个生态，中国在当时其实对大模型属于一种。

大家热情惶恐也需要快速入场的，所以我们这个开源的话，在市场上产生了蛮好的影响力，做一家把自己当时最好的模型开源了，这样一个做了认证，且开源了这么一个商业化的厂商，得到市场很多的认可。

也给我们做了很多的这样一个好的credit，对我们是挺大的鼓舞，不管最后人才的储备，资本的这种关注，也算是给行业交了个投名状，我觉得这是有历史上，它当时的这样一个意义，但当时我看完还有一个心态的话。

我们也看到模型会快速地进步的，所以在当时我们觉得，开源是不是把自己的底库就拿出去，就没有竞争力，我觉得不会的，因为在那个我们认为模型生态里面，大家今天我们最好的，可能在明天就是一个不够好的模型了。

所以我们从商业竞争里面，其实也没什么大的损失，因此我觉得既有贡献，又没有这样的一个降低我们竞争力的事情，那么就毅然做了这样一个决定，所以这个符合了市场预期，也给公司带来了这样的一个，它的这样声誉。

因此我们这个事情做得蛮成功，挺对的一件事情，那今天其实有更多的公司在里面，也做各方面的这种开源，使得中国这样一个生态，在追赶美国里面，包括我们自主产权里面，我觉得大家共同在做这样一个贡献。

我也希望这个生态能够大家越做越好，好 谢谢小川，这个随着整个大模型的发展，确实AI安全问题也是被不断的讨论，那各位都是做企业的，我想了解一下，就是说AI安全，现在在我们大模型的产业界怎么去看。

是一个当下最急迫的问题吗，志玲，对 我觉得AI安全是非常重要的，它可能不一定是当前最急迫，但是是一个我们需要提前去准备的事情，因为可能随着模型的进展，因为Scaling low本身它的发展是说。

你可能每N个月，你可能就是算力乘10倍，那这里面你的智能会得到提升，那我觉得是一个逐渐去适应的过程，所以它不一定是说当前最大的矛盾，或者最重要的最紧急的事情，但是它肯定是长期储备。

那这里面我觉得最重要的，可能两个方面吧，一个就是说，你的模型本身，它可能会因为你的用户，它本身有一些恶意的意图，导致它会发生一些，去做一些它可能本来不应该做的事情，比如说像现在有研究去做这种。

Prompt Injection，就是你可能，比如说你有Long Context能力，但是你可以在Prompt里面去，注入一些这种，这个不太恰当的意图，然后可能这些我觉得需要去关注，然后第二个就是说。

你的模型本身，它是不是会有自己的这个Motivation，所以我觉得这个是跟训练方式相关的，包括就是你能不能在这个用户的，就是在模型的这个底层，能够去注入比如说这种AI的宪法，能够去框定它的行为。

就不管用户给什么样的指示，或者不管它自己的Chain of Thought是什么样，它都不会违背这个宪法，我觉得这个是很重要的 对，好 小川，我觉得安全的话呢，有不同的这个内涵和外延。

所以我想提三个安全相关的事情，第一个事情就是这个意识形态安全，由于大家都知道做2C，有工作人员这样一个服务，所以作为一个这个中国主权的，这么一个大模型，在意识形态上能跟这个国家发展。

国家意识能够保持一致，这是大家的一个基本功，就每个模型有他们的这种价值观，我们有我们的价值观，所以这个安全的话呢，我认为是对一个民族，对一个社会负责的那件事情，这个安全是个底线，我们大家得把它给做好了。

那第二个安全是大家这个，空谈得比较远的这种安全，就是这个模型是不是把人类毁灭了，以后人就没了，然后机器掌握世界了，所以在这里面的话呢，我其实内心来想，不希望发生的就像核弹一样的，把这个人类文明给搞没了。

就要使得这个，我们人类发展了好几千年，好不容易有了这样一种智慧，结结个模型，然后把地球搞没了，这个事情来讲我就是不发生的，但是至于这个模型，它是否比人更聪明，能够取代人做事情。

我觉得这是个鼓励的一件事情，因为从人类文明里面，我们现在每个人都知道，这种生孩子，然后这种发展技术，去延续我们的生命，和延续我们的文明，这才是重要的事情，人的肉身在中间，每个人都会死亡的。

我觉得大家今天不回避这个问题，所以这个技术能够，跟我们一块去拓展人类文明，我觉得这件事情是有意义的，并不是限制这件事，所以在去年我下场的时候，写了一份公开信，我还讲到AGI，帮助我们繁荣和延续人类文明。

我把这个事情当成一个目标，所以只要再，让文明能够更好的延续，而不是说只是叫做，机器一定帮到我们努力，当我们的工具，我觉得这一派在安全里面，我可能在中间是以一个文明为标准，来看待它。

这是第二层的这么一个安全，这是理想的色彩，第三安全，第三个安全是比较现实的，我刚才提到说，AGI是什么，AGI怎么评测，当我跟很多人在聊的时候，拿AGI去做个医生，大家就哎呀好难啊对吧，医疗都搞不定。

如果连这个都做不到之后，那它能力如此之弱，我们就不要想它是什么颠覆人类，还有这么复杂的事，所以现实里面，我觉得在近期里面，还不存在这个安全的问题，所以在现实里面的安全，我们就放在一个意识形态安全。

在远期里面发展文明，而当前里面还是努力，把它的能力给提上去，还没碰到今天的一个，人类文明安全的边界，好 谢谢小川，好 江鹏，您对AI怎么，对AI安全，我们智府其实一直很注意，相关的一些事情。

然后尤其在AI安全方面，因为，我们应该前一段时间，还签署了一个，AI安全的前沿，人工智能安全的承诺是吧，对 承诺书，但是什么样的考量，当时是应该是有15家企业，AI相关的一些企业。

然后来自全球各地各大洲，然后一起签署了这样一个，负责任的AI的这样的一个承诺书，其实我觉得可能安全，只是其中的所谓的一部分，就是我们叫负责任的AI，负责任的AI这个事情，就比安全要更大。

叫安全其中的一块，就是包括刚才，小川师兄想的这三个方面的，这种安全，但其实更多的，还有更多的方面的问题，就是我们如何来保证，或者说如何来努力，让这个技术是真的帮助人类，帮助这个社会 帮助这个地球。

而不是说去为恶，当然这个事情很难说，人的两面性，很难说你们保证，没有人去拿这个事情去作恶，其实现实社会当中，已经有人在发现，发现有人在做这些事情，这个事情永远是，你防守比破坏要难，所以这个需要大家一起。

共同来努力，我相信这个事情的，更重要的一个意义，并不是说我们现在能拿出，多么安全的这样的一些，技术方法，或者是这样的一些管理的规定，去约束大家不要去做这件事情，而是在于说，增强大家对这件事情的了解。

对这件事情的这种，统一的这样一个认识，大家能够坐下来，正面的面对这些问题，把这些问题摆到桌面上来，希望大家更多的人，参与这件事情来一起来讨论，总有解决问题的这个办法，好 大海，咱们对AI安全这块的看法。

对 我比较同意前面，各位老板说到的这个观点，我认为现在这个阶段，安全主要还是聚焦在，基础安全跟内容安全，这两个方向上，然后我会觉得，未来 现在的大模型，其实本质上是只独的，就是我们把模型训练好。

权重是固定的，你的推力其实不会影响权重，你的权重都是在，线下再去持续的阶段去训练的，有一天当我们把模型，部署到机器人，部署到这些我说的中端上，然后它能够去动态地，去更新自己的权重了以后。

我觉得安全问题会变成一个，非常非常重要的问题，好 谢谢，谢谢大海，我们今天其实讨论了很多，关于AGI 也讨论AI安全，但其实对于在座都是企业家，企业家对于企业而言，可能虽然也很关注AGI。

但可能也更关注ROI，其实最近有好多的记者朋友，也都在问我关于最近的，大模型的价格战怎么看，然后我当时给他们的回复说，志愿研究院是坚定地拥抱开源，我们都是免费的给整个社区，给产业界在使用。

但我也给他们承诺，就是正好借志愿大会，借今天这个圆桌的机会，所以也想请教一下诸位，对于近期大模型的价格战的一个看法，它是更有利于大模型的普及，还是实际上这种过于，对吧就是激烈的价格战。

并不利于企业的发展，尤其我们知道大模型还是需要，有非常持续的投入，还在研发的过程，对吧，还是企业要有，要有正当的这样的一个利润，才能够进入到一个，持续良性的一个发展，那志霖，对 我觉得这是很好问题。

我觉得最终如果我们把时间，先拉足够长的话，其实最终还是会回归这个价值本身，我自己有三个判断，就是第一个就是说，很重要的一个点就是，其实在接下来，就是比如说我们去看这个算力的投入。

你可能投入在推理上的算力，在某个时间点之后，它应该是可以显著超过训练的这个算力，我觉得这个是标志就是说，你的价值开始得到释放，所以你可能前面用来训练的这些，这个成本它其实是可以，很大程度上被覆盖。

然后可能第二个很重要的节点，我觉得是说就是，如果从C端的角度来说，我觉得是你的推理成本，可能会显著地低于你的获客成本，对 所以我觉得它可能从商业本质上来讲，可能不会跟之前的各种商业模式。

会有非常本质的区别，对 我觉得这两个是很重要的，然后有了这两个东西之后，我觉得很重要的是第三个因素，就是我们今天其实AI在整个，人的这个工作流程里面的占比，它还是很低的，它可能是1%。

也就是说人做的事情，要有点多于AI做的事情，所以我觉得最重要的第三个点是说，AI本身做的事情，可能会在某个时间点，超过人做的事情，对 那这个时候我觉得，它就可能会产生新的商业模式。

就它可能不是像今天说的，在B端用API去做价格战，而是可能它是一个普惠的AI，同时可能是根据它产生的价值，从这里面去分层产生的这个商业模式，对 所以我觉得可能这三个点，会是改变这个商业模式本身。

或者你刚刚说的IR这个问题的，一个很重要的一个趋势，对，好 谢谢指令，小川 您对近期大模型的价格战怎么看，我先说结论，我觉得今天价格战对于，中国发展大模型是特别好的事。

先说结论 我是积极看待这样一个事情，首先一个视角，就是很多时候这个好不好，你得看是对单个的公司，还是对一个群体 一个整个市场，因为价格战的话，通常是这个市场行为，是一个竞争的这么一个导向。

那我觉得至少带来两个好的后果，第一个 更多公司，更多人能用上大模型了，很多企业之前是不懂这个的，就变成一场普及运动一样的，就很多公司它可以免费，或者很便宜地开始做POC，开始去使用大模型。

使得这样一个大模型，中国能够迅速去有一个普及，不管是个人还是很多企业，就入场了，这对整个市场是第一个好处，第二块的话呢，就在中间我觉得之前还有很多浪费，因为大家恐慌的时候，大家不知道大模型是何物。

我就观察到很多企业，但凡有点技术能力，都说我自己要逊个大模型，对吧 然后自己拿卡，甚至跑来找我们说，怎么联合训练啊这块，明明它该是大模型的用户 消费者，大模型的使用方，但都想转型成为一个大模型的供给方。

要提供一个自己的大模型，然后我要在行业做大模型，一个企业变成所谓做一个行业，这些情况下其实带来很多的人才，资金和这种社会的浪费，当有加盖站之后的话呢，很多企业就开始清醒了，我干嘛非得去做。

做完了我到底在干嘛，我的竞争优势在什么地方，它就退回来说成为大模型的用户，我觉得这个浪费也会减少很多，所以既能带来一个启蒙，也能带来对社会资源的一个，减少这样一个消耗，那更多的企业在里面就是能够。

有自己定位 对吧，把自己给做好，不需要一千一万个大模型，在之前如果没有加盖站的时候，中国可能真的是上百上千个大模型在进行，那么这样的市场的分层就能做好，每家都能够受益，这种竞争力就能起来。

谢谢小川非常鲜明的观点，我不知道詹鹏您赞同小川的观点吗，基本上是赞同这个观点的，而且这个事情其实有人跑过来跟我们说，说你们是加盖站的什么发起方什么之类的，我说这个子虚乌有，其实在那个之前。

其实我们一直秉持的一个概念，其实就是你说的那个RI，就是给用户带来最大的收益价值，然后用我们的技术，用我们的创新去极低的降低，大家的使用这个技术的成本，这是为了让这个技术能够更多的普及。

让更多的人能够享受这个收益，所以我们当时推出的这些，其实在很长一段时间里面，我们的很多的价格都是行业内都算是极低的，因为是我们的技术确实能做到那一步，能把中间的空间成本的空间，释放出来当做大家的收益。

帮助大家去把RI算出一个大于一的数字来，当然这个事情从宏观长度来讲，肯定是说对于整个中国的大模型产业是有利的，有更多的人来使用，能更多的人来把真的把大模型当做什么，当做我们一开始提到的那件事情。

就是它会变成基础设施，基础设施什么意思，就是非常便宜随时就可以用，你不用去特别的计较，说在这个事情上我要投入特别特别的大，然后收益是什么，当真的有一天AI的能力。

大模型的能力变得像水电这样的基础能力的时候，其实这个事儿它就对我们来讲，企业来讲是一个更好的发展的这样一个空间，这样更好的一个发展的这样一个态势，所以这个也是我们一直在坚持做的事情。

包括最近20号我们发的新的模型，它真的是把成本已经压到，我们都不好意思跟大家报价的地步，以前你看都是大家报价都是，1000token多少多少钱是吧几分钱，就没有比这个更小的单位了，人民币里头就几厘。

这个好像没法算了，怎么办呢，把单位变成100万token多少钱，它已经到了这样的一个地步了，所以我是觉得这件事情对整体上大的是有好处，但是也要注意的就是说不要去，过多的关注这件事情，过多的宣扬这件事情。

商业上肯定这件事情就是说，你去牺牲企业的短期的，比如说成本也好，就亏本做买卖，这个不是一个正常的商业逻辑，这个肯定是只能持续很短的时间，真正还回归最终的用户价值，生产力价值上，好谢谢。

大海咱们在端测的大模型会面临价格战的困扰吗，其实我们做端测就是看到了端测的一个落地，更早能更快落地的一个可能性，其实最近有一个机构做过一个调研，发现说全国10亿用户的手机的端测的算力。

差不多相当于100万片H100，这个是非常夸张的一个数字，如果这些不同的手机上的这些算力，能够被好好的利用起来，其实我们很多的应用就可以落地了，当然这个里面现在这个阶段一定是。

包括现在到未来都需要端测模型跟云测模型，好好的协同，这个是端测有端测的优势，它的优势是隐私性好，然后更可靠，但是云上的模型肯定能力要比端测更强，所以怎么把端跟云协同好，我觉得是一个后面。

其实我们跟所有其他的模型公司一起要去协作的事，然后我也非常同意前面大家说的观点，我认为我自己的看法，我觉得当前的这个所谓的价格战，多多少少有一些营销的成分在，但是我相信未来一定会比现在这个还要便宜。

并且大家都有利润，这才是健康的方式，并且这才真的能让千行百业的应用往下落地，好谢谢大海，对其实想问的问题还有特别的多，但因为时间的关系，所以可能没办法全部都问完，但最后也还是想请各位CEO。

因为我们知道其实在座的诸位，以及在座的企业，其实跟智原都有非常深厚的渊源，也有很深厚的关系，那也想请大家对于智原，对于我们的智原大会，看看有没有什么样的一些寄语，好 志霖，对 智原是。

对 我记得应该是我们20年的时候开始开发这个悟道模型，所以我觉得其实智原是可能，在至少是亚洲地区我觉得最早投入，而且是真seriously，就真的投入去做这个大模型的机构，我觉得这个是非常难得的。

很早的一个非常领先的这样的一个想法，然后今天我觉得其实整个视野也会更宽，就是说不光只是说大语言模型，可能也做很多动模态，然后巨声智能，然后慢慢智原大会也变成一个，就是一个非常好的平台。

能够让大家在上面交流，所以我们其实收益都很大，所以也希望就是说，这个能够持续的成为一个，就是这种全球领先的平台，对，谢谢志霖，小川，其实这个智原是可以应该叫中国大模型，这个的黄埔军校。

要整个这个大模型的这种思潮，它后面的技术都从智原这个发展起来的，其实我上一家做的公司叫SOCO，当时这个比较早就给智原在合作，提供当时SOCO搜索的这个数据，来发展这个大模型，从一下子到今天。

中国大模型已经蓬勃而出了，那今天我觉得智原有它非常好的这么一个定位，因为其他更多，咱们都是市场化的这样一些企业，那企业在过程当中的话呢，既有技术的需求，也要跟政府的这样一个连接。

因此智原在中间处于一个中立的，有技术高度，又同时得到这样一个，这个政府信任这么一个机构，所以它扮演的这个技术角色，和这个公平的这么一个，一个智库的这种角色，对吧，这两个方面讲，我觉得是有独有的这个意义。

所以我认为在今天这样一个生态里面，是能够帮助我们更加快速健康的发展，好 谢谢小川，张鹏，智原我们就很熟悉了，这么多年了，这个智原从最早定位成一个NGO，一个偏研究的一个新型的研发机构，到发展到今天。

真的是已经是这个，国内甚至是国际上，这个人工智能领域的一面旗帜了，这也是 我觉得也是智原取了一个很好的名字，就是发布的那个系列，Flag系列的这一个产品的这个本意吧，也是可以看到智原在整个人工智能。

这一次浪潮当中有非常大的这样宏观，很好的这样一个 宏远的这样一个布局，我们也非常希望跟智原能够长期的在学术研究，这个落地应用的合作，甚至包括公共政策相关这样的一些方面，能够很深入的这样继续地保持合作。

也希望也祝愿这个智原大会越办越好，谢谢张鹏 大海，对 大模型这个领域变化非常快，但这里面确实有一些事情是商业公司没有动力，和没有 可能也没有资源去做的事，我们非常期待在智原的这个中间的撮合跟代理下。

能够把行业搭建一个更好的这样的平台，能够把这些需要做好的事情能够一起协作好，然后也祝愿智原的每年的年会，像我们AIG的春晚一样能够越办越好，好 谢谢 谢谢各位CEO对于智原大会的美好的祝愿。

因为时间的关系，我们今天这个尖锋对话的环节可能就到这边，好 谢谢大家，谢谢大家，謝謝大家，謝謝。